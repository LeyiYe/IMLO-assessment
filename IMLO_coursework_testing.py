{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeyiYe/IMLO-assessment/blob/main/IMLO_coursework_testing.py\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "3kilRioudwz6",
        "outputId": "d0676126-1a84-4974-ac4c-4868e5d799ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to data/flowers-102/102flowers.tgz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 344862509/344862509 [00:24<00:00, 14339606.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/flowers-102/102flowers.tgz to data/flowers-102\n",
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to data/flowers-102/imagelabels.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 502/502 [00:00<00:00, 426741.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to data/flowers-102/setid.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 14989/14989 [00:00<00:00, 26639162.14it/s]\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (32x32768 and 1048576x512)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d4741db87a80>\u001b[0m in \u001b[0;36m<cell line: 91>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-d4741db87a80>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Flatten the tensor while preserving the batch size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x32768 and 1048576x512)"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import Flowers102\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define transforms for data augmentation and normalization\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(128),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(144),\n",
        "    transforms.CenterCrop(128),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the dataset with train/val/test splits\n",
        "train_dataset = Flowers102(root='./data', split='train', transform=train_transform, download=True)\n",
        "val_dataset = Flowers102(root='./data', split='test', transform=val_transform, download=True)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Define data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "class CNN_NN(nn.Module):\n",
        "    def __init__(self, num_classes=102):\n",
        "        super(CNN_NN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        # Calculate the size after convolutions and pooling\n",
        "        self._to_linear = None\n",
        "        self.convs = nn.Sequential(\n",
        "            self.conv1,\n",
        "            nn.ReLU(),\n",
        "            self.pool,\n",
        "            self.conv2,\n",
        "            nn.ReLU(),\n",
        "            self.pool,\n",
        "            self.conv3,\n",
        "            nn.ReLU(),\n",
        "            self.pool\n",
        "        )\n",
        "        x = torch.randn(32, 3, 128, 128)  # Sample input with batch size 1\n",
        "        self._to_linear = self.convs(x).view(1, -1).shape[1]\n",
        "\n",
        "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor while preserving the batch size\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Define the device (GPU or CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyperparameters\n",
        "num_classes = 102  # Number of output classes\n",
        "learning_rate = 0.001\n",
        "num_epochs = 25\n",
        "\n",
        "# Initialize the model\n",
        "model = CNN_NN(num_classes=num_classes).to(device)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    # Calculate average loss for the epoch\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Calculate average validation loss and accuracy\n",
        "    val_loss = val_loss / len(val_loader.dataset)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "          f'Training Loss: {epoch_loss:.4f}, '\n",
        "          f'Validation Loss: {val_loss:.4f}, '\n",
        "          f'Validation Accuracy: {accuracy:.4f}')\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUiwi1trgGQk",
        "outputId": "048980d3-bbd4-4d08-b68f-a0d5cddc10f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/100], Training Loss: 4.6460, Validation Loss: 4.4936, Validation Accuracy: 0.0117\n",
            "Epoch [2/100], Training Loss: 4.4863, Validation Loss: 4.2615, Validation Accuracy: 0.0320\n",
            "Epoch [3/100], Training Loss: 4.2801, Validation Loss: 4.0858, Validation Accuracy: 0.0337\n",
            "Epoch [4/100], Training Loss: 4.0561, Validation Loss: 3.9437, Validation Accuracy: 0.0475\n",
            "Epoch [5/100], Training Loss: 3.8947, Validation Loss: 3.8466, Validation Accuracy: 0.0784\n",
            "Epoch [6/100], Training Loss: 3.8420, Validation Loss: 3.7714, Validation Accuracy: 0.0784\n",
            "Epoch [7/100], Training Loss: 3.7099, Validation Loss: 3.7246, Validation Accuracy: 0.1002\n",
            "Epoch [8/100], Training Loss: 3.6160, Validation Loss: 3.6498, Validation Accuracy: 0.1173\n",
            "Epoch [9/100], Training Loss: 3.5210, Validation Loss: 3.5151, Validation Accuracy: 0.1394\n",
            "Epoch [10/100], Training Loss: 3.3749, Validation Loss: 3.4124, Validation Accuracy: 0.1604\n",
            "Epoch [11/100], Training Loss: 3.3534, Validation Loss: 3.4347, Validation Accuracy: 0.1584\n",
            "Epoch [12/100], Training Loss: 3.1871, Validation Loss: 3.3794, Validation Accuracy: 0.1719\n",
            "Epoch [13/100], Training Loss: 3.0971, Validation Loss: 3.2228, Validation Accuracy: 0.2296\n",
            "Epoch [14/100], Training Loss: 3.0711, Validation Loss: 3.2103, Validation Accuracy: 0.2194\n",
            "Epoch [15/100], Training Loss: 3.0296, Validation Loss: 3.1663, Validation Accuracy: 0.2407\n",
            "Epoch [16/100], Training Loss: 2.9102, Validation Loss: 3.1169, Validation Accuracy: 0.2374\n",
            "Epoch [17/100], Training Loss: 2.8666, Validation Loss: 3.0525, Validation Accuracy: 0.2639\n",
            "Epoch [18/100], Training Loss: 2.7655, Validation Loss: 3.0106, Validation Accuracy: 0.2646\n",
            "Epoch [19/100], Training Loss: 2.7444, Validation Loss: 2.9812, Validation Accuracy: 0.2826\n",
            "Epoch [20/100], Training Loss: 2.5693, Validation Loss: 3.0719, Validation Accuracy: 0.2792\n",
            "Epoch [21/100], Training Loss: 2.6038, Validation Loss: 2.9651, Validation Accuracy: 0.2835\n",
            "Epoch [22/100], Training Loss: 2.5620, Validation Loss: 2.9153, Validation Accuracy: 0.2924\n",
            "Epoch [23/100], Training Loss: 2.4824, Validation Loss: 2.8828, Validation Accuracy: 0.3079\n",
            "Epoch [24/100], Training Loss: 2.4229, Validation Loss: 2.9107, Validation Accuracy: 0.3179\n",
            "Epoch [25/100], Training Loss: 2.3459, Validation Loss: 2.8668, Validation Accuracy: 0.3077\n",
            "Epoch [26/100], Training Loss: 2.2949, Validation Loss: 2.8885, Validation Accuracy: 0.3126\n",
            "Epoch [27/100], Training Loss: 2.2361, Validation Loss: 2.8063, Validation Accuracy: 0.3264\n",
            "Epoch [28/100], Training Loss: 2.2013, Validation Loss: 2.7945, Validation Accuracy: 0.3329\n",
            "Epoch [29/100], Training Loss: 2.2250, Validation Loss: 2.9032, Validation Accuracy: 0.3202\n",
            "Epoch [30/100], Training Loss: 2.1063, Validation Loss: 2.8303, Validation Accuracy: 0.3444\n",
            "Epoch [31/100], Training Loss: 2.1049, Validation Loss: 2.8443, Validation Accuracy: 0.3472\n",
            "Epoch [32/100], Training Loss: 2.0096, Validation Loss: 2.8467, Validation Accuracy: 0.3610\n",
            "Epoch [33/100], Training Loss: 2.0815, Validation Loss: 2.6773, Validation Accuracy: 0.3625\n",
            "Epoch [34/100], Training Loss: 2.0038, Validation Loss: 2.8832, Validation Accuracy: 0.3397\n",
            "Epoch [35/100], Training Loss: 2.0275, Validation Loss: 2.7775, Validation Accuracy: 0.3662\n",
            "Epoch [36/100], Training Loss: 1.8953, Validation Loss: 2.8542, Validation Accuracy: 0.3534\n",
            "Epoch [37/100], Training Loss: 1.8415, Validation Loss: 2.8775, Validation Accuracy: 0.3547\n",
            "Epoch [38/100], Training Loss: 1.8607, Validation Loss: 2.7224, Validation Accuracy: 0.3705\n",
            "Epoch [39/100], Training Loss: 1.7578, Validation Loss: 2.9444, Validation Accuracy: 0.3628\n",
            "Epoch [40/100], Training Loss: 1.8109, Validation Loss: 2.8511, Validation Accuracy: 0.3815\n",
            "Epoch [41/100], Training Loss: 1.8066, Validation Loss: 2.8308, Validation Accuracy: 0.3661\n",
            "Epoch [42/100], Training Loss: 1.8670, Validation Loss: 2.7475, Validation Accuracy: 0.3861\n",
            "Epoch [43/100], Training Loss: 1.7045, Validation Loss: 2.8265, Validation Accuracy: 0.3817\n",
            "Epoch [44/100], Training Loss: 1.7303, Validation Loss: 2.7978, Validation Accuracy: 0.3827\n",
            "Epoch [45/100], Training Loss: 1.6958, Validation Loss: 2.9632, Validation Accuracy: 0.3662\n",
            "Epoch [46/100], Training Loss: 1.6915, Validation Loss: 2.8731, Validation Accuracy: 0.3830\n",
            "Epoch [47/100], Training Loss: 1.6654, Validation Loss: 3.0007, Validation Accuracy: 0.3812\n",
            "Epoch [48/100], Training Loss: 1.6522, Validation Loss: 2.8659, Validation Accuracy: 0.3858\n",
            "Epoch [49/100], Training Loss: 1.5624, Validation Loss: 2.9298, Validation Accuracy: 0.3791\n",
            "Epoch [50/100], Training Loss: 1.5332, Validation Loss: 3.0251, Validation Accuracy: 0.3792\n",
            "Epoch [51/100], Training Loss: 1.5956, Validation Loss: 2.9446, Validation Accuracy: 0.3914\n",
            "Epoch [52/100], Training Loss: 1.4782, Validation Loss: 2.9077, Validation Accuracy: 0.4023\n",
            "Epoch [53/100], Training Loss: 1.4836, Validation Loss: 2.9273, Validation Accuracy: 0.3947\n",
            "Epoch [54/100], Training Loss: 1.6465, Validation Loss: 2.8629, Validation Accuracy: 0.3846\n",
            "Epoch [55/100], Training Loss: 1.4948, Validation Loss: 3.0410, Validation Accuracy: 0.3893\n",
            "Epoch [56/100], Training Loss: 1.3819, Validation Loss: 2.9847, Validation Accuracy: 0.3921\n",
            "Epoch [57/100], Training Loss: 1.4185, Validation Loss: 2.9932, Validation Accuracy: 0.3981\n",
            "Epoch [58/100], Training Loss: 1.4933, Validation Loss: 3.0181, Validation Accuracy: 0.4028\n",
            "Epoch [59/100], Training Loss: 1.4582, Validation Loss: 2.9089, Validation Accuracy: 0.3833\n",
            "Epoch [60/100], Training Loss: 1.4053, Validation Loss: 3.0519, Validation Accuracy: 0.3921\n",
            "Epoch [61/100], Training Loss: 1.4316, Validation Loss: 2.9405, Validation Accuracy: 0.4015\n",
            "Epoch [62/100], Training Loss: 1.3030, Validation Loss: 3.1763, Validation Accuracy: 0.3939\n",
            "Epoch [63/100], Training Loss: 1.3523, Validation Loss: 2.9858, Validation Accuracy: 0.4201\n",
            "Epoch [64/100], Training Loss: 1.3630, Validation Loss: 3.0973, Validation Accuracy: 0.4056\n",
            "Epoch [65/100], Training Loss: 1.3292, Validation Loss: 3.1563, Validation Accuracy: 0.3971\n",
            "Epoch [66/100], Training Loss: 1.3749, Validation Loss: 2.9554, Validation Accuracy: 0.4071\n",
            "Epoch [67/100], Training Loss: 1.3001, Validation Loss: 3.0646, Validation Accuracy: 0.4059\n",
            "Epoch [68/100], Training Loss: 1.4124, Validation Loss: 3.0023, Validation Accuracy: 0.3918\n",
            "Epoch [69/100], Training Loss: 1.2462, Validation Loss: 3.0770, Validation Accuracy: 0.4095\n",
            "Epoch [70/100], Training Loss: 1.2515, Validation Loss: 3.1605, Validation Accuracy: 0.4054\n",
            "Epoch [71/100], Training Loss: 1.2297, Validation Loss: 3.0754, Validation Accuracy: 0.4126\n",
            "Epoch [72/100], Training Loss: 1.2077, Validation Loss: 3.1534, Validation Accuracy: 0.4080\n",
            "Epoch [73/100], Training Loss: 1.2317, Validation Loss: 3.1089, Validation Accuracy: 0.4108\n",
            "Epoch [74/100], Training Loss: 1.2428, Validation Loss: 3.0162, Validation Accuracy: 0.4128\n",
            "Epoch [75/100], Training Loss: 1.1130, Validation Loss: 3.0929, Validation Accuracy: 0.4240\n",
            "Epoch [76/100], Training Loss: 1.2390, Validation Loss: 3.0642, Validation Accuracy: 0.4249\n",
            "Epoch [77/100], Training Loss: 1.2231, Validation Loss: 3.1961, Validation Accuracy: 0.4152\n",
            "Epoch [78/100], Training Loss: 1.2043, Validation Loss: 3.1549, Validation Accuracy: 0.4290\n",
            "Epoch [79/100], Training Loss: 1.1890, Validation Loss: 3.2749, Validation Accuracy: 0.4007\n",
            "Epoch [80/100], Training Loss: 1.1884, Validation Loss: 3.2899, Validation Accuracy: 0.4180\n",
            "Epoch [81/100], Training Loss: 1.1475, Validation Loss: 3.2511, Validation Accuracy: 0.4165\n",
            "Epoch [82/100], Training Loss: 1.1637, Validation Loss: 3.1215, Validation Accuracy: 0.4025\n",
            "Epoch [83/100], Training Loss: 1.1728, Validation Loss: 3.1246, Validation Accuracy: 0.4204\n",
            "Epoch [84/100], Training Loss: 1.1665, Validation Loss: 3.2406, Validation Accuracy: 0.4160\n",
            "Epoch [85/100], Training Loss: 1.0847, Validation Loss: 3.2272, Validation Accuracy: 0.4258\n",
            "Epoch [86/100], Training Loss: 1.0633, Validation Loss: 3.2695, Validation Accuracy: 0.4121\n",
            "Epoch [87/100], Training Loss: 1.2818, Validation Loss: 3.2551, Validation Accuracy: 0.4275\n",
            "Epoch [88/100], Training Loss: 1.1142, Validation Loss: 3.1698, Validation Accuracy: 0.4163\n",
            "Epoch [89/100], Training Loss: 1.1172, Validation Loss: 3.2501, Validation Accuracy: 0.4289\n",
            "Epoch [90/100], Training Loss: 1.1314, Validation Loss: 3.2690, Validation Accuracy: 0.4212\n",
            "Epoch [91/100], Training Loss: 0.9800, Validation Loss: 3.3246, Validation Accuracy: 0.4207\n",
            "Epoch [92/100], Training Loss: 0.9942, Validation Loss: 3.2892, Validation Accuracy: 0.4178\n",
            "Epoch [93/100], Training Loss: 1.0743, Validation Loss: 3.3942, Validation Accuracy: 0.4188\n",
            "Epoch [94/100], Training Loss: 1.0239, Validation Loss: 3.3052, Validation Accuracy: 0.4238\n",
            "Epoch [95/100], Training Loss: 1.0098, Validation Loss: 3.3676, Validation Accuracy: 0.4432\n",
            "Epoch [96/100], Training Loss: 1.0999, Validation Loss: 3.3805, Validation Accuracy: 0.4183\n",
            "Epoch [97/100], Training Loss: 1.0500, Validation Loss: 3.3179, Validation Accuracy: 0.4220\n",
            "Epoch [98/100], Training Loss: 1.0251, Validation Loss: 3.4274, Validation Accuracy: 0.4292\n",
            "Epoch [99/100], Training Loss: 1.0945, Validation Loss: 3.3210, Validation Accuracy: 0.4191\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import Flowers102\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define transforms for data augmentation and normalization\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(128),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(144),\n",
        "    transforms.CenterCrop(128),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the dataset with train/val/test splits\n",
        "train_dataset = Flowers102(root='./data', split='train', transform=train_transform, download=True)\n",
        "val_dataset = Flowers102(root='./data', split='test', transform=val_transform, download=True)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Define data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "class CNN_NN(nn.Module):\n",
        "    def __init__(self, num_classes=102):\n",
        "        super(CNN_NN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        # Initialize the size of the fully connected layer based on the sample input\n",
        "        self._to_linear = None\n",
        "        self.convs = nn.Sequential(\n",
        "            self.conv1,\n",
        "            nn.ReLU(),\n",
        "            self.pool,\n",
        "            self.conv2,\n",
        "            nn.ReLU(),\n",
        "            self.pool,\n",
        "            self.conv3,\n",
        "            nn.ReLU(),\n",
        "            self.pool\n",
        "        )\n",
        "        self._initialize_linear_layer()\n",
        "\n",
        "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def _initialize_linear_layer(self):\n",
        "        # Create a dummy input tensor to calculate the output size after conv layers\n",
        "        x = torch.randn(1, 3, 128, 128)\n",
        "        x = self.convs(x)\n",
        "        self._to_linear = x.view(1, -1).shape[1]\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor while preserving the batch size\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Define the device (GPU or CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyperparameters\n",
        "num_classes = 102  # Number of output classes\n",
        "learning_rate = 0.001\n",
        "num_epochs = 100\n",
        "\n",
        "# Initialize the model\n",
        "model = CNN_NN(num_classes=num_classes).to(device)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    # Calculate average loss for the epoch\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Calculate average validation loss and accuracy\n",
        "    val_loss = val_loss / len(val_loader.dataset)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "          f'Training Loss: {epoch_loss:.4f}, '\n",
        "          f'Validation Loss: {val_loss:.4f}, '\n",
        "          f'Validation Accuracy: {accuracy:.4f}')\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBfyh2HeSyaG",
        "outputId": "dc7acb49-7021-4a2d-abd7-9cf18df4ee45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to data/flowers-102/102flowers.tgz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 344862509/344862509 [00:10<00:00, 33314038.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/flowers-102/102flowers.tgz to data/flowers-102\n",
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to data/flowers-102/imagelabels.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 502/502 [00:00<00:00, 1092652.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to data/flowers-102/setid.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 14989/14989 [00:00<00:00, 8480834.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/100], Training Loss: 4.6488, Validation Loss: 4.6014, Validation Accuracy: 0.0270\n",
            "Epoch [2/100], Training Loss: 4.5745, Validation Loss: 4.4741, Validation Accuracy: 0.0351\n",
            "Epoch [3/100], Training Loss: 4.4303, Validation Loss: 4.2763, Validation Accuracy: 0.0472\n",
            "Epoch [4/100], Training Loss: 4.2511, Validation Loss: 4.1117, Validation Accuracy: 0.0340\n",
            "Epoch [5/100], Training Loss: 4.1175, Validation Loss: 3.9832, Validation Accuracy: 0.0841\n",
            "Epoch [6/100], Training Loss: 4.0397, Validation Loss: 3.8871, Validation Accuracy: 0.0997\n",
            "Epoch [7/100], Training Loss: 3.9044, Validation Loss: 3.7957, Validation Accuracy: 0.1104\n",
            "Epoch [8/100], Training Loss: 3.8407, Validation Loss: 3.7369, Validation Accuracy: 0.1203\n",
            "Epoch [9/100], Training Loss: 3.7780, Validation Loss: 3.6295, Validation Accuracy: 0.1342\n",
            "Epoch [10/100], Training Loss: 3.6542, Validation Loss: 3.5983, Validation Accuracy: 0.1368\n",
            "Epoch [11/100], Training Loss: 3.6401, Validation Loss: 3.5298, Validation Accuracy: 0.1604\n",
            "Epoch [12/100], Training Loss: 3.5332, Validation Loss: 3.4937, Validation Accuracy: 0.1756\n",
            "Epoch [13/100], Training Loss: 3.4826, Validation Loss: 3.4365, Validation Accuracy: 0.1847\n",
            "Epoch [14/100], Training Loss: 3.4861, Validation Loss: 3.3924, Validation Accuracy: 0.1873\n",
            "Epoch [15/100], Training Loss: 3.3982, Validation Loss: 3.3498, Validation Accuracy: 0.2021\n",
            "Epoch [16/100], Training Loss: 3.3151, Validation Loss: 3.3048, Validation Accuracy: 0.2181\n",
            "Epoch [17/100], Training Loss: 3.3050, Validation Loss: 3.2959, Validation Accuracy: 0.2056\n",
            "Epoch [18/100], Training Loss: 3.2481, Validation Loss: 3.2824, Validation Accuracy: 0.2126\n",
            "Epoch [19/100], Training Loss: 3.2615, Validation Loss: 3.2376, Validation Accuracy: 0.2184\n",
            "Epoch [20/100], Training Loss: 3.1511, Validation Loss: 3.1889, Validation Accuracy: 0.2262\n",
            "Epoch [21/100], Training Loss: 3.1860, Validation Loss: 3.1521, Validation Accuracy: 0.2467\n",
            "Epoch [22/100], Training Loss: 3.1044, Validation Loss: 3.1333, Validation Accuracy: 0.2386\n",
            "Epoch [23/100], Training Loss: 3.0661, Validation Loss: 3.0621, Validation Accuracy: 0.2552\n",
            "Epoch [24/100], Training Loss: 3.0459, Validation Loss: 3.1301, Validation Accuracy: 0.2402\n",
            "Epoch [25/100], Training Loss: 2.9357, Validation Loss: 3.0557, Validation Accuracy: 0.2496\n",
            "Epoch [26/100], Training Loss: 2.9187, Validation Loss: 3.0169, Validation Accuracy: 0.2591\n",
            "Epoch [27/100], Training Loss: 2.8582, Validation Loss: 3.0028, Validation Accuracy: 0.2674\n",
            "Epoch [28/100], Training Loss: 2.8126, Validation Loss: 2.9945, Validation Accuracy: 0.2700\n",
            "Epoch [29/100], Training Loss: 2.9012, Validation Loss: 3.0245, Validation Accuracy: 0.2574\n",
            "Epoch [30/100], Training Loss: 2.8780, Validation Loss: 2.9734, Validation Accuracy: 0.2701\n",
            "Epoch [31/100], Training Loss: 2.8247, Validation Loss: 2.9560, Validation Accuracy: 0.2822\n",
            "Epoch [32/100], Training Loss: 2.7752, Validation Loss: 2.9908, Validation Accuracy: 0.2667\n",
            "Epoch [33/100], Training Loss: 2.8054, Validation Loss: 2.9544, Validation Accuracy: 0.2885\n",
            "Epoch [34/100], Training Loss: 2.7636, Validation Loss: 2.9042, Validation Accuracy: 0.2927\n",
            "Epoch [35/100], Training Loss: 2.6571, Validation Loss: 2.9385, Validation Accuracy: 0.2835\n",
            "Epoch [36/100], Training Loss: 2.6345, Validation Loss: 2.9310, Validation Accuracy: 0.2844\n",
            "Epoch [37/100], Training Loss: 2.6516, Validation Loss: 2.8839, Validation Accuracy: 0.2953\n",
            "Epoch [38/100], Training Loss: 2.5959, Validation Loss: 2.8427, Validation Accuracy: 0.3160\n",
            "Epoch [39/100], Training Loss: 2.5678, Validation Loss: 2.8258, Validation Accuracy: 0.3166\n",
            "Epoch [40/100], Training Loss: 2.5230, Validation Loss: 2.8824, Validation Accuracy: 0.3040\n",
            "Epoch [41/100], Training Loss: 2.5808, Validation Loss: 2.8590, Validation Accuracy: 0.2999\n",
            "Epoch [42/100], Training Loss: 2.5505, Validation Loss: 2.8709, Validation Accuracy: 0.3098\n",
            "Epoch [43/100], Training Loss: 2.5029, Validation Loss: 2.8664, Validation Accuracy: 0.3025\n",
            "Epoch [44/100], Training Loss: 2.5114, Validation Loss: 2.8378, Validation Accuracy: 0.3197\n",
            "Epoch [45/100], Training Loss: 2.4085, Validation Loss: 2.8495, Validation Accuracy: 0.3142\n",
            "Epoch [46/100], Training Loss: 2.4073, Validation Loss: 2.7931, Validation Accuracy: 0.3251\n",
            "Epoch [47/100], Training Loss: 2.4559, Validation Loss: 2.8013, Validation Accuracy: 0.3139\n",
            "Epoch [48/100], Training Loss: 2.4560, Validation Loss: 2.7522, Validation Accuracy: 0.3309\n",
            "Epoch [49/100], Training Loss: 2.3889, Validation Loss: 2.8100, Validation Accuracy: 0.3243\n",
            "Epoch [50/100], Training Loss: 2.3809, Validation Loss: 2.8172, Validation Accuracy: 0.3222\n",
            "Epoch [51/100], Training Loss: 2.3823, Validation Loss: 2.8042, Validation Accuracy: 0.3218\n",
            "Epoch [52/100], Training Loss: 2.2799, Validation Loss: 2.8126, Validation Accuracy: 0.3269\n",
            "Epoch [53/100], Training Loss: 2.2934, Validation Loss: 2.7004, Validation Accuracy: 0.3485\n",
            "Epoch [54/100], Training Loss: 2.3397, Validation Loss: 2.8012, Validation Accuracy: 0.3295\n",
            "Epoch [55/100], Training Loss: 2.3288, Validation Loss: 2.7827, Validation Accuracy: 0.3274\n",
            "Epoch [56/100], Training Loss: 2.2484, Validation Loss: 2.7072, Validation Accuracy: 0.3488\n",
            "Epoch [57/100], Training Loss: 2.1755, Validation Loss: 2.7391, Validation Accuracy: 0.3375\n",
            "Epoch [58/100], Training Loss: 2.2835, Validation Loss: 2.7219, Validation Accuracy: 0.3495\n",
            "Epoch [59/100], Training Loss: 2.2219, Validation Loss: 2.7600, Validation Accuracy: 0.3436\n",
            "Epoch [60/100], Training Loss: 2.2502, Validation Loss: 2.7951, Validation Accuracy: 0.3386\n",
            "Epoch [61/100], Training Loss: 2.1888, Validation Loss: 2.7777, Validation Accuracy: 0.3394\n",
            "Epoch [62/100], Training Loss: 2.0963, Validation Loss: 2.7490, Validation Accuracy: 0.3454\n",
            "Epoch [63/100], Training Loss: 2.1766, Validation Loss: 2.6939, Validation Accuracy: 0.3516\n",
            "Epoch [64/100], Training Loss: 2.1733, Validation Loss: 2.7898, Validation Accuracy: 0.3407\n",
            "Epoch [65/100], Training Loss: 2.1552, Validation Loss: 2.7119, Validation Accuracy: 0.3552\n",
            "Epoch [66/100], Training Loss: 2.0754, Validation Loss: 2.7080, Validation Accuracy: 0.3500\n",
            "Epoch [67/100], Training Loss: 2.0862, Validation Loss: 2.7015, Validation Accuracy: 0.3610\n",
            "Epoch [68/100], Training Loss: 2.1110, Validation Loss: 2.6929, Validation Accuracy: 0.3628\n",
            "Epoch [69/100], Training Loss: 1.9916, Validation Loss: 2.7389, Validation Accuracy: 0.3557\n",
            "Epoch [70/100], Training Loss: 1.9507, Validation Loss: 2.8359, Validation Accuracy: 0.3475\n",
            "Epoch [71/100], Training Loss: 2.0178, Validation Loss: 2.7268, Validation Accuracy: 0.3618\n",
            "Epoch [72/100], Training Loss: 2.0231, Validation Loss: 2.7143, Validation Accuracy: 0.3687\n",
            "Epoch [73/100], Training Loss: 2.0023, Validation Loss: 2.7669, Validation Accuracy: 0.3573\n",
            "Epoch [74/100], Training Loss: 1.9749, Validation Loss: 2.7282, Validation Accuracy: 0.3584\n",
            "Epoch [75/100], Training Loss: 1.9754, Validation Loss: 2.7641, Validation Accuracy: 0.3640\n",
            "Epoch [76/100], Training Loss: 1.9990, Validation Loss: 2.7520, Validation Accuracy: 0.3644\n",
            "Epoch [77/100], Training Loss: 1.9951, Validation Loss: 2.7187, Validation Accuracy: 0.3658\n",
            "Epoch [78/100], Training Loss: 1.9770, Validation Loss: 2.7377, Validation Accuracy: 0.3638\n",
            "Epoch [79/100], Training Loss: 1.9088, Validation Loss: 2.7468, Validation Accuracy: 0.3693\n",
            "Epoch [80/100], Training Loss: 1.9012, Validation Loss: 2.7731, Validation Accuracy: 0.3664\n",
            "Epoch [81/100], Training Loss: 1.8834, Validation Loss: 2.7347, Validation Accuracy: 0.3662\n",
            "Epoch [82/100], Training Loss: 1.9121, Validation Loss: 2.7030, Validation Accuracy: 0.3719\n",
            "Epoch [83/100], Training Loss: 1.8829, Validation Loss: 2.7698, Validation Accuracy: 0.3617\n",
            "Epoch [84/100], Training Loss: 1.8384, Validation Loss: 2.7680, Validation Accuracy: 0.3640\n",
            "Epoch [85/100], Training Loss: 1.8472, Validation Loss: 2.6533, Validation Accuracy: 0.3740\n",
            "Epoch [86/100], Training Loss: 1.8340, Validation Loss: 2.7218, Validation Accuracy: 0.3758\n",
            "Epoch [87/100], Training Loss: 1.9602, Validation Loss: 2.6793, Validation Accuracy: 0.3822\n",
            "Epoch [88/100], Training Loss: 1.7744, Validation Loss: 2.7358, Validation Accuracy: 0.3740\n",
            "Epoch [89/100], Training Loss: 1.8487, Validation Loss: 2.8334, Validation Accuracy: 0.3627\n",
            "Epoch [90/100], Training Loss: 1.8254, Validation Loss: 2.6464, Validation Accuracy: 0.3885\n",
            "Epoch [91/100], Training Loss: 1.7413, Validation Loss: 2.7024, Validation Accuracy: 0.3807\n",
            "Epoch [92/100], Training Loss: 1.7004, Validation Loss: 2.8127, Validation Accuracy: 0.3609\n",
            "Epoch [93/100], Training Loss: 1.8193, Validation Loss: 2.7916, Validation Accuracy: 0.3771\n",
            "Epoch [94/100], Training Loss: 1.7530, Validation Loss: 2.7905, Validation Accuracy: 0.3713\n",
            "Epoch [95/100], Training Loss: 1.6805, Validation Loss: 2.7207, Validation Accuracy: 0.3849\n",
            "Epoch [96/100], Training Loss: 1.7711, Validation Loss: 2.7343, Validation Accuracy: 0.3796\n",
            "Epoch [97/100], Training Loss: 1.7148, Validation Loss: 2.7307, Validation Accuracy: 0.3797\n",
            "Epoch [98/100], Training Loss: 1.7560, Validation Loss: 2.6475, Validation Accuracy: 0.3861\n",
            "Epoch [99/100], Training Loss: 1.7408, Validation Loss: 2.7705, Validation Accuracy: 0.3745\n",
            "Epoch [100/100], Training Loss: 1.7360, Validation Loss: 2.7659, Validation Accuracy: 0.3750\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import Flowers102\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define transforms for data augmentation and normalization\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(128),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(144),\n",
        "    transforms.CenterCrop(128),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the dataset with train/val/test splits\n",
        "train_dataset = Flowers102(root='./data', split='train', transform=train_transform, download=True)\n",
        "val_dataset = Flowers102(root='./data', split='test', transform=val_transform, download=True)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Define data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "class CNN_NN(nn.Module):\n",
        "    def __init__(self, num_classes=102):\n",
        "        super(CNN_NN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        # Initialize the size of the fully connected layer based on the sample input\n",
        "        self._to_linear = None\n",
        "        self.convs = nn.Sequential(\n",
        "            self.conv1,\n",
        "            nn.ReLU(),\n",
        "            self.pool,\n",
        "            self.conv2,\n",
        "            nn.ReLU(),\n",
        "            self.pool,\n",
        "            self.conv3,\n",
        "            nn.ReLU(),\n",
        "            self.pool\n",
        "        )\n",
        "        self._initialize_linear_layer()\n",
        "\n",
        "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def _initialize_linear_layer(self):\n",
        "        # Create a dummy input tensor to calculate the output size after conv layers\n",
        "        x = torch.randn(1, 3, 128, 128)\n",
        "        x = self.convs(x)\n",
        "        self._to_linear = x.view(1, -1).shape[1]\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor while preserving the batch size\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Define the device (GPU or CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyperparameters\n",
        "num_classes = 102  # Number of output classes\n",
        "learning_rate = 0.0001\n",
        "num_epochs = 100\n",
        "\n",
        "# Initialize the model\n",
        "model = CNN_NN(num_classes=num_classes).to(device)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    # Calculate average loss for the epoch\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Calculate average validation loss and accuracy\n",
        "    val_loss = val_loss / len(val_loader.dataset)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "          f'Training Loss: {epoch_loss:.4f}, '\n",
        "          f'Validation Loss: {val_loss:.4f}, '\n",
        "          f'Validation Accuracy: {accuracy:.4f}')\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoaSGnnW5c0B",
        "outputId": "130d9720-af45-47ad-e465-7a9f03fcf720"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to data/flowers-102/102flowers.tgz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 344862509/344862509 [00:12<00:00, 28255118.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/flowers-102/102flowers.tgz to data/flowers-102\n",
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to data/flowers-102/imagelabels.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 502/502 [00:00<00:00, 448846.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to data/flowers-102/setid.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 14989/14989 [00:00<00:00, 30787670.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/250], Training Loss: 4.6237, Validation Loss: 4.4787, Validation Accuracy: 0.0206\n",
            "Epoch [2/250], Training Loss: 4.4306, Validation Loss: 4.3003, Validation Accuracy: 0.0216\n",
            "Epoch [3/250], Training Loss: 4.2906, Validation Loss: 4.1368, Validation Accuracy: 0.0422\n",
            "Epoch [4/250], Training Loss: 4.1873, Validation Loss: 4.0209, Validation Accuracy: 0.0520\n",
            "Epoch [5/250], Training Loss: 3.9940, Validation Loss: 3.8680, Validation Accuracy: 0.0804\n",
            "Epoch [6/250], Training Loss: 3.9255, Validation Loss: 3.7528, Validation Accuracy: 0.1196\n",
            "Epoch [7/250], Training Loss: 3.8247, Validation Loss: 3.5785, Validation Accuracy: 0.1578\n",
            "Epoch [8/250], Training Loss: 3.6643, Validation Loss: 3.5107, Validation Accuracy: 0.1745\n",
            "Epoch [9/250], Training Loss: 3.5731, Validation Loss: 3.3467, Validation Accuracy: 0.1873\n",
            "Epoch [10/250], Training Loss: 3.4639, Validation Loss: 3.2176, Validation Accuracy: 0.2098\n",
            "Epoch [11/250], Training Loss: 3.3682, Validation Loss: 3.2080, Validation Accuracy: 0.2265\n",
            "Epoch [12/250], Training Loss: 3.2309, Validation Loss: 3.1301, Validation Accuracy: 0.2363\n",
            "Epoch [13/250], Training Loss: 3.1370, Validation Loss: 3.0723, Validation Accuracy: 0.2490\n",
            "Epoch [14/250], Training Loss: 3.1045, Validation Loss: 3.0621, Validation Accuracy: 0.2373\n",
            "Epoch [15/250], Training Loss: 3.0625, Validation Loss: 2.9774, Validation Accuracy: 0.2882\n",
            "Epoch [16/250], Training Loss: 2.9940, Validation Loss: 2.9513, Validation Accuracy: 0.2745\n",
            "Epoch [17/250], Training Loss: 2.9143, Validation Loss: 2.8979, Validation Accuracy: 0.2814\n",
            "Epoch [18/250], Training Loss: 2.8402, Validation Loss: 2.8707, Validation Accuracy: 0.3020\n",
            "Epoch [19/250], Training Loss: 2.8162, Validation Loss: 2.8631, Validation Accuracy: 0.2941\n",
            "Epoch [20/250], Training Loss: 2.7041, Validation Loss: 2.8893, Validation Accuracy: 0.2961\n",
            "Epoch [21/250], Training Loss: 2.6661, Validation Loss: 2.8171, Validation Accuracy: 0.2824\n",
            "Epoch [22/250], Training Loss: 2.6746, Validation Loss: 2.7539, Validation Accuracy: 0.3098\n",
            "Epoch [23/250], Training Loss: 2.6090, Validation Loss: 2.7320, Validation Accuracy: 0.3294\n",
            "Epoch [24/250], Training Loss: 2.5857, Validation Loss: 2.7655, Validation Accuracy: 0.3245\n",
            "Epoch [25/250], Training Loss: 2.4171, Validation Loss: 2.7019, Validation Accuracy: 0.3333\n",
            "Epoch [26/250], Training Loss: 2.3862, Validation Loss: 2.8089, Validation Accuracy: 0.3235\n",
            "Epoch [27/250], Training Loss: 2.3963, Validation Loss: 2.7389, Validation Accuracy: 0.3284\n",
            "Epoch [28/250], Training Loss: 2.3063, Validation Loss: 2.6454, Validation Accuracy: 0.3627\n",
            "Epoch [29/250], Training Loss: 2.3632, Validation Loss: 2.6618, Validation Accuracy: 0.3578\n",
            "Epoch [30/250], Training Loss: 2.2583, Validation Loss: 2.7126, Validation Accuracy: 0.3480\n",
            "Epoch [31/250], Training Loss: 2.2313, Validation Loss: 2.7048, Validation Accuracy: 0.3500\n",
            "Epoch [32/250], Training Loss: 2.2047, Validation Loss: 2.6107, Validation Accuracy: 0.3735\n",
            "Epoch [33/250], Training Loss: 2.1769, Validation Loss: 2.6399, Validation Accuracy: 0.3598\n",
            "Epoch [34/250], Training Loss: 2.1041, Validation Loss: 2.6355, Validation Accuracy: 0.3676\n",
            "Epoch [35/250], Training Loss: 2.0246, Validation Loss: 2.6901, Validation Accuracy: 0.3647\n",
            "Epoch [36/250], Training Loss: 2.1036, Validation Loss: 2.6176, Validation Accuracy: 0.3824\n",
            "Epoch [37/250], Training Loss: 2.0075, Validation Loss: 2.6578, Validation Accuracy: 0.3902\n",
            "Epoch [38/250], Training Loss: 1.9238, Validation Loss: 2.7455, Validation Accuracy: 0.3627\n",
            "Epoch [39/250], Training Loss: 1.9187, Validation Loss: 2.6970, Validation Accuracy: 0.3882\n",
            "Epoch [40/250], Training Loss: 1.8186, Validation Loss: 2.6743, Validation Accuracy: 0.3971\n",
            "Epoch [41/250], Training Loss: 1.9260, Validation Loss: 2.7250, Validation Accuracy: 0.3882\n",
            "Epoch [42/250], Training Loss: 1.9529, Validation Loss: 2.6906, Validation Accuracy: 0.4000\n",
            "Epoch [43/250], Training Loss: 1.7426, Validation Loss: 2.6690, Validation Accuracy: 0.4118\n",
            "Epoch [44/250], Training Loss: 1.7846, Validation Loss: 2.7608, Validation Accuracy: 0.3863\n",
            "Epoch [45/250], Training Loss: 1.7108, Validation Loss: 2.7356, Validation Accuracy: 0.3961\n",
            "Epoch [46/250], Training Loss: 1.7357, Validation Loss: 2.6804, Validation Accuracy: 0.4059\n",
            "Epoch [47/250], Training Loss: 1.7658, Validation Loss: 2.7159, Validation Accuracy: 0.3990\n",
            "Epoch [48/250], Training Loss: 1.7439, Validation Loss: 2.8478, Validation Accuracy: 0.3755\n",
            "Epoch [49/250], Training Loss: 1.6887, Validation Loss: 2.6296, Validation Accuracy: 0.4196\n",
            "Epoch [50/250], Training Loss: 1.5990, Validation Loss: 2.6737, Validation Accuracy: 0.3912\n",
            "Epoch [51/250], Training Loss: 1.6552, Validation Loss: 2.6619, Validation Accuracy: 0.4176\n",
            "Epoch [52/250], Training Loss: 1.5289, Validation Loss: 2.7802, Validation Accuracy: 0.4137\n",
            "Epoch [53/250], Training Loss: 1.6056, Validation Loss: 2.7301, Validation Accuracy: 0.3873\n",
            "Epoch [54/250], Training Loss: 1.5773, Validation Loss: 2.7619, Validation Accuracy: 0.4147\n",
            "Epoch [55/250], Training Loss: 1.6367, Validation Loss: 2.7552, Validation Accuracy: 0.4098\n",
            "Epoch [56/250], Training Loss: 1.5165, Validation Loss: 2.7276, Validation Accuracy: 0.4049\n",
            "Epoch [57/250], Training Loss: 1.4121, Validation Loss: 2.7862, Validation Accuracy: 0.4039\n",
            "Epoch [58/250], Training Loss: 1.5390, Validation Loss: 2.7893, Validation Accuracy: 0.4127\n",
            "Epoch [59/250], Training Loss: 1.4115, Validation Loss: 2.7936, Validation Accuracy: 0.4157\n",
            "Epoch [60/250], Training Loss: 1.5051, Validation Loss: 2.8296, Validation Accuracy: 0.4157\n",
            "Epoch [61/250], Training Loss: 1.5085, Validation Loss: 2.6119, Validation Accuracy: 0.4402\n",
            "Epoch [62/250], Training Loss: 1.3309, Validation Loss: 2.7985, Validation Accuracy: 0.4206\n",
            "Epoch [63/250], Training Loss: 1.3965, Validation Loss: 2.7613, Validation Accuracy: 0.4235\n",
            "Epoch [64/250], Training Loss: 1.5017, Validation Loss: 2.7510, Validation Accuracy: 0.4010\n",
            "Epoch [65/250], Training Loss: 1.4058, Validation Loss: 2.8669, Validation Accuracy: 0.4275\n",
            "Epoch [66/250], Training Loss: 1.3564, Validation Loss: 2.8311, Validation Accuracy: 0.4088\n",
            "Epoch [67/250], Training Loss: 1.3999, Validation Loss: 2.9027, Validation Accuracy: 0.4147\n",
            "Epoch [68/250], Training Loss: 1.4330, Validation Loss: 2.7873, Validation Accuracy: 0.4343\n",
            "Epoch [69/250], Training Loss: 1.3504, Validation Loss: 2.8090, Validation Accuracy: 0.4333\n",
            "Epoch [70/250], Training Loss: 1.2571, Validation Loss: 3.0186, Validation Accuracy: 0.4098\n",
            "Epoch [71/250], Training Loss: 1.2572, Validation Loss: 2.8750, Validation Accuracy: 0.4186\n",
            "Epoch [72/250], Training Loss: 1.2470, Validation Loss: 2.8988, Validation Accuracy: 0.4186\n",
            "Epoch [73/250], Training Loss: 1.2108, Validation Loss: 2.9173, Validation Accuracy: 0.4294\n",
            "Epoch [74/250], Training Loss: 1.2314, Validation Loss: 2.9614, Validation Accuracy: 0.4294\n",
            "Epoch [75/250], Training Loss: 1.2173, Validation Loss: 2.8812, Validation Accuracy: 0.4127\n",
            "Epoch [76/250], Training Loss: 1.3659, Validation Loss: 2.9542, Validation Accuracy: 0.4157\n",
            "Epoch [77/250], Training Loss: 1.3124, Validation Loss: 2.9012, Validation Accuracy: 0.4118\n",
            "Epoch [78/250], Training Loss: 1.2145, Validation Loss: 2.9714, Validation Accuracy: 0.4294\n",
            "Epoch [79/250], Training Loss: 1.1710, Validation Loss: 2.9775, Validation Accuracy: 0.4353\n",
            "Epoch [80/250], Training Loss: 1.2544, Validation Loss: 2.8806, Validation Accuracy: 0.4235\n",
            "Epoch [81/250], Training Loss: 1.2468, Validation Loss: 2.9339, Validation Accuracy: 0.4020\n",
            "Epoch [82/250], Training Loss: 1.1591, Validation Loss: 2.8636, Validation Accuracy: 0.4118\n",
            "Epoch [83/250], Training Loss: 1.2242, Validation Loss: 2.8954, Validation Accuracy: 0.4275\n",
            "Epoch [84/250], Training Loss: 1.2254, Validation Loss: 2.8181, Validation Accuracy: 0.4441\n",
            "Epoch [85/250], Training Loss: 1.0884, Validation Loss: 2.9663, Validation Accuracy: 0.4235\n",
            "Epoch [86/250], Training Loss: 1.1083, Validation Loss: 3.0304, Validation Accuracy: 0.4451\n",
            "Epoch [87/250], Training Loss: 1.2782, Validation Loss: 2.9018, Validation Accuracy: 0.4304\n",
            "Epoch [88/250], Training Loss: 1.1943, Validation Loss: 2.9414, Validation Accuracy: 0.4304\n",
            "Epoch [89/250], Training Loss: 1.1223, Validation Loss: 2.8978, Validation Accuracy: 0.4441\n",
            "Epoch [90/250], Training Loss: 1.1214, Validation Loss: 2.8873, Validation Accuracy: 0.4265\n",
            "Epoch [91/250], Training Loss: 1.0702, Validation Loss: 2.9522, Validation Accuracy: 0.4343\n",
            "Epoch [92/250], Training Loss: 1.0106, Validation Loss: 3.0081, Validation Accuracy: 0.4333\n",
            "Epoch [93/250], Training Loss: 1.1134, Validation Loss: 3.1454, Validation Accuracy: 0.4225\n",
            "Epoch [94/250], Training Loss: 1.0589, Validation Loss: 3.1227, Validation Accuracy: 0.4304\n",
            "Epoch [95/250], Training Loss: 1.1292, Validation Loss: 2.9967, Validation Accuracy: 0.4137\n",
            "Epoch [96/250], Training Loss: 1.1320, Validation Loss: 3.0118, Validation Accuracy: 0.4363\n",
            "Epoch [97/250], Training Loss: 1.0566, Validation Loss: 3.4462, Validation Accuracy: 0.4186\n",
            "Epoch [98/250], Training Loss: 1.0531, Validation Loss: 3.0136, Validation Accuracy: 0.4284\n",
            "Epoch [99/250], Training Loss: 1.0840, Validation Loss: 3.0850, Validation Accuracy: 0.4471\n",
            "Epoch [100/250], Training Loss: 0.9857, Validation Loss: 3.1788, Validation Accuracy: 0.4363\n",
            "Epoch [101/250], Training Loss: 1.1002, Validation Loss: 3.2675, Validation Accuracy: 0.4176\n",
            "Epoch [102/250], Training Loss: 1.0707, Validation Loss: 3.0981, Validation Accuracy: 0.4343\n",
            "Epoch [103/250], Training Loss: 1.0253, Validation Loss: 3.1641, Validation Accuracy: 0.4294\n",
            "Epoch [104/250], Training Loss: 0.9825, Validation Loss: 3.0970, Validation Accuracy: 0.4167\n",
            "Epoch [105/250], Training Loss: 1.1305, Validation Loss: 3.0104, Validation Accuracy: 0.4382\n",
            "Epoch [106/250], Training Loss: 1.0616, Validation Loss: 3.0688, Validation Accuracy: 0.4500\n",
            "Epoch [107/250], Training Loss: 1.0790, Validation Loss: 3.1995, Validation Accuracy: 0.4147\n",
            "Epoch [108/250], Training Loss: 0.9721, Validation Loss: 3.0045, Validation Accuracy: 0.4627\n",
            "Epoch [109/250], Training Loss: 1.1130, Validation Loss: 3.0100, Validation Accuracy: 0.4373\n",
            "Epoch [110/250], Training Loss: 1.0738, Validation Loss: 2.9583, Validation Accuracy: 0.4373\n",
            "Epoch [111/250], Training Loss: 0.9424, Validation Loss: 3.0997, Validation Accuracy: 0.4265\n",
            "Epoch [112/250], Training Loss: 1.0418, Validation Loss: 3.1952, Validation Accuracy: 0.4392\n",
            "Epoch [113/250], Training Loss: 1.0550, Validation Loss: 3.0605, Validation Accuracy: 0.4333\n",
            "Epoch [114/250], Training Loss: 0.9240, Validation Loss: 3.0552, Validation Accuracy: 0.4382\n",
            "Epoch [115/250], Training Loss: 0.8575, Validation Loss: 3.2376, Validation Accuracy: 0.4255\n",
            "Epoch [116/250], Training Loss: 0.9526, Validation Loss: 3.3181, Validation Accuracy: 0.4304\n",
            "Epoch [117/250], Training Loss: 0.9327, Validation Loss: 3.1292, Validation Accuracy: 0.4206\n",
            "Epoch [118/250], Training Loss: 0.9820, Validation Loss: 3.1606, Validation Accuracy: 0.4314\n",
            "Epoch [119/250], Training Loss: 0.9695, Validation Loss: 3.1644, Validation Accuracy: 0.4294\n",
            "Epoch [120/250], Training Loss: 0.9341, Validation Loss: 3.1988, Validation Accuracy: 0.4304\n",
            "Epoch [121/250], Training Loss: 0.9711, Validation Loss: 3.1495, Validation Accuracy: 0.4324\n",
            "Epoch [122/250], Training Loss: 0.9504, Validation Loss: 3.1468, Validation Accuracy: 0.4441\n",
            "Epoch [123/250], Training Loss: 0.9204, Validation Loss: 3.3393, Validation Accuracy: 0.4314\n",
            "Epoch [124/250], Training Loss: 0.8939, Validation Loss: 3.1963, Validation Accuracy: 0.4520\n",
            "Epoch [125/250], Training Loss: 0.8885, Validation Loss: 3.1633, Validation Accuracy: 0.4480\n",
            "Epoch [126/250], Training Loss: 0.9022, Validation Loss: 3.3755, Validation Accuracy: 0.4167\n",
            "Epoch [127/250], Training Loss: 0.9680, Validation Loss: 3.2343, Validation Accuracy: 0.4559\n",
            "Epoch [128/250], Training Loss: 0.9040, Validation Loss: 3.1448, Validation Accuracy: 0.4431\n",
            "Epoch [129/250], Training Loss: 0.9570, Validation Loss: 3.2475, Validation Accuracy: 0.4431\n",
            "Epoch [130/250], Training Loss: 0.9615, Validation Loss: 3.2171, Validation Accuracy: 0.4333\n",
            "Epoch [131/250], Training Loss: 0.8958, Validation Loss: 3.1964, Validation Accuracy: 0.4471\n",
            "Epoch [132/250], Training Loss: 0.8769, Validation Loss: 3.2391, Validation Accuracy: 0.4235\n",
            "Epoch [133/250], Training Loss: 0.9161, Validation Loss: 3.0914, Validation Accuracy: 0.4373\n",
            "Epoch [134/250], Training Loss: 0.8572, Validation Loss: 3.3002, Validation Accuracy: 0.4539\n",
            "Epoch [135/250], Training Loss: 0.8558, Validation Loss: 3.2747, Validation Accuracy: 0.4294\n",
            "Epoch [136/250], Training Loss: 0.9888, Validation Loss: 3.1720, Validation Accuracy: 0.4392\n",
            "Epoch [137/250], Training Loss: 0.8910, Validation Loss: 3.2570, Validation Accuracy: 0.4343\n",
            "Epoch [138/250], Training Loss: 0.9069, Validation Loss: 3.2512, Validation Accuracy: 0.4294\n",
            "Epoch [139/250], Training Loss: 0.9528, Validation Loss: 3.2879, Validation Accuracy: 0.4451\n",
            "Epoch [140/250], Training Loss: 0.8263, Validation Loss: 3.3909, Validation Accuracy: 0.4314\n",
            "Epoch [141/250], Training Loss: 0.9059, Validation Loss: 3.3842, Validation Accuracy: 0.4314\n",
            "Epoch [142/250], Training Loss: 0.8664, Validation Loss: 3.3981, Validation Accuracy: 0.4294\n",
            "Epoch [143/250], Training Loss: 0.7417, Validation Loss: 3.4145, Validation Accuracy: 0.4363\n",
            "Epoch [144/250], Training Loss: 0.8224, Validation Loss: 3.3572, Validation Accuracy: 0.4412\n",
            "Epoch [145/250], Training Loss: 0.8939, Validation Loss: 3.1004, Validation Accuracy: 0.4588\n",
            "Epoch [146/250], Training Loss: 0.8301, Validation Loss: 3.2483, Validation Accuracy: 0.4539\n",
            "Epoch [147/250], Training Loss: 0.8394, Validation Loss: 3.4601, Validation Accuracy: 0.4422\n",
            "Epoch [148/250], Training Loss: 0.8665, Validation Loss: 3.2223, Validation Accuracy: 0.4441\n",
            "Epoch [149/250], Training Loss: 0.8880, Validation Loss: 3.2890, Validation Accuracy: 0.4588\n",
            "Epoch [150/250], Training Loss: 0.8178, Validation Loss: 3.2930, Validation Accuracy: 0.4431\n",
            "Epoch [151/250], Training Loss: 0.8497, Validation Loss: 3.2730, Validation Accuracy: 0.4343\n",
            "Epoch [152/250], Training Loss: 0.7814, Validation Loss: 3.3146, Validation Accuracy: 0.4647\n",
            "Epoch [153/250], Training Loss: 0.8349, Validation Loss: 3.3773, Validation Accuracy: 0.4461\n",
            "Epoch [154/250], Training Loss: 0.8364, Validation Loss: 3.5257, Validation Accuracy: 0.4333\n",
            "Epoch [155/250], Training Loss: 0.8995, Validation Loss: 3.3852, Validation Accuracy: 0.4569\n",
            "Epoch [156/250], Training Loss: 0.9004, Validation Loss: 3.3762, Validation Accuracy: 0.4539\n",
            "Epoch [157/250], Training Loss: 0.8966, Validation Loss: 3.1715, Validation Accuracy: 0.4422\n",
            "Epoch [158/250], Training Loss: 0.9148, Validation Loss: 3.2595, Validation Accuracy: 0.4569\n",
            "Epoch [159/250], Training Loss: 0.7456, Validation Loss: 3.2615, Validation Accuracy: 0.4402\n",
            "Epoch [160/250], Training Loss: 0.8906, Validation Loss: 3.3355, Validation Accuracy: 0.4343\n",
            "Epoch [161/250], Training Loss: 0.8720, Validation Loss: 3.3828, Validation Accuracy: 0.4490\n",
            "Epoch [162/250], Training Loss: 0.6974, Validation Loss: 3.4379, Validation Accuracy: 0.4588\n",
            "Epoch [163/250], Training Loss: 0.8403, Validation Loss: 3.2538, Validation Accuracy: 0.4431\n",
            "Epoch [164/250], Training Loss: 0.8764, Validation Loss: 3.2725, Validation Accuracy: 0.4559\n",
            "Epoch [165/250], Training Loss: 0.8740, Validation Loss: 3.3924, Validation Accuracy: 0.4529\n",
            "Epoch [166/250], Training Loss: 0.8226, Validation Loss: 3.4495, Validation Accuracy: 0.4353\n",
            "Epoch [167/250], Training Loss: 0.8262, Validation Loss: 3.3462, Validation Accuracy: 0.4324\n",
            "Epoch [168/250], Training Loss: 0.8462, Validation Loss: 3.1416, Validation Accuracy: 0.4569\n",
            "Epoch [169/250], Training Loss: 0.8188, Validation Loss: 3.4011, Validation Accuracy: 0.4265\n",
            "Epoch [170/250], Training Loss: 0.8191, Validation Loss: 3.3087, Validation Accuracy: 0.4569\n",
            "Epoch [171/250], Training Loss: 0.8428, Validation Loss: 3.2161, Validation Accuracy: 0.4520\n",
            "Epoch [172/250], Training Loss: 0.8098, Validation Loss: 3.4438, Validation Accuracy: 0.4422\n",
            "Epoch [173/250], Training Loss: 0.8526, Validation Loss: 3.2833, Validation Accuracy: 0.4588\n",
            "Epoch [174/250], Training Loss: 0.8558, Validation Loss: 3.2668, Validation Accuracy: 0.4647\n",
            "Epoch [175/250], Training Loss: 0.7625, Validation Loss: 3.2636, Validation Accuracy: 0.4578\n",
            "Epoch [176/250], Training Loss: 0.7652, Validation Loss: 3.4529, Validation Accuracy: 0.4441\n",
            "Epoch [177/250], Training Loss: 0.6627, Validation Loss: 3.5087, Validation Accuracy: 0.4480\n",
            "Epoch [178/250], Training Loss: 0.7528, Validation Loss: 3.3037, Validation Accuracy: 0.4520\n",
            "Epoch [179/250], Training Loss: 0.7507, Validation Loss: 3.4956, Validation Accuracy: 0.4569\n",
            "Epoch [180/250], Training Loss: 0.7443, Validation Loss: 3.5002, Validation Accuracy: 0.4657\n",
            "Epoch [181/250], Training Loss: 0.7589, Validation Loss: 3.3227, Validation Accuracy: 0.4578\n",
            "Epoch [182/250], Training Loss: 0.7458, Validation Loss: 3.5163, Validation Accuracy: 0.4412\n",
            "Epoch [183/250], Training Loss: 0.8552, Validation Loss: 3.4850, Validation Accuracy: 0.4490\n",
            "Epoch [184/250], Training Loss: 0.7357, Validation Loss: 3.5825, Validation Accuracy: 0.4549\n",
            "Epoch [185/250], Training Loss: 0.7912, Validation Loss: 3.3242, Validation Accuracy: 0.4490\n",
            "Epoch [186/250], Training Loss: 0.7046, Validation Loss: 3.5609, Validation Accuracy: 0.4520\n",
            "Epoch [187/250], Training Loss: 0.7130, Validation Loss: 3.4944, Validation Accuracy: 0.4627\n",
            "Epoch [188/250], Training Loss: 0.7427, Validation Loss: 3.6866, Validation Accuracy: 0.4363\n",
            "Epoch [189/250], Training Loss: 0.7195, Validation Loss: 3.6234, Validation Accuracy: 0.4471\n",
            "Epoch [190/250], Training Loss: 0.6602, Validation Loss: 3.2944, Validation Accuracy: 0.4598\n",
            "Epoch [191/250], Training Loss: 0.7338, Validation Loss: 3.7482, Validation Accuracy: 0.4441\n",
            "Epoch [192/250], Training Loss: 0.7208, Validation Loss: 3.7173, Validation Accuracy: 0.4245\n",
            "Epoch [193/250], Training Loss: 0.8103, Validation Loss: 3.4296, Validation Accuracy: 0.4363\n",
            "Epoch [194/250], Training Loss: 0.7495, Validation Loss: 3.7387, Validation Accuracy: 0.4549\n",
            "Epoch [195/250], Training Loss: 0.8176, Validation Loss: 3.4957, Validation Accuracy: 0.4500\n",
            "Epoch [196/250], Training Loss: 0.7472, Validation Loss: 3.5552, Validation Accuracy: 0.4520\n",
            "Epoch [197/250], Training Loss: 0.7101, Validation Loss: 3.4455, Validation Accuracy: 0.4471\n",
            "Epoch [198/250], Training Loss: 0.7251, Validation Loss: 3.5773, Validation Accuracy: 0.4500\n",
            "Epoch [199/250], Training Loss: 0.6678, Validation Loss: 3.5628, Validation Accuracy: 0.4549\n",
            "Epoch [200/250], Training Loss: 0.7478, Validation Loss: 3.5314, Validation Accuracy: 0.4441\n",
            "Epoch [201/250], Training Loss: 0.8137, Validation Loss: 3.6417, Validation Accuracy: 0.4549\n",
            "Epoch [202/250], Training Loss: 0.7418, Validation Loss: 3.5229, Validation Accuracy: 0.4569\n",
            "Epoch [203/250], Training Loss: 0.7411, Validation Loss: 3.6737, Validation Accuracy: 0.4490\n",
            "Epoch [204/250], Training Loss: 0.7704, Validation Loss: 3.3503, Validation Accuracy: 0.4647\n",
            "Epoch [205/250], Training Loss: 0.7215, Validation Loss: 3.6452, Validation Accuracy: 0.4451\n",
            "Epoch [206/250], Training Loss: 0.7331, Validation Loss: 3.6840, Validation Accuracy: 0.4618\n",
            "Epoch [207/250], Training Loss: 0.7714, Validation Loss: 3.4356, Validation Accuracy: 0.4529\n",
            "Epoch [208/250], Training Loss: 0.7207, Validation Loss: 3.4542, Validation Accuracy: 0.4392\n",
            "Epoch [209/250], Training Loss: 0.7650, Validation Loss: 3.5973, Validation Accuracy: 0.4382\n",
            "Epoch [210/250], Training Loss: 0.6766, Validation Loss: 3.4993, Validation Accuracy: 0.4618\n",
            "Epoch [211/250], Training Loss: 0.7782, Validation Loss: 3.6076, Validation Accuracy: 0.4324\n",
            "Epoch [212/250], Training Loss: 0.7397, Validation Loss: 3.5353, Validation Accuracy: 0.4529\n",
            "Epoch [213/250], Training Loss: 0.6610, Validation Loss: 3.3368, Validation Accuracy: 0.4480\n",
            "Epoch [214/250], Training Loss: 0.6875, Validation Loss: 3.5522, Validation Accuracy: 0.4402\n",
            "Epoch [215/250], Training Loss: 0.6712, Validation Loss: 3.3326, Validation Accuracy: 0.4618\n",
            "Epoch [216/250], Training Loss: 0.6933, Validation Loss: 3.7272, Validation Accuracy: 0.4431\n",
            "Epoch [217/250], Training Loss: 0.7929, Validation Loss: 3.5705, Validation Accuracy: 0.4441\n",
            "Epoch [218/250], Training Loss: 0.6955, Validation Loss: 3.7820, Validation Accuracy: 0.4520\n",
            "Epoch [219/250], Training Loss: 0.7168, Validation Loss: 3.6002, Validation Accuracy: 0.4627\n",
            "Epoch [220/250], Training Loss: 0.7346, Validation Loss: 3.5318, Validation Accuracy: 0.4627\n",
            "Epoch [221/250], Training Loss: 0.6256, Validation Loss: 3.8969, Validation Accuracy: 0.4598\n",
            "Epoch [222/250], Training Loss: 0.7175, Validation Loss: 4.0123, Validation Accuracy: 0.4520\n",
            "Epoch [223/250], Training Loss: 0.7481, Validation Loss: 3.6625, Validation Accuracy: 0.4510\n",
            "Epoch [224/250], Training Loss: 0.6895, Validation Loss: 3.6136, Validation Accuracy: 0.4618\n",
            "Epoch [225/250], Training Loss: 0.6903, Validation Loss: 3.8906, Validation Accuracy: 0.4569\n",
            "Epoch [226/250], Training Loss: 0.7381, Validation Loss: 3.6943, Validation Accuracy: 0.4500\n",
            "Epoch [227/250], Training Loss: 0.6460, Validation Loss: 3.4803, Validation Accuracy: 0.4500\n",
            "Epoch [228/250], Training Loss: 0.6516, Validation Loss: 3.5235, Validation Accuracy: 0.4647\n",
            "Epoch [229/250], Training Loss: 0.7402, Validation Loss: 3.4414, Validation Accuracy: 0.4196\n",
            "Epoch [230/250], Training Loss: 0.6087, Validation Loss: 3.4547, Validation Accuracy: 0.4608\n",
            "Epoch [231/250], Training Loss: 0.5907, Validation Loss: 3.7598, Validation Accuracy: 0.4510\n",
            "Epoch [232/250], Training Loss: 0.7377, Validation Loss: 3.6299, Validation Accuracy: 0.4618\n",
            "Epoch [233/250], Training Loss: 0.6704, Validation Loss: 3.6846, Validation Accuracy: 0.4529\n",
            "Epoch [234/250], Training Loss: 0.6494, Validation Loss: 3.6116, Validation Accuracy: 0.4745\n",
            "Epoch [235/250], Training Loss: 0.6851, Validation Loss: 3.5254, Validation Accuracy: 0.4696\n",
            "Epoch [236/250], Training Loss: 0.6845, Validation Loss: 3.4975, Validation Accuracy: 0.4529\n",
            "Epoch [237/250], Training Loss: 0.6998, Validation Loss: 3.5427, Validation Accuracy: 0.4676\n",
            "Epoch [238/250], Training Loss: 0.6245, Validation Loss: 3.7999, Validation Accuracy: 0.4549\n",
            "Epoch [239/250], Training Loss: 0.6827, Validation Loss: 3.6700, Validation Accuracy: 0.4765\n",
            "Epoch [240/250], Training Loss: 0.7357, Validation Loss: 3.6419, Validation Accuracy: 0.4686\n",
            "Epoch [241/250], Training Loss: 0.6695, Validation Loss: 3.4203, Validation Accuracy: 0.4627\n",
            "Epoch [242/250], Training Loss: 0.5761, Validation Loss: 3.6719, Validation Accuracy: 0.4520\n",
            "Epoch [243/250], Training Loss: 0.5522, Validation Loss: 3.6197, Validation Accuracy: 0.4618\n",
            "Epoch [244/250], Training Loss: 0.5847, Validation Loss: 3.7779, Validation Accuracy: 0.4588\n",
            "Epoch [245/250], Training Loss: 0.6539, Validation Loss: 3.7015, Validation Accuracy: 0.4510\n",
            "Epoch [246/250], Training Loss: 0.6915, Validation Loss: 3.8312, Validation Accuracy: 0.4441\n",
            "Epoch [247/250], Training Loss: 0.6819, Validation Loss: 3.8291, Validation Accuracy: 0.4333\n",
            "Epoch [248/250], Training Loss: 0.6953, Validation Loss: 3.6486, Validation Accuracy: 0.4510\n",
            "Epoch [249/250], Training Loss: 0.6240, Validation Loss: 3.8915, Validation Accuracy: 0.4490\n",
            "Epoch [250/250], Training Loss: 0.6128, Validation Loss: 3.6771, Validation Accuracy: 0.4451\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import Flowers102\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define transforms for data augmentation and normalization\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(128),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(144),\n",
        "    transforms.CenterCrop(128),\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the dataset with train/val/test splits\n",
        "train_dataset = Flowers102(root='./data', split='train', transform=train_transform, download=True)\n",
        "val_dataset = Flowers102(root='./data', split='val', transform=val_transform, download=True)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Define data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "class CNN_NN(nn.Module):\n",
        "    def __init__(self, num_classes=102):\n",
        "        super(CNN_NN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        # Initialize the size of the fully connected layer based on the sample input\n",
        "        self._to_linear = None\n",
        "        self.convs = nn.Sequential(\n",
        "            self.conv1,\n",
        "            nn.ReLU(),\n",
        "            self.pool,\n",
        "            self.conv2,\n",
        "            nn.ReLU(),\n",
        "            self.pool,\n",
        "            self.conv3,\n",
        "            nn.ReLU(),\n",
        "            self.pool\n",
        "        )\n",
        "        self._initialize_linear_layer()\n",
        "\n",
        "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def _initialize_linear_layer(self):\n",
        "        # Create a dummy input tensor to calculate the output size after conv layers\n",
        "        x = torch.randn(1, 3, 128, 128)\n",
        "        x = self.convs(x)\n",
        "        self._to_linear = x.view(1, -1).shape[1]\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor while preserving the batch size\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Define the device (GPU or CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyperparameters\n",
        "num_classes = 102  # Number of output classes\n",
        "learning_rate = 0.001\n",
        "num_epochs = 250\n",
        "\n",
        "# Initialize the model\n",
        "model = CNN_NN(num_classes=num_classes).to(device)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    # Calculate average loss for the epoch\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Calculate average validation loss and accuracy\n",
        "    val_loss = val_loss / len(val_loader.dataset)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "          f'Training Loss: {epoch_loss:.4f}, '\n",
        "          f'Validation Loss: {val_loss:.4f}, '\n",
        "          f'Validation Accuracy: {accuracy:.4f}')\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nQ6iBrY0yS9",
        "outputId": "7e817c68-d9c6-4db6-9c97-ed3f496ee789"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to data/flowers-102/102flowers.tgz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 344862509/344862509 [00:16<00:00, 21503688.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/flowers-102/102flowers.tgz to data/flowers-102\n",
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to data/flowers-102/imagelabels.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 502/502 [00:00<00:00, 464082.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to data/flowers-102/setid.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 14989/14989 [00:00<00:00, 12439339.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/300], Training Loss: 4.6333, Validation Loss: 4.5878, Validation Accuracy: 0.0088\n",
            "Epoch [2/300], Training Loss: 4.5151, Validation Loss: 4.3199, Validation Accuracy: 0.0196\n",
            "Epoch [3/300], Training Loss: 4.2762, Validation Loss: 4.0709, Validation Accuracy: 0.0520\n",
            "Epoch [4/300], Training Loss: 4.0982, Validation Loss: 3.8989, Validation Accuracy: 0.0716\n",
            "Epoch [5/300], Training Loss: 3.9286, Validation Loss: 3.8706, Validation Accuracy: 0.0598\n",
            "Epoch [6/300], Training Loss: 3.8469, Validation Loss: 3.7347, Validation Accuracy: 0.1069\n",
            "Epoch [7/300], Training Loss: 3.7759, Validation Loss: 3.6374, Validation Accuracy: 0.1245\n",
            "Epoch [8/300], Training Loss: 3.7178, Validation Loss: 3.5575, Validation Accuracy: 0.1373\n",
            "Epoch [9/300], Training Loss: 3.5871, Validation Loss: 3.4741, Validation Accuracy: 0.1618\n",
            "Epoch [10/300], Training Loss: 3.5477, Validation Loss: 3.3836, Validation Accuracy: 0.1971\n",
            "Epoch [11/300], Training Loss: 3.4119, Validation Loss: 3.3234, Validation Accuracy: 0.1804\n",
            "Epoch [12/300], Training Loss: 3.3554, Validation Loss: 3.2938, Validation Accuracy: 0.2020\n",
            "Epoch [13/300], Training Loss: 3.3588, Validation Loss: 3.2591, Validation Accuracy: 0.2029\n",
            "Epoch [14/300], Training Loss: 3.2338, Validation Loss: 3.1450, Validation Accuracy: 0.2412\n",
            "Epoch [15/300], Training Loss: 3.1818, Validation Loss: 3.1174, Validation Accuracy: 0.2412\n",
            "Epoch [16/300], Training Loss: 3.0855, Validation Loss: 3.0859, Validation Accuracy: 0.2549\n",
            "Epoch [17/300], Training Loss: 3.1409, Validation Loss: 3.0722, Validation Accuracy: 0.2353\n",
            "Epoch [18/300], Training Loss: 2.9765, Validation Loss: 2.9967, Validation Accuracy: 0.2578\n",
            "Epoch [19/300], Training Loss: 3.0040, Validation Loss: 3.0039, Validation Accuracy: 0.2725\n",
            "Epoch [20/300], Training Loss: 2.9061, Validation Loss: 3.0404, Validation Accuracy: 0.2667\n",
            "Epoch [21/300], Training Loss: 2.8805, Validation Loss: 2.9621, Validation Accuracy: 0.2696\n",
            "Epoch [22/300], Training Loss: 2.8096, Validation Loss: 2.9073, Validation Accuracy: 0.2824\n",
            "Epoch [23/300], Training Loss: 2.7604, Validation Loss: 2.8724, Validation Accuracy: 0.2755\n",
            "Epoch [24/300], Training Loss: 2.6659, Validation Loss: 2.8169, Validation Accuracy: 0.3324\n",
            "Epoch [25/300], Training Loss: 2.7045, Validation Loss: 2.8379, Validation Accuracy: 0.2961\n",
            "Epoch [26/300], Training Loss: 2.6643, Validation Loss: 2.7911, Validation Accuracy: 0.3118\n",
            "Epoch [27/300], Training Loss: 2.5756, Validation Loss: 2.8090, Validation Accuracy: 0.3118\n",
            "Epoch [28/300], Training Loss: 2.5890, Validation Loss: 2.7551, Validation Accuracy: 0.3373\n",
            "Epoch [29/300], Training Loss: 2.4893, Validation Loss: 2.7018, Validation Accuracy: 0.3314\n",
            "Epoch [30/300], Training Loss: 2.4271, Validation Loss: 2.7017, Validation Accuracy: 0.3529\n",
            "Epoch [31/300], Training Loss: 2.4748, Validation Loss: 2.6877, Validation Accuracy: 0.3431\n",
            "Epoch [32/300], Training Loss: 2.3725, Validation Loss: 2.7001, Validation Accuracy: 0.3431\n",
            "Epoch [33/300], Training Loss: 2.3982, Validation Loss: 2.6637, Validation Accuracy: 0.3549\n",
            "Epoch [34/300], Training Loss: 2.2738, Validation Loss: 2.6954, Validation Accuracy: 0.3539\n",
            "Epoch [35/300], Training Loss: 2.2324, Validation Loss: 2.6634, Validation Accuracy: 0.3549\n",
            "Epoch [36/300], Training Loss: 2.1974, Validation Loss: 2.7352, Validation Accuracy: 0.3392\n",
            "Epoch [37/300], Training Loss: 2.1959, Validation Loss: 2.7042, Validation Accuracy: 0.3647\n",
            "Epoch [38/300], Training Loss: 2.2013, Validation Loss: 2.6959, Validation Accuracy: 0.3363\n",
            "Epoch [39/300], Training Loss: 2.1252, Validation Loss: 2.6551, Validation Accuracy: 0.3441\n",
            "Epoch [40/300], Training Loss: 2.1037, Validation Loss: 2.6463, Validation Accuracy: 0.3637\n",
            "Epoch [41/300], Training Loss: 2.1484, Validation Loss: 2.6962, Validation Accuracy: 0.3696\n",
            "Epoch [42/300], Training Loss: 2.0418, Validation Loss: 2.6318, Validation Accuracy: 0.3765\n",
            "Epoch [43/300], Training Loss: 2.0078, Validation Loss: 2.6375, Validation Accuracy: 0.4039\n",
            "Epoch [44/300], Training Loss: 1.9057, Validation Loss: 2.6171, Validation Accuracy: 0.3843\n",
            "Epoch [45/300], Training Loss: 1.9929, Validation Loss: 2.6550, Validation Accuracy: 0.3804\n",
            "Epoch [46/300], Training Loss: 1.8620, Validation Loss: 2.6646, Validation Accuracy: 0.3912\n",
            "Epoch [47/300], Training Loss: 1.9349, Validation Loss: 2.6838, Validation Accuracy: 0.3902\n",
            "Epoch [48/300], Training Loss: 1.8630, Validation Loss: 2.6839, Validation Accuracy: 0.3755\n",
            "Epoch [49/300], Training Loss: 1.8760, Validation Loss: 2.6576, Validation Accuracy: 0.3804\n",
            "Epoch [50/300], Training Loss: 1.8856, Validation Loss: 2.6247, Validation Accuracy: 0.3951\n",
            "Epoch [51/300], Training Loss: 1.8663, Validation Loss: 2.6012, Validation Accuracy: 0.3931\n",
            "Epoch [52/300], Training Loss: 1.7513, Validation Loss: 2.7369, Validation Accuracy: 0.3902\n",
            "Epoch [53/300], Training Loss: 1.7741, Validation Loss: 2.6385, Validation Accuracy: 0.4010\n",
            "Epoch [54/300], Training Loss: 1.7091, Validation Loss: 2.5980, Validation Accuracy: 0.4078\n",
            "Epoch [55/300], Training Loss: 1.6842, Validation Loss: 2.7232, Validation Accuracy: 0.4098\n",
            "Epoch [56/300], Training Loss: 1.7502, Validation Loss: 2.6410, Validation Accuracy: 0.4088\n",
            "Epoch [57/300], Training Loss: 1.5971, Validation Loss: 2.6575, Validation Accuracy: 0.4020\n",
            "Epoch [58/300], Training Loss: 1.6096, Validation Loss: 2.7766, Validation Accuracy: 0.4118\n",
            "Epoch [59/300], Training Loss: 1.5672, Validation Loss: 2.7420, Validation Accuracy: 0.3971\n",
            "Epoch [60/300], Training Loss: 1.6237, Validation Loss: 2.6650, Validation Accuracy: 0.3990\n",
            "Epoch [61/300], Training Loss: 1.6365, Validation Loss: 2.7562, Validation Accuracy: 0.4059\n",
            "Epoch [62/300], Training Loss: 1.5399, Validation Loss: 2.6759, Validation Accuracy: 0.4137\n",
            "Epoch [63/300], Training Loss: 1.5135, Validation Loss: 2.8035, Validation Accuracy: 0.4147\n",
            "Epoch [64/300], Training Loss: 1.6073, Validation Loss: 2.6954, Validation Accuracy: 0.4275\n",
            "Epoch [65/300], Training Loss: 1.4056, Validation Loss: 2.7608, Validation Accuracy: 0.4245\n",
            "Epoch [66/300], Training Loss: 1.4951, Validation Loss: 2.7746, Validation Accuracy: 0.4108\n",
            "Epoch [67/300], Training Loss: 1.5794, Validation Loss: 2.7833, Validation Accuracy: 0.4049\n",
            "Epoch [68/300], Training Loss: 1.4340, Validation Loss: 2.8870, Validation Accuracy: 0.4088\n",
            "Epoch [69/300], Training Loss: 1.5642, Validation Loss: 2.7299, Validation Accuracy: 0.4098\n",
            "Epoch [70/300], Training Loss: 1.4247, Validation Loss: 2.8060, Validation Accuracy: 0.4157\n",
            "Epoch [71/300], Training Loss: 1.4503, Validation Loss: 2.7122, Validation Accuracy: 0.4304\n",
            "Epoch [72/300], Training Loss: 1.5373, Validation Loss: 2.7481, Validation Accuracy: 0.4010\n",
            "Epoch [73/300], Training Loss: 1.3876, Validation Loss: 2.7739, Validation Accuracy: 0.4275\n",
            "Epoch [74/300], Training Loss: 1.4065, Validation Loss: 2.9464, Validation Accuracy: 0.4020\n",
            "Epoch [75/300], Training Loss: 1.3915, Validation Loss: 2.7189, Validation Accuracy: 0.4284\n",
            "Epoch [76/300], Training Loss: 1.3950, Validation Loss: 3.0237, Validation Accuracy: 0.3980\n",
            "Epoch [77/300], Training Loss: 1.3768, Validation Loss: 2.8100, Validation Accuracy: 0.4225\n",
            "Epoch [78/300], Training Loss: 1.3745, Validation Loss: 2.7946, Validation Accuracy: 0.4265\n",
            "Epoch [79/300], Training Loss: 1.3671, Validation Loss: 2.7756, Validation Accuracy: 0.4186\n",
            "Epoch [80/300], Training Loss: 1.2937, Validation Loss: 2.9081, Validation Accuracy: 0.4255\n",
            "Epoch [81/300], Training Loss: 1.2718, Validation Loss: 2.7817, Validation Accuracy: 0.4343\n",
            "Epoch [82/300], Training Loss: 1.2337, Validation Loss: 2.9229, Validation Accuracy: 0.4304\n",
            "Epoch [83/300], Training Loss: 1.3191, Validation Loss: 2.8285, Validation Accuracy: 0.4343\n",
            "Epoch [84/300], Training Loss: 1.3038, Validation Loss: 2.8672, Validation Accuracy: 0.4304\n",
            "Epoch [85/300], Training Loss: 1.3164, Validation Loss: 2.6855, Validation Accuracy: 0.4412\n",
            "Epoch [86/300], Training Loss: 1.3013, Validation Loss: 2.8497, Validation Accuracy: 0.4490\n",
            "Epoch [87/300], Training Loss: 1.2445, Validation Loss: 2.8314, Validation Accuracy: 0.4314\n",
            "Epoch [88/300], Training Loss: 1.1987, Validation Loss: 2.7967, Validation Accuracy: 0.4382\n",
            "Epoch [89/300], Training Loss: 1.1940, Validation Loss: 2.8239, Validation Accuracy: 0.4255\n",
            "Epoch [90/300], Training Loss: 1.2444, Validation Loss: 2.8425, Validation Accuracy: 0.4235\n",
            "Epoch [91/300], Training Loss: 1.3483, Validation Loss: 2.8616, Validation Accuracy: 0.4304\n",
            "Epoch [92/300], Training Loss: 1.2355, Validation Loss: 2.8386, Validation Accuracy: 0.4324\n",
            "Epoch [93/300], Training Loss: 1.2179, Validation Loss: 2.9766, Validation Accuracy: 0.4392\n",
            "Epoch [94/300], Training Loss: 1.1374, Validation Loss: 2.9107, Validation Accuracy: 0.4402\n",
            "Epoch [95/300], Training Loss: 1.1222, Validation Loss: 2.9542, Validation Accuracy: 0.4461\n",
            "Epoch [96/300], Training Loss: 1.1718, Validation Loss: 2.9670, Validation Accuracy: 0.4206\n",
            "Epoch [97/300], Training Loss: 1.2171, Validation Loss: 2.8458, Validation Accuracy: 0.4578\n",
            "Epoch [98/300], Training Loss: 1.1744, Validation Loss: 2.9668, Validation Accuracy: 0.4510\n",
            "Epoch [99/300], Training Loss: 1.1382, Validation Loss: 2.8898, Validation Accuracy: 0.4412\n",
            "Epoch [100/300], Training Loss: 1.1895, Validation Loss: 2.9335, Validation Accuracy: 0.4529\n",
            "Epoch [101/300], Training Loss: 1.1345, Validation Loss: 2.9290, Validation Accuracy: 0.4353\n",
            "Epoch [102/300], Training Loss: 1.1279, Validation Loss: 2.9354, Validation Accuracy: 0.4333\n",
            "Epoch [103/300], Training Loss: 1.0989, Validation Loss: 2.8620, Validation Accuracy: 0.4294\n",
            "Epoch [104/300], Training Loss: 1.0784, Validation Loss: 3.0200, Validation Accuracy: 0.4588\n",
            "Epoch [105/300], Training Loss: 1.1121, Validation Loss: 2.9489, Validation Accuracy: 0.4304\n",
            "Epoch [106/300], Training Loss: 1.0919, Validation Loss: 2.8364, Validation Accuracy: 0.4343\n",
            "Epoch [107/300], Training Loss: 1.1703, Validation Loss: 2.9032, Validation Accuracy: 0.4451\n",
            "Epoch [108/300], Training Loss: 1.0851, Validation Loss: 2.9442, Validation Accuracy: 0.4471\n",
            "Epoch [109/300], Training Loss: 1.0185, Validation Loss: 2.9695, Validation Accuracy: 0.4382\n",
            "Epoch [110/300], Training Loss: 1.1106, Validation Loss: 2.7273, Validation Accuracy: 0.4333\n",
            "Epoch [111/300], Training Loss: 1.0650, Validation Loss: 3.0477, Validation Accuracy: 0.4363\n",
            "Epoch [112/300], Training Loss: 1.0127, Validation Loss: 2.8897, Validation Accuracy: 0.4431\n",
            "Epoch [113/300], Training Loss: 1.0917, Validation Loss: 2.9727, Validation Accuracy: 0.4402\n",
            "Epoch [114/300], Training Loss: 1.1010, Validation Loss: 2.9800, Validation Accuracy: 0.4265\n",
            "Epoch [115/300], Training Loss: 1.0947, Validation Loss: 3.0533, Validation Accuracy: 0.4284\n",
            "Epoch [116/300], Training Loss: 1.0078, Validation Loss: 3.2363, Validation Accuracy: 0.4255\n",
            "Epoch [117/300], Training Loss: 0.9514, Validation Loss: 3.0460, Validation Accuracy: 0.4353\n",
            "Epoch [118/300], Training Loss: 1.0598, Validation Loss: 2.9597, Validation Accuracy: 0.4363\n",
            "Epoch [119/300], Training Loss: 1.0486, Validation Loss: 2.9734, Validation Accuracy: 0.4618\n",
            "Epoch [120/300], Training Loss: 1.0282, Validation Loss: 2.9700, Validation Accuracy: 0.4392\n",
            "Epoch [121/300], Training Loss: 1.0596, Validation Loss: 2.8948, Validation Accuracy: 0.4490\n",
            "Epoch [122/300], Training Loss: 1.0448, Validation Loss: 2.9845, Validation Accuracy: 0.4500\n",
            "Epoch [123/300], Training Loss: 1.1081, Validation Loss: 3.0441, Validation Accuracy: 0.4529\n",
            "Epoch [124/300], Training Loss: 1.0838, Validation Loss: 2.9915, Validation Accuracy: 0.4539\n",
            "Epoch [125/300], Training Loss: 1.0405, Validation Loss: 3.1537, Validation Accuracy: 0.4402\n",
            "Epoch [126/300], Training Loss: 0.9106, Validation Loss: 3.0161, Validation Accuracy: 0.4588\n",
            "Epoch [127/300], Training Loss: 0.8624, Validation Loss: 3.1665, Validation Accuracy: 0.4265\n",
            "Epoch [128/300], Training Loss: 0.9405, Validation Loss: 3.3362, Validation Accuracy: 0.4461\n",
            "Epoch [129/300], Training Loss: 0.9052, Validation Loss: 3.0175, Validation Accuracy: 0.4480\n",
            "Epoch [130/300], Training Loss: 1.0189, Validation Loss: 3.1574, Validation Accuracy: 0.4627\n",
            "Epoch [131/300], Training Loss: 1.0222, Validation Loss: 3.0854, Validation Accuracy: 0.4451\n",
            "Epoch [132/300], Training Loss: 0.9428, Validation Loss: 3.0920, Validation Accuracy: 0.4529\n",
            "Epoch [133/300], Training Loss: 0.9078, Validation Loss: 3.0234, Validation Accuracy: 0.4657\n",
            "Epoch [134/300], Training Loss: 0.8639, Validation Loss: 3.2076, Validation Accuracy: 0.4500\n",
            "Epoch [135/300], Training Loss: 0.9301, Validation Loss: 3.0558, Validation Accuracy: 0.4647\n",
            "Epoch [136/300], Training Loss: 0.8653, Validation Loss: 3.3534, Validation Accuracy: 0.4480\n",
            "Epoch [137/300], Training Loss: 0.8570, Validation Loss: 3.1268, Validation Accuracy: 0.4578\n",
            "Epoch [138/300], Training Loss: 0.8877, Validation Loss: 3.1890, Validation Accuracy: 0.4569\n",
            "Epoch [139/300], Training Loss: 0.9128, Validation Loss: 2.9708, Validation Accuracy: 0.4461\n",
            "Epoch [140/300], Training Loss: 0.8826, Validation Loss: 3.3928, Validation Accuracy: 0.4490\n",
            "Epoch [141/300], Training Loss: 0.8892, Validation Loss: 3.2413, Validation Accuracy: 0.4598\n",
            "Epoch [142/300], Training Loss: 0.9185, Validation Loss: 3.1338, Validation Accuracy: 0.4667\n",
            "Epoch [143/300], Training Loss: 0.9676, Validation Loss: 3.1285, Validation Accuracy: 0.4451\n",
            "Epoch [144/300], Training Loss: 0.9114, Validation Loss: 3.1179, Validation Accuracy: 0.4608\n",
            "Epoch [145/300], Training Loss: 0.9019, Validation Loss: 3.2559, Validation Accuracy: 0.4353\n",
            "Epoch [146/300], Training Loss: 0.9553, Validation Loss: 3.0037, Validation Accuracy: 0.4461\n",
            "Epoch [147/300], Training Loss: 0.7750, Validation Loss: 3.5123, Validation Accuracy: 0.4500\n",
            "Epoch [148/300], Training Loss: 0.8035, Validation Loss: 3.4390, Validation Accuracy: 0.4441\n",
            "Epoch [149/300], Training Loss: 0.8460, Validation Loss: 3.0340, Validation Accuracy: 0.4667\n",
            "Epoch [150/300], Training Loss: 0.9217, Validation Loss: 3.1499, Validation Accuracy: 0.4569\n",
            "Epoch [151/300], Training Loss: 0.9142, Validation Loss: 3.1843, Validation Accuracy: 0.4392\n",
            "Epoch [152/300], Training Loss: 0.8479, Validation Loss: 3.2126, Validation Accuracy: 0.4578\n",
            "Epoch [153/300], Training Loss: 0.8691, Validation Loss: 3.4022, Validation Accuracy: 0.4490\n",
            "Epoch [154/300], Training Loss: 0.9122, Validation Loss: 3.2277, Validation Accuracy: 0.4520\n",
            "Epoch [155/300], Training Loss: 0.9263, Validation Loss: 3.2465, Validation Accuracy: 0.4569\n",
            "Epoch [156/300], Training Loss: 0.8694, Validation Loss: 3.2551, Validation Accuracy: 0.4549\n",
            "Epoch [157/300], Training Loss: 0.7903, Validation Loss: 3.3309, Validation Accuracy: 0.4490\n",
            "Epoch [158/300], Training Loss: 0.9037, Validation Loss: 3.1497, Validation Accuracy: 0.4667\n",
            "Epoch [159/300], Training Loss: 0.7762, Validation Loss: 3.3782, Validation Accuracy: 0.4539\n",
            "Epoch [160/300], Training Loss: 0.8582, Validation Loss: 3.4296, Validation Accuracy: 0.4480\n",
            "Epoch [161/300], Training Loss: 0.8357, Validation Loss: 3.2972, Validation Accuracy: 0.4716\n",
            "Epoch [162/300], Training Loss: 0.7933, Validation Loss: 3.4560, Validation Accuracy: 0.4490\n",
            "Epoch [163/300], Training Loss: 0.8386, Validation Loss: 3.2282, Validation Accuracy: 0.4333\n",
            "Epoch [164/300], Training Loss: 0.8075, Validation Loss: 3.7636, Validation Accuracy: 0.4265\n",
            "Epoch [165/300], Training Loss: 0.9106, Validation Loss: 3.3727, Validation Accuracy: 0.4314\n",
            "Epoch [166/300], Training Loss: 0.8183, Validation Loss: 3.2648, Validation Accuracy: 0.4647\n",
            "Epoch [167/300], Training Loss: 0.7499, Validation Loss: 3.4334, Validation Accuracy: 0.4588\n",
            "Epoch [168/300], Training Loss: 0.8399, Validation Loss: 3.5353, Validation Accuracy: 0.4569\n",
            "Epoch [169/300], Training Loss: 0.7620, Validation Loss: 3.2388, Validation Accuracy: 0.4490\n",
            "Epoch [170/300], Training Loss: 0.8391, Validation Loss: 3.3806, Validation Accuracy: 0.4480\n",
            "Epoch [171/300], Training Loss: 0.8448, Validation Loss: 3.5031, Validation Accuracy: 0.4480\n",
            "Epoch [172/300], Training Loss: 0.7528, Validation Loss: 3.1808, Validation Accuracy: 0.4490\n",
            "Epoch [173/300], Training Loss: 0.8870, Validation Loss: 3.2108, Validation Accuracy: 0.4490\n",
            "Epoch [174/300], Training Loss: 0.8236, Validation Loss: 3.4618, Validation Accuracy: 0.4353\n",
            "Epoch [175/300], Training Loss: 0.8944, Validation Loss: 3.4014, Validation Accuracy: 0.4461\n",
            "Epoch [176/300], Training Loss: 0.8725, Validation Loss: 3.4015, Validation Accuracy: 0.4676\n",
            "Epoch [177/300], Training Loss: 0.8528, Validation Loss: 3.1154, Validation Accuracy: 0.4559\n",
            "Epoch [178/300], Training Loss: 0.8596, Validation Loss: 3.1340, Validation Accuracy: 0.4637\n",
            "Epoch [179/300], Training Loss: 0.9260, Validation Loss: 3.3968, Validation Accuracy: 0.4520\n",
            "Epoch [180/300], Training Loss: 0.7842, Validation Loss: 3.3913, Validation Accuracy: 0.4461\n",
            "Epoch [181/300], Training Loss: 0.8009, Validation Loss: 3.2673, Validation Accuracy: 0.4578\n",
            "Epoch [182/300], Training Loss: 0.7960, Validation Loss: 3.5080, Validation Accuracy: 0.4608\n",
            "Epoch [183/300], Training Loss: 0.7471, Validation Loss: 3.1807, Validation Accuracy: 0.4647\n",
            "Epoch [184/300], Training Loss: 0.7708, Validation Loss: 3.3875, Validation Accuracy: 0.4412\n",
            "Epoch [185/300], Training Loss: 0.7971, Validation Loss: 3.3234, Validation Accuracy: 0.4500\n",
            "Epoch [186/300], Training Loss: 0.8330, Validation Loss: 3.3552, Validation Accuracy: 0.4510\n",
            "Epoch [187/300], Training Loss: 0.7867, Validation Loss: 3.1981, Validation Accuracy: 0.4647\n",
            "Epoch [188/300], Training Loss: 0.8188, Validation Loss: 3.2456, Validation Accuracy: 0.4510\n",
            "Epoch [189/300], Training Loss: 0.7869, Validation Loss: 3.2608, Validation Accuracy: 0.4539\n",
            "Epoch [190/300], Training Loss: 0.7575, Validation Loss: 3.3202, Validation Accuracy: 0.4402\n",
            "Epoch [191/300], Training Loss: 0.8253, Validation Loss: 3.2020, Validation Accuracy: 0.4608\n",
            "Epoch [192/300], Training Loss: 0.7082, Validation Loss: 3.2437, Validation Accuracy: 0.4598\n",
            "Epoch [193/300], Training Loss: 0.8133, Validation Loss: 3.4335, Validation Accuracy: 0.4529\n",
            "Epoch [194/300], Training Loss: 0.7581, Validation Loss: 3.5146, Validation Accuracy: 0.4451\n",
            "Epoch [195/300], Training Loss: 0.7278, Validation Loss: 3.6582, Validation Accuracy: 0.4314\n",
            "Epoch [196/300], Training Loss: 0.8274, Validation Loss: 3.2089, Validation Accuracy: 0.4451\n",
            "Epoch [197/300], Training Loss: 0.7311, Validation Loss: 3.4685, Validation Accuracy: 0.4471\n",
            "Epoch [198/300], Training Loss: 0.8368, Validation Loss: 3.5371, Validation Accuracy: 0.4657\n",
            "Epoch [199/300], Training Loss: 0.7363, Validation Loss: 3.4581, Validation Accuracy: 0.4667\n",
            "Epoch [200/300], Training Loss: 0.7160, Validation Loss: 3.5826, Validation Accuracy: 0.4490\n",
            "Epoch [201/300], Training Loss: 0.8034, Validation Loss: 3.6075, Validation Accuracy: 0.4490\n",
            "Epoch [202/300], Training Loss: 0.8285, Validation Loss: 3.5579, Validation Accuracy: 0.4402\n",
            "Epoch [203/300], Training Loss: 0.8062, Validation Loss: 3.2517, Validation Accuracy: 0.4686\n",
            "Epoch [204/300], Training Loss: 0.7785, Validation Loss: 3.3372, Validation Accuracy: 0.4608\n",
            "Epoch [205/300], Training Loss: 0.6884, Validation Loss: 3.4215, Validation Accuracy: 0.4618\n",
            "Epoch [206/300], Training Loss: 0.7230, Validation Loss: 3.6276, Validation Accuracy: 0.4422\n",
            "Epoch [207/300], Training Loss: 0.6858, Validation Loss: 3.4969, Validation Accuracy: 0.4441\n",
            "Epoch [208/300], Training Loss: 0.8122, Validation Loss: 3.4343, Validation Accuracy: 0.4520\n",
            "Epoch [209/300], Training Loss: 0.6903, Validation Loss: 3.7115, Validation Accuracy: 0.4520\n",
            "Epoch [210/300], Training Loss: 0.8385, Validation Loss: 3.4046, Validation Accuracy: 0.4637\n",
            "Epoch [211/300], Training Loss: 0.7873, Validation Loss: 3.3790, Validation Accuracy: 0.4510\n",
            "Epoch [212/300], Training Loss: 0.6305, Validation Loss: 3.5882, Validation Accuracy: 0.4618\n",
            "Epoch [213/300], Training Loss: 0.6993, Validation Loss: 3.5032, Validation Accuracy: 0.4598\n",
            "Epoch [214/300], Training Loss: 0.6953, Validation Loss: 3.5801, Validation Accuracy: 0.4667\n",
            "Epoch [215/300], Training Loss: 0.6747, Validation Loss: 3.6073, Validation Accuracy: 0.4559\n",
            "Epoch [216/300], Training Loss: 0.8109, Validation Loss: 3.4444, Validation Accuracy: 0.4490\n",
            "Epoch [217/300], Training Loss: 0.7677, Validation Loss: 3.5840, Validation Accuracy: 0.4510\n",
            "Epoch [218/300], Training Loss: 0.7934, Validation Loss: 3.4471, Validation Accuracy: 0.4529\n",
            "Epoch [219/300], Training Loss: 0.7867, Validation Loss: 3.2478, Validation Accuracy: 0.4412\n",
            "Epoch [220/300], Training Loss: 0.7842, Validation Loss: 3.4753, Validation Accuracy: 0.4324\n",
            "Epoch [221/300], Training Loss: 0.8048, Validation Loss: 3.5108, Validation Accuracy: 0.4578\n",
            "Epoch [222/300], Training Loss: 0.8120, Validation Loss: 3.3535, Validation Accuracy: 0.4618\n",
            "Epoch [223/300], Training Loss: 0.6618, Validation Loss: 3.5053, Validation Accuracy: 0.4657\n",
            "Epoch [224/300], Training Loss: 0.6700, Validation Loss: 3.4262, Validation Accuracy: 0.4725\n",
            "Epoch [225/300], Training Loss: 0.8038, Validation Loss: 3.7347, Validation Accuracy: 0.4627\n",
            "Epoch [226/300], Training Loss: 0.7666, Validation Loss: 3.6199, Validation Accuracy: 0.4667\n",
            "Epoch [227/300], Training Loss: 0.7123, Validation Loss: 3.3832, Validation Accuracy: 0.4657\n",
            "Epoch [228/300], Training Loss: 0.6612, Validation Loss: 3.5257, Validation Accuracy: 0.4598\n",
            "Epoch [229/300], Training Loss: 0.7135, Validation Loss: 3.3525, Validation Accuracy: 0.4510\n",
            "Epoch [230/300], Training Loss: 0.6845, Validation Loss: 3.4646, Validation Accuracy: 0.4529\n",
            "Epoch [231/300], Training Loss: 0.7483, Validation Loss: 3.4519, Validation Accuracy: 0.4539\n",
            "Epoch [232/300], Training Loss: 0.7215, Validation Loss: 3.2796, Validation Accuracy: 0.4745\n",
            "Epoch [233/300], Training Loss: 0.6235, Validation Loss: 3.3916, Validation Accuracy: 0.4500\n",
            "Epoch [234/300], Training Loss: 0.7014, Validation Loss: 3.5841, Validation Accuracy: 0.4647\n",
            "Epoch [235/300], Training Loss: 0.7100, Validation Loss: 3.5558, Validation Accuracy: 0.4608\n",
            "Epoch [236/300], Training Loss: 0.7159, Validation Loss: 3.5943, Validation Accuracy: 0.4559\n",
            "Epoch [237/300], Training Loss: 0.6733, Validation Loss: 3.7071, Validation Accuracy: 0.4618\n",
            "Epoch [238/300], Training Loss: 0.7354, Validation Loss: 3.4708, Validation Accuracy: 0.4686\n",
            "Epoch [239/300], Training Loss: 0.6847, Validation Loss: 3.6421, Validation Accuracy: 0.4578\n",
            "Epoch [240/300], Training Loss: 0.6659, Validation Loss: 3.5444, Validation Accuracy: 0.4539\n",
            "Epoch [241/300], Training Loss: 0.7091, Validation Loss: 3.5920, Validation Accuracy: 0.4461\n",
            "Epoch [242/300], Training Loss: 0.7977, Validation Loss: 3.5942, Validation Accuracy: 0.4559\n",
            "Epoch [243/300], Training Loss: 0.5896, Validation Loss: 3.6312, Validation Accuracy: 0.4608\n",
            "Epoch [244/300], Training Loss: 0.6830, Validation Loss: 3.6828, Validation Accuracy: 0.4637\n",
            "Epoch [245/300], Training Loss: 0.7816, Validation Loss: 3.5205, Validation Accuracy: 0.4510\n",
            "Epoch [246/300], Training Loss: 0.7218, Validation Loss: 3.6315, Validation Accuracy: 0.4598\n",
            "Epoch [247/300], Training Loss: 0.6493, Validation Loss: 3.7194, Validation Accuracy: 0.4461\n",
            "Epoch [248/300], Training Loss: 0.7539, Validation Loss: 3.4833, Validation Accuracy: 0.4569\n",
            "Epoch [249/300], Training Loss: 0.6054, Validation Loss: 3.6796, Validation Accuracy: 0.4471\n",
            "Epoch [250/300], Training Loss: 0.7908, Validation Loss: 3.3867, Validation Accuracy: 0.4608\n",
            "Epoch [251/300], Training Loss: 0.8053, Validation Loss: 3.2314, Validation Accuracy: 0.4804\n",
            "Epoch [252/300], Training Loss: 0.6752, Validation Loss: 3.3491, Validation Accuracy: 0.4569\n",
            "Epoch [253/300], Training Loss: 0.7094, Validation Loss: 3.7406, Validation Accuracy: 0.4333\n",
            "Epoch [254/300], Training Loss: 0.6522, Validation Loss: 3.5646, Validation Accuracy: 0.4569\n",
            "Epoch [255/300], Training Loss: 0.6269, Validation Loss: 3.5994, Validation Accuracy: 0.4559\n",
            "Epoch [256/300], Training Loss: 0.6243, Validation Loss: 3.6697, Validation Accuracy: 0.4461\n",
            "Epoch [257/300], Training Loss: 0.7160, Validation Loss: 3.7649, Validation Accuracy: 0.4539\n",
            "Epoch [258/300], Training Loss: 0.7151, Validation Loss: 3.6117, Validation Accuracy: 0.4647\n",
            "Epoch [259/300], Training Loss: 0.6802, Validation Loss: 3.3924, Validation Accuracy: 0.4784\n",
            "Epoch [260/300], Training Loss: 0.7135, Validation Loss: 3.6816, Validation Accuracy: 0.4451\n",
            "Epoch [261/300], Training Loss: 0.7616, Validation Loss: 3.5873, Validation Accuracy: 0.4520\n",
            "Epoch [262/300], Training Loss: 0.6001, Validation Loss: 3.5491, Validation Accuracy: 0.4598\n",
            "Epoch [263/300], Training Loss: 0.5820, Validation Loss: 3.8420, Validation Accuracy: 0.4480\n",
            "Epoch [264/300], Training Loss: 0.6322, Validation Loss: 3.6706, Validation Accuracy: 0.4559\n",
            "Epoch [265/300], Training Loss: 0.5782, Validation Loss: 3.8525, Validation Accuracy: 0.4510\n",
            "Epoch [266/300], Training Loss: 0.7879, Validation Loss: 3.7059, Validation Accuracy: 0.4402\n",
            "Epoch [267/300], Training Loss: 0.6527, Validation Loss: 3.5344, Validation Accuracy: 0.4471\n",
            "Epoch [268/300], Training Loss: 0.6357, Validation Loss: 3.6390, Validation Accuracy: 0.4657\n",
            "Epoch [269/300], Training Loss: 0.6213, Validation Loss: 3.9564, Validation Accuracy: 0.4412\n",
            "Epoch [270/300], Training Loss: 0.7232, Validation Loss: 3.6685, Validation Accuracy: 0.4529\n",
            "Epoch [271/300], Training Loss: 0.6857, Validation Loss: 3.6916, Validation Accuracy: 0.4716\n",
            "Epoch [272/300], Training Loss: 0.6291, Validation Loss: 3.7253, Validation Accuracy: 0.4784\n",
            "Epoch [273/300], Training Loss: 0.7407, Validation Loss: 3.4671, Validation Accuracy: 0.4735\n",
            "Epoch [274/300], Training Loss: 0.6008, Validation Loss: 3.9244, Validation Accuracy: 0.4618\n",
            "Epoch [275/300], Training Loss: 0.6741, Validation Loss: 3.5318, Validation Accuracy: 0.4422\n",
            "Epoch [276/300], Training Loss: 0.6627, Validation Loss: 3.7109, Validation Accuracy: 0.4451\n",
            "Epoch [277/300], Training Loss: 0.6410, Validation Loss: 3.5493, Validation Accuracy: 0.4431\n",
            "Epoch [278/300], Training Loss: 0.7264, Validation Loss: 3.7402, Validation Accuracy: 0.4510\n",
            "Epoch [279/300], Training Loss: 0.8663, Validation Loss: 3.8199, Validation Accuracy: 0.4324\n",
            "Epoch [280/300], Training Loss: 0.7135, Validation Loss: 3.6612, Validation Accuracy: 0.4529\n",
            "Epoch [281/300], Training Loss: 0.6078, Validation Loss: 3.8527, Validation Accuracy: 0.4529\n",
            "Epoch [282/300], Training Loss: 0.6126, Validation Loss: 3.9464, Validation Accuracy: 0.4353\n",
            "Epoch [283/300], Training Loss: 0.5972, Validation Loss: 3.9107, Validation Accuracy: 0.4490\n",
            "Epoch [284/300], Training Loss: 0.7134, Validation Loss: 3.8760, Validation Accuracy: 0.4510\n",
            "Epoch [285/300], Training Loss: 0.6514, Validation Loss: 3.7124, Validation Accuracy: 0.4569\n",
            "Epoch [286/300], Training Loss: 0.6689, Validation Loss: 3.8026, Validation Accuracy: 0.4353\n",
            "Epoch [287/300], Training Loss: 0.5994, Validation Loss: 3.6553, Validation Accuracy: 0.4627\n",
            "Epoch [288/300], Training Loss: 0.5597, Validation Loss: 3.9779, Validation Accuracy: 0.4520\n",
            "Epoch [289/300], Training Loss: 0.5911, Validation Loss: 3.7987, Validation Accuracy: 0.4559\n",
            "Epoch [290/300], Training Loss: 0.6360, Validation Loss: 3.7400, Validation Accuracy: 0.4549\n",
            "Epoch [291/300], Training Loss: 0.7385, Validation Loss: 3.6790, Validation Accuracy: 0.4363\n",
            "Epoch [292/300], Training Loss: 0.6766, Validation Loss: 3.7842, Validation Accuracy: 0.4529\n",
            "Epoch [293/300], Training Loss: 0.5368, Validation Loss: 3.6371, Validation Accuracy: 0.4676\n",
            "Epoch [294/300], Training Loss: 0.6361, Validation Loss: 3.8458, Validation Accuracy: 0.4647\n",
            "Epoch [295/300], Training Loss: 0.6266, Validation Loss: 3.7237, Validation Accuracy: 0.4676\n",
            "Epoch [296/300], Training Loss: 0.6018, Validation Loss: 3.6488, Validation Accuracy: 0.4725\n",
            "Epoch [297/300], Training Loss: 0.6113, Validation Loss: 3.5656, Validation Accuracy: 0.4627\n",
            "Epoch [298/300], Training Loss: 0.5513, Validation Loss: 3.8482, Validation Accuracy: 0.4559\n",
            "Epoch [299/300], Training Loss: 0.6828, Validation Loss: 3.7609, Validation Accuracy: 0.4549\n",
            "Epoch [300/300], Training Loss: 0.6347, Validation Loss: 3.8097, Validation Accuracy: 0.4559\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import Flowers102\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define transforms for data augmentation and normalization\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(128),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(144),\n",
        "    transforms.CenterCrop(128),\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the dataset with train/val/test splits\n",
        "train_dataset = Flowers102(root='./data', split='train', transform=train_transform, download=True)\n",
        "val_dataset = Flowers102(root='./data', split='val', transform=val_transform, download=True)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Define data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "class CNN_NN(nn.Module):\n",
        "    def __init__(self, num_classes=102):\n",
        "        super(CNN_NN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        # Initialize the size of the fully connected layer based on the sample input\n",
        "        self._to_linear = None\n",
        "        self.convs = nn.Sequential(\n",
        "            self.conv1,\n",
        "            nn.ReLU(),\n",
        "            self.pool,\n",
        "            self.conv2,\n",
        "            nn.ReLU(),\n",
        "            self.pool,\n",
        "            self.conv3,\n",
        "            nn.ReLU(),\n",
        "            self.pool\n",
        "        )\n",
        "        self._initialize_linear_layer()\n",
        "\n",
        "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def _initialize_linear_layer(self):\n",
        "        # Create a dummy input tensor to calculate the output size after conv layers\n",
        "        x = torch.randn(1, 3, 128, 128)\n",
        "        x = self.convs(x)\n",
        "        self._to_linear = x.view(1, -1).shape[1]\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor while preserving the batch size\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Define the device (GPU or CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyperparameters\n",
        "num_classes = 102  # Number of output classes\n",
        "learning_rate = 0.001\n",
        "num_epochs = 300\n",
        "\n",
        "# Initialize the model\n",
        "model = CNN_NN(num_classes=num_classes).to(device)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    # Calculate average loss for the epoch\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Calculate average validation loss and accuracy\n",
        "    val_loss = val_loss / len(val_loader.dataset)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "          f'Training Loss: {epoch_loss:.4f}, '\n",
        "          f'Validation Loss: {val_loss:.4f}, '\n",
        "          f'Validation Accuracy: {accuracy:.4f}')\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRscotqFyhP2",
        "outputId": "c87e8bf1-f8db-4fab-dd81-2f9ab950bc15"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to data/flowers-102/102flowers.tgz\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 344862509/344862509 [00:10<00:00, 33571381.79it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/flowers-102/102flowers.tgz to data/flowers-102\n",
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to data/flowers-102/imagelabels.mat\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 502/502 [00:00<00:00, 383732.57it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to data/flowers-102/setid.mat\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 14989/14989 [00:00<00:00, 22121190.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/500], Training Loss: 4.6333, Validation Loss: 4.5878, Validation Accuracy: 0.0088, Percentage:0.8824%\n",
            "Epoch [2/500], Training Loss: 4.5151, Validation Loss: 4.3199, Validation Accuracy: 0.0196, Percentage:1.9608%\n",
            "Epoch [3/500], Training Loss: 4.2762, Validation Loss: 4.0709, Validation Accuracy: 0.0520, Percentage:5.1961%\n",
            "Epoch [4/500], Training Loss: 4.0982, Validation Loss: 3.8989, Validation Accuracy: 0.0716, Percentage:7.1569%\n",
            "Epoch [5/500], Training Loss: 3.9286, Validation Loss: 3.8706, Validation Accuracy: 0.0598, Percentage:5.9804%\n",
            "Epoch [6/500], Training Loss: 3.8469, Validation Loss: 3.7347, Validation Accuracy: 0.1069, Percentage:10.6863%\n",
            "Epoch [7/500], Training Loss: 3.7759, Validation Loss: 3.6374, Validation Accuracy: 0.1245, Percentage:12.4510%\n",
            "Epoch [8/500], Training Loss: 3.7178, Validation Loss: 3.5575, Validation Accuracy: 0.1373, Percentage:13.7255%\n",
            "Epoch [9/500], Training Loss: 3.5871, Validation Loss: 3.4741, Validation Accuracy: 0.1618, Percentage:16.1765%\n",
            "Epoch [10/500], Training Loss: 3.5477, Validation Loss: 3.3836, Validation Accuracy: 0.1971, Percentage:19.7059%\n",
            "Epoch [11/500], Training Loss: 3.4119, Validation Loss: 3.3234, Validation Accuracy: 0.1804, Percentage:18.0392%\n",
            "Epoch [12/500], Training Loss: 3.3554, Validation Loss: 3.2938, Validation Accuracy: 0.2020, Percentage:20.1961%\n",
            "Epoch [13/500], Training Loss: 3.3588, Validation Loss: 3.2591, Validation Accuracy: 0.2029, Percentage:20.2941%\n",
            "Epoch [14/500], Training Loss: 3.2338, Validation Loss: 3.1450, Validation Accuracy: 0.2412, Percentage:24.1176%\n",
            "Epoch [15/500], Training Loss: 3.1818, Validation Loss: 3.1174, Validation Accuracy: 0.2412, Percentage:24.1176%\n",
            "Epoch [16/500], Training Loss: 3.0855, Validation Loss: 3.0859, Validation Accuracy: 0.2549, Percentage:25.4902%\n",
            "Epoch [17/500], Training Loss: 3.1409, Validation Loss: 3.0722, Validation Accuracy: 0.2353, Percentage:23.5294%\n",
            "Epoch [18/500], Training Loss: 2.9765, Validation Loss: 2.9967, Validation Accuracy: 0.2578, Percentage:25.7843%\n",
            "Epoch [19/500], Training Loss: 3.0040, Validation Loss: 3.0039, Validation Accuracy: 0.2725, Percentage:27.2549%\n",
            "Epoch [20/500], Training Loss: 2.9061, Validation Loss: 3.0404, Validation Accuracy: 0.2667, Percentage:26.6667%\n",
            "Epoch [21/500], Training Loss: 2.8805, Validation Loss: 2.9621, Validation Accuracy: 0.2696, Percentage:26.9608%\n",
            "Epoch [22/500], Training Loss: 2.8096, Validation Loss: 2.9073, Validation Accuracy: 0.2824, Percentage:28.2353%\n",
            "Epoch [23/500], Training Loss: 2.7604, Validation Loss: 2.8724, Validation Accuracy: 0.2755, Percentage:27.5490%\n",
            "Epoch [24/500], Training Loss: 2.6659, Validation Loss: 2.8169, Validation Accuracy: 0.3324, Percentage:33.2353%\n",
            "Epoch [25/500], Training Loss: 2.7045, Validation Loss: 2.8379, Validation Accuracy: 0.2961, Percentage:29.6078%\n",
            "Epoch [26/500], Training Loss: 2.6643, Validation Loss: 2.7911, Validation Accuracy: 0.3118, Percentage:31.1765%\n",
            "Epoch [27/500], Training Loss: 2.5756, Validation Loss: 2.8090, Validation Accuracy: 0.3118, Percentage:31.1765%\n",
            "Epoch [28/500], Training Loss: 2.5890, Validation Loss: 2.7551, Validation Accuracy: 0.3373, Percentage:33.7255%\n",
            "Epoch [29/500], Training Loss: 2.4893, Validation Loss: 2.7018, Validation Accuracy: 0.3314, Percentage:33.1373%\n",
            "Epoch [30/500], Training Loss: 2.4271, Validation Loss: 2.7017, Validation Accuracy: 0.3529, Percentage:35.2941%\n",
            "Epoch [31/500], Training Loss: 2.4748, Validation Loss: 2.6877, Validation Accuracy: 0.3431, Percentage:34.3137%\n",
            "Epoch [32/500], Training Loss: 2.3725, Validation Loss: 2.7001, Validation Accuracy: 0.3431, Percentage:34.3137%\n",
            "Epoch [33/500], Training Loss: 2.3982, Validation Loss: 2.6637, Validation Accuracy: 0.3549, Percentage:35.4902%\n",
            "Epoch [34/500], Training Loss: 2.2738, Validation Loss: 2.6954, Validation Accuracy: 0.3539, Percentage:35.3922%\n",
            "Epoch [35/500], Training Loss: 2.2324, Validation Loss: 2.6634, Validation Accuracy: 0.3549, Percentage:35.4902%\n",
            "Epoch [36/500], Training Loss: 2.1974, Validation Loss: 2.7352, Validation Accuracy: 0.3392, Percentage:33.9216%\n",
            "Epoch [37/500], Training Loss: 2.1959, Validation Loss: 2.7042, Validation Accuracy: 0.3647, Percentage:36.4706%\n",
            "Epoch [38/500], Training Loss: 2.2013, Validation Loss: 2.6959, Validation Accuracy: 0.3363, Percentage:33.6275%\n",
            "Epoch [39/500], Training Loss: 2.1252, Validation Loss: 2.6551, Validation Accuracy: 0.3441, Percentage:34.4118%\n",
            "Epoch [40/500], Training Loss: 2.1037, Validation Loss: 2.6463, Validation Accuracy: 0.3637, Percentage:36.3725%\n",
            "Epoch [41/500], Training Loss: 2.1484, Validation Loss: 2.6962, Validation Accuracy: 0.3696, Percentage:36.9608%\n",
            "Epoch [42/500], Training Loss: 2.0418, Validation Loss: 2.6318, Validation Accuracy: 0.3765, Percentage:37.6471%\n",
            "Epoch [43/500], Training Loss: 2.0078, Validation Loss: 2.6375, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [44/500], Training Loss: 1.9057, Validation Loss: 2.6171, Validation Accuracy: 0.3843, Percentage:38.4314%\n",
            "Epoch [45/500], Training Loss: 1.9929, Validation Loss: 2.6550, Validation Accuracy: 0.3804, Percentage:38.0392%\n",
            "Epoch [46/500], Training Loss: 1.8620, Validation Loss: 2.6646, Validation Accuracy: 0.3912, Percentage:39.1176%\n",
            "Epoch [47/500], Training Loss: 1.9349, Validation Loss: 2.6838, Validation Accuracy: 0.3902, Percentage:39.0196%\n",
            "Epoch [48/500], Training Loss: 1.8630, Validation Loss: 2.6839, Validation Accuracy: 0.3755, Percentage:37.5490%\n",
            "Epoch [49/500], Training Loss: 1.8760, Validation Loss: 2.6576, Validation Accuracy: 0.3804, Percentage:38.0392%\n",
            "Epoch [50/500], Training Loss: 1.8856, Validation Loss: 2.6247, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [51/500], Training Loss: 1.8663, Validation Loss: 2.6012, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [52/500], Training Loss: 1.7513, Validation Loss: 2.7369, Validation Accuracy: 0.3902, Percentage:39.0196%\n",
            "Epoch [53/500], Training Loss: 1.7741, Validation Loss: 2.6385, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [54/500], Training Loss: 1.7091, Validation Loss: 2.5980, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [55/500], Training Loss: 1.6842, Validation Loss: 2.7232, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [56/500], Training Loss: 1.7502, Validation Loss: 2.6410, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [57/500], Training Loss: 1.5971, Validation Loss: 2.6575, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [58/500], Training Loss: 1.6096, Validation Loss: 2.7766, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [59/500], Training Loss: 1.5672, Validation Loss: 2.7420, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [60/500], Training Loss: 1.6237, Validation Loss: 2.6650, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [61/500], Training Loss: 1.6365, Validation Loss: 2.7562, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [62/500], Training Loss: 1.5399, Validation Loss: 2.6759, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [63/500], Training Loss: 1.5135, Validation Loss: 2.8035, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [64/500], Training Loss: 1.6073, Validation Loss: 2.6954, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [65/500], Training Loss: 1.4056, Validation Loss: 2.7608, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [66/500], Training Loss: 1.4951, Validation Loss: 2.7746, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [67/500], Training Loss: 1.5794, Validation Loss: 2.7833, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [68/500], Training Loss: 1.4340, Validation Loss: 2.8870, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [69/500], Training Loss: 1.5642, Validation Loss: 2.7299, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [70/500], Training Loss: 1.4247, Validation Loss: 2.8060, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [71/500], Training Loss: 1.4503, Validation Loss: 2.7122, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [72/500], Training Loss: 1.5373, Validation Loss: 2.7481, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [73/500], Training Loss: 1.3876, Validation Loss: 2.7739, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [74/500], Training Loss: 1.4065, Validation Loss: 2.9464, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [75/500], Training Loss: 1.3915, Validation Loss: 2.7189, Validation Accuracy: 0.4284, Percentage:42.8431%\n",
            "Epoch [76/500], Training Loss: 1.3950, Validation Loss: 3.0237, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [77/500], Training Loss: 1.3768, Validation Loss: 2.8100, Validation Accuracy: 0.4225, Percentage:42.2549%\n",
            "Epoch [78/500], Training Loss: 1.3745, Validation Loss: 2.7946, Validation Accuracy: 0.4265, Percentage:42.6471%\n",
            "Epoch [79/500], Training Loss: 1.3671, Validation Loss: 2.7756, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [80/500], Training Loss: 1.2937, Validation Loss: 2.9081, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [81/500], Training Loss: 1.2718, Validation Loss: 2.7817, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [82/500], Training Loss: 1.2337, Validation Loss: 2.9229, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [83/500], Training Loss: 1.3191, Validation Loss: 2.8285, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [84/500], Training Loss: 1.3038, Validation Loss: 2.8672, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [85/500], Training Loss: 1.3164, Validation Loss: 2.6855, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [86/500], Training Loss: 1.3013, Validation Loss: 2.8497, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [87/500], Training Loss: 1.2445, Validation Loss: 2.8314, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [88/500], Training Loss: 1.1987, Validation Loss: 2.7967, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [89/500], Training Loss: 1.1940, Validation Loss: 2.8239, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [90/500], Training Loss: 1.2444, Validation Loss: 2.8425, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [91/500], Training Loss: 1.3483, Validation Loss: 2.8616, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [92/500], Training Loss: 1.2355, Validation Loss: 2.8386, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [93/500], Training Loss: 1.2179, Validation Loss: 2.9766, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [94/500], Training Loss: 1.1374, Validation Loss: 2.9107, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [95/500], Training Loss: 1.1222, Validation Loss: 2.9542, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [96/500], Training Loss: 1.1718, Validation Loss: 2.9670, Validation Accuracy: 0.4206, Percentage:42.0588%\n",
            "Epoch [97/500], Training Loss: 1.2171, Validation Loss: 2.8458, Validation Accuracy: 0.4578, Percentage:45.7843%\n",
            "Epoch [98/500], Training Loss: 1.1744, Validation Loss: 2.9668, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [99/500], Training Loss: 1.1382, Validation Loss: 2.8898, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [100/500], Training Loss: 1.1895, Validation Loss: 2.9335, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [101/500], Training Loss: 1.1345, Validation Loss: 2.9290, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [102/500], Training Loss: 1.1279, Validation Loss: 2.9354, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [103/500], Training Loss: 1.0989, Validation Loss: 2.8620, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [104/500], Training Loss: 1.0784, Validation Loss: 3.0200, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [105/500], Training Loss: 1.1121, Validation Loss: 2.9489, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [106/500], Training Loss: 1.0919, Validation Loss: 2.8364, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [107/500], Training Loss: 1.1703, Validation Loss: 2.9032, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [108/500], Training Loss: 1.0851, Validation Loss: 2.9442, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [109/500], Training Loss: 1.0185, Validation Loss: 2.9695, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [110/500], Training Loss: 1.1106, Validation Loss: 2.7273, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [111/500], Training Loss: 1.0650, Validation Loss: 3.0477, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [112/500], Training Loss: 1.0127, Validation Loss: 2.8897, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [113/500], Training Loss: 1.0917, Validation Loss: 2.9727, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [114/500], Training Loss: 1.1010, Validation Loss: 2.9800, Validation Accuracy: 0.4265, Percentage:42.6471%\n",
            "Epoch [115/500], Training Loss: 1.0947, Validation Loss: 3.0533, Validation Accuracy: 0.4284, Percentage:42.8431%\n",
            "Epoch [116/500], Training Loss: 1.0078, Validation Loss: 3.2363, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [117/500], Training Loss: 0.9514, Validation Loss: 3.0460, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [118/500], Training Loss: 1.0598, Validation Loss: 2.9597, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [119/500], Training Loss: 1.0486, Validation Loss: 2.9734, Validation Accuracy: 0.4618, Percentage:46.1765%\n",
            "Epoch [120/500], Training Loss: 1.0282, Validation Loss: 2.9700, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [121/500], Training Loss: 1.0596, Validation Loss: 2.8948, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [122/500], Training Loss: 1.0448, Validation Loss: 2.9845, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [123/500], Training Loss: 1.1081, Validation Loss: 3.0441, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [124/500], Training Loss: 1.0838, Validation Loss: 2.9915, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [125/500], Training Loss: 1.0405, Validation Loss: 3.1537, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [126/500], Training Loss: 0.9106, Validation Loss: 3.0161, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [127/500], Training Loss: 0.8624, Validation Loss: 3.1665, Validation Accuracy: 0.4265, Percentage:42.6471%\n",
            "Epoch [128/500], Training Loss: 0.9405, Validation Loss: 3.3362, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [129/500], Training Loss: 0.9052, Validation Loss: 3.0175, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [130/500], Training Loss: 1.0189, Validation Loss: 3.1574, Validation Accuracy: 0.4627, Percentage:46.2745%\n",
            "Epoch [131/500], Training Loss: 1.0222, Validation Loss: 3.0854, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [132/500], Training Loss: 0.9428, Validation Loss: 3.0920, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [133/500], Training Loss: 0.9078, Validation Loss: 3.0234, Validation Accuracy: 0.4657, Percentage:46.5686%\n",
            "Epoch [134/500], Training Loss: 0.8639, Validation Loss: 3.2076, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [135/500], Training Loss: 0.9301, Validation Loss: 3.0558, Validation Accuracy: 0.4647, Percentage:46.4706%\n",
            "Epoch [136/500], Training Loss: 0.8653, Validation Loss: 3.3534, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [137/500], Training Loss: 0.8570, Validation Loss: 3.1268, Validation Accuracy: 0.4578, Percentage:45.7843%\n",
            "Epoch [138/500], Training Loss: 0.8877, Validation Loss: 3.1890, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [139/500], Training Loss: 0.9128, Validation Loss: 2.9708, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [140/500], Training Loss: 0.8826, Validation Loss: 3.3928, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [141/500], Training Loss: 0.8892, Validation Loss: 3.2413, Validation Accuracy: 0.4598, Percentage:45.9804%\n",
            "Epoch [142/500], Training Loss: 0.9185, Validation Loss: 3.1338, Validation Accuracy: 0.4667, Percentage:46.6667%\n",
            "Epoch [143/500], Training Loss: 0.9676, Validation Loss: 3.1285, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [144/500], Training Loss: 0.9114, Validation Loss: 3.1179, Validation Accuracy: 0.4608, Percentage:46.0784%\n",
            "Epoch [145/500], Training Loss: 0.9019, Validation Loss: 3.2559, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [146/500], Training Loss: 0.9553, Validation Loss: 3.0037, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [147/500], Training Loss: 0.7750, Validation Loss: 3.5123, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [148/500], Training Loss: 0.8035, Validation Loss: 3.4390, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [149/500], Training Loss: 0.8460, Validation Loss: 3.0340, Validation Accuracy: 0.4667, Percentage:46.6667%\n",
            "Epoch [150/500], Training Loss: 0.9217, Validation Loss: 3.1499, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [151/500], Training Loss: 0.9142, Validation Loss: 3.1843, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [152/500], Training Loss: 0.8479, Validation Loss: 3.2126, Validation Accuracy: 0.4578, Percentage:45.7843%\n",
            "Epoch [153/500], Training Loss: 0.8691, Validation Loss: 3.4022, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [154/500], Training Loss: 0.9122, Validation Loss: 3.2277, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [155/500], Training Loss: 0.9263, Validation Loss: 3.2465, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [156/500], Training Loss: 0.8694, Validation Loss: 3.2551, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [157/500], Training Loss: 0.7903, Validation Loss: 3.3309, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [158/500], Training Loss: 0.9037, Validation Loss: 3.1497, Validation Accuracy: 0.4667, Percentage:46.6667%\n",
            "Epoch [159/500], Training Loss: 0.7762, Validation Loss: 3.3782, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [160/500], Training Loss: 0.8582, Validation Loss: 3.4296, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [161/500], Training Loss: 0.8357, Validation Loss: 3.2972, Validation Accuracy: 0.4716, Percentage:47.1569%\n",
            "Epoch [162/500], Training Loss: 0.7933, Validation Loss: 3.4560, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [163/500], Training Loss: 0.8386, Validation Loss: 3.2282, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [164/500], Training Loss: 0.8075, Validation Loss: 3.7636, Validation Accuracy: 0.4265, Percentage:42.6471%\n",
            "Epoch [165/500], Training Loss: 0.9106, Validation Loss: 3.3727, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [166/500], Training Loss: 0.8183, Validation Loss: 3.2648, Validation Accuracy: 0.4647, Percentage:46.4706%\n",
            "Epoch [167/500], Training Loss: 0.7499, Validation Loss: 3.4334, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [168/500], Training Loss: 0.8399, Validation Loss: 3.5353, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [169/500], Training Loss: 0.7620, Validation Loss: 3.2388, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [170/500], Training Loss: 0.8391, Validation Loss: 3.3806, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [171/500], Training Loss: 0.8448, Validation Loss: 3.5031, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [172/500], Training Loss: 0.7528, Validation Loss: 3.1808, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [173/500], Training Loss: 0.8870, Validation Loss: 3.2108, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [174/500], Training Loss: 0.8236, Validation Loss: 3.4618, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [175/500], Training Loss: 0.8944, Validation Loss: 3.4014, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [176/500], Training Loss: 0.8725, Validation Loss: 3.4015, Validation Accuracy: 0.4676, Percentage:46.7647%\n",
            "Epoch [177/500], Training Loss: 0.8528, Validation Loss: 3.1154, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [178/500], Training Loss: 0.8596, Validation Loss: 3.1340, Validation Accuracy: 0.4637, Percentage:46.3725%\n",
            "Epoch [179/500], Training Loss: 0.9260, Validation Loss: 3.3968, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [180/500], Training Loss: 0.7842, Validation Loss: 3.3913, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [181/500], Training Loss: 0.8009, Validation Loss: 3.2673, Validation Accuracy: 0.4578, Percentage:45.7843%\n",
            "Epoch [182/500], Training Loss: 0.7960, Validation Loss: 3.5080, Validation Accuracy: 0.4608, Percentage:46.0784%\n",
            "Epoch [183/500], Training Loss: 0.7471, Validation Loss: 3.1807, Validation Accuracy: 0.4647, Percentage:46.4706%\n",
            "Epoch [184/500], Training Loss: 0.7708, Validation Loss: 3.3875, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [185/500], Training Loss: 0.7971, Validation Loss: 3.3234, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [186/500], Training Loss: 0.8330, Validation Loss: 3.3552, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [187/500], Training Loss: 0.7867, Validation Loss: 3.1981, Validation Accuracy: 0.4647, Percentage:46.4706%\n",
            "Epoch [188/500], Training Loss: 0.8188, Validation Loss: 3.2456, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [189/500], Training Loss: 0.7869, Validation Loss: 3.2608, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [190/500], Training Loss: 0.7575, Validation Loss: 3.3202, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [191/500], Training Loss: 0.8253, Validation Loss: 3.2020, Validation Accuracy: 0.4608, Percentage:46.0784%\n",
            "Epoch [192/500], Training Loss: 0.7082, Validation Loss: 3.2437, Validation Accuracy: 0.4598, Percentage:45.9804%\n",
            "Epoch [193/500], Training Loss: 0.8133, Validation Loss: 3.4335, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [194/500], Training Loss: 0.7581, Validation Loss: 3.5146, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [195/500], Training Loss: 0.7278, Validation Loss: 3.6582, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [196/500], Training Loss: 0.8274, Validation Loss: 3.2089, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [197/500], Training Loss: 0.7311, Validation Loss: 3.4685, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [198/500], Training Loss: 0.8368, Validation Loss: 3.5371, Validation Accuracy: 0.4657, Percentage:46.5686%\n",
            "Epoch [199/500], Training Loss: 0.7363, Validation Loss: 3.4581, Validation Accuracy: 0.4667, Percentage:46.6667%\n",
            "Epoch [200/500], Training Loss: 0.7160, Validation Loss: 3.5826, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [201/500], Training Loss: 0.8034, Validation Loss: 3.6075, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [202/500], Training Loss: 0.8285, Validation Loss: 3.5579, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [203/500], Training Loss: 0.8062, Validation Loss: 3.2517, Validation Accuracy: 0.4686, Percentage:46.8627%\n",
            "Epoch [204/500], Training Loss: 0.7785, Validation Loss: 3.3372, Validation Accuracy: 0.4608, Percentage:46.0784%\n",
            "Epoch [205/500], Training Loss: 0.6884, Validation Loss: 3.4215, Validation Accuracy: 0.4618, Percentage:46.1765%\n",
            "Epoch [206/500], Training Loss: 0.7230, Validation Loss: 3.6276, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [207/500], Training Loss: 0.6858, Validation Loss: 3.4969, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [208/500], Training Loss: 0.8122, Validation Loss: 3.4343, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [209/500], Training Loss: 0.6903, Validation Loss: 3.7115, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [210/500], Training Loss: 0.8385, Validation Loss: 3.4046, Validation Accuracy: 0.4637, Percentage:46.3725%\n",
            "Epoch [211/500], Training Loss: 0.7873, Validation Loss: 3.3790, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [212/500], Training Loss: 0.6305, Validation Loss: 3.5882, Validation Accuracy: 0.4618, Percentage:46.1765%\n",
            "Epoch [213/500], Training Loss: 0.6993, Validation Loss: 3.5032, Validation Accuracy: 0.4598, Percentage:45.9804%\n",
            "Epoch [214/500], Training Loss: 0.6953, Validation Loss: 3.5801, Validation Accuracy: 0.4667, Percentage:46.6667%\n",
            "Epoch [215/500], Training Loss: 0.6747, Validation Loss: 3.6073, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [216/500], Training Loss: 0.8109, Validation Loss: 3.4444, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [217/500], Training Loss: 0.7677, Validation Loss: 3.5840, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [218/500], Training Loss: 0.7934, Validation Loss: 3.4471, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [219/500], Training Loss: 0.7867, Validation Loss: 3.2478, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [220/500], Training Loss: 0.7842, Validation Loss: 3.4753, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [221/500], Training Loss: 0.8048, Validation Loss: 3.5108, Validation Accuracy: 0.4578, Percentage:45.7843%\n",
            "Epoch [222/500], Training Loss: 0.8120, Validation Loss: 3.3535, Validation Accuracy: 0.4618, Percentage:46.1765%\n",
            "Epoch [223/500], Training Loss: 0.6618, Validation Loss: 3.5053, Validation Accuracy: 0.4657, Percentage:46.5686%\n",
            "Epoch [224/500], Training Loss: 0.6700, Validation Loss: 3.4262, Validation Accuracy: 0.4725, Percentage:47.2549%\n",
            "Epoch [225/500], Training Loss: 0.8038, Validation Loss: 3.7347, Validation Accuracy: 0.4627, Percentage:46.2745%\n",
            "Epoch [226/500], Training Loss: 0.7666, Validation Loss: 3.6199, Validation Accuracy: 0.4667, Percentage:46.6667%\n",
            "Epoch [227/500], Training Loss: 0.7123, Validation Loss: 3.3832, Validation Accuracy: 0.4657, Percentage:46.5686%\n",
            "Epoch [228/500], Training Loss: 0.6612, Validation Loss: 3.5257, Validation Accuracy: 0.4598, Percentage:45.9804%\n",
            "Epoch [229/500], Training Loss: 0.7135, Validation Loss: 3.3525, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [230/500], Training Loss: 0.6845, Validation Loss: 3.4646, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [231/500], Training Loss: 0.7483, Validation Loss: 3.4519, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [232/500], Training Loss: 0.7215, Validation Loss: 3.2796, Validation Accuracy: 0.4745, Percentage:47.4510%\n",
            "Epoch [233/500], Training Loss: 0.6235, Validation Loss: 3.3916, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [234/500], Training Loss: 0.7014, Validation Loss: 3.5841, Validation Accuracy: 0.4647, Percentage:46.4706%\n",
            "Epoch [235/500], Training Loss: 0.7100, Validation Loss: 3.5558, Validation Accuracy: 0.4608, Percentage:46.0784%\n",
            "Epoch [236/500], Training Loss: 0.7159, Validation Loss: 3.5943, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [237/500], Training Loss: 0.6733, Validation Loss: 3.7071, Validation Accuracy: 0.4618, Percentage:46.1765%\n",
            "Epoch [238/500], Training Loss: 0.7354, Validation Loss: 3.4708, Validation Accuracy: 0.4686, Percentage:46.8627%\n",
            "Epoch [239/500], Training Loss: 0.6847, Validation Loss: 3.6421, Validation Accuracy: 0.4578, Percentage:45.7843%\n",
            "Epoch [240/500], Training Loss: 0.6659, Validation Loss: 3.5444, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [241/500], Training Loss: 0.7091, Validation Loss: 3.5920, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [242/500], Training Loss: 0.7977, Validation Loss: 3.5942, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [243/500], Training Loss: 0.5896, Validation Loss: 3.6312, Validation Accuracy: 0.4608, Percentage:46.0784%\n",
            "Epoch [244/500], Training Loss: 0.6830, Validation Loss: 3.6828, Validation Accuracy: 0.4637, Percentage:46.3725%\n",
            "Epoch [245/500], Training Loss: 0.7816, Validation Loss: 3.5205, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [246/500], Training Loss: 0.7218, Validation Loss: 3.6315, Validation Accuracy: 0.4598, Percentage:45.9804%\n",
            "Epoch [247/500], Training Loss: 0.6493, Validation Loss: 3.7194, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [248/500], Training Loss: 0.7539, Validation Loss: 3.4833, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [249/500], Training Loss: 0.6054, Validation Loss: 3.6796, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [250/500], Training Loss: 0.7908, Validation Loss: 3.3867, Validation Accuracy: 0.4608, Percentage:46.0784%\n",
            "Epoch [251/500], Training Loss: 0.8053, Validation Loss: 3.2314, Validation Accuracy: 0.4804, Percentage:48.0392%\n",
            "Epoch [252/500], Training Loss: 0.6752, Validation Loss: 3.3491, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [253/500], Training Loss: 0.7094, Validation Loss: 3.7406, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [254/500], Training Loss: 0.6522, Validation Loss: 3.5646, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [255/500], Training Loss: 0.6269, Validation Loss: 3.5994, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [256/500], Training Loss: 0.6243, Validation Loss: 3.6697, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [257/500], Training Loss: 0.7160, Validation Loss: 3.7649, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [258/500], Training Loss: 0.7151, Validation Loss: 3.6117, Validation Accuracy: 0.4647, Percentage:46.4706%\n",
            "Epoch [259/500], Training Loss: 0.6802, Validation Loss: 3.3924, Validation Accuracy: 0.4784, Percentage:47.8431%\n",
            "Epoch [260/500], Training Loss: 0.7135, Validation Loss: 3.6816, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [261/500], Training Loss: 0.7616, Validation Loss: 3.5873, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [262/500], Training Loss: 0.6001, Validation Loss: 3.5491, Validation Accuracy: 0.4598, Percentage:45.9804%\n",
            "Epoch [263/500], Training Loss: 0.5820, Validation Loss: 3.8420, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [264/500], Training Loss: 0.6322, Validation Loss: 3.6706, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [265/500], Training Loss: 0.5782, Validation Loss: 3.8525, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [266/500], Training Loss: 0.7879, Validation Loss: 3.7059, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [267/500], Training Loss: 0.6527, Validation Loss: 3.5344, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [268/500], Training Loss: 0.6357, Validation Loss: 3.6390, Validation Accuracy: 0.4657, Percentage:46.5686%\n",
            "Epoch [269/500], Training Loss: 0.6213, Validation Loss: 3.9564, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [270/500], Training Loss: 0.7232, Validation Loss: 3.6685, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [271/500], Training Loss: 0.6857, Validation Loss: 3.6916, Validation Accuracy: 0.4716, Percentage:47.1569%\n",
            "Epoch [272/500], Training Loss: 0.6291, Validation Loss: 3.7253, Validation Accuracy: 0.4784, Percentage:47.8431%\n",
            "Epoch [273/500], Training Loss: 0.7407, Validation Loss: 3.4671, Validation Accuracy: 0.4735, Percentage:47.3529%\n",
            "Epoch [274/500], Training Loss: 0.6008, Validation Loss: 3.9244, Validation Accuracy: 0.4618, Percentage:46.1765%\n",
            "Epoch [275/500], Training Loss: 0.6741, Validation Loss: 3.5318, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [276/500], Training Loss: 0.6627, Validation Loss: 3.7109, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [277/500], Training Loss: 0.6410, Validation Loss: 3.5493, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [278/500], Training Loss: 0.7264, Validation Loss: 3.7402, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [279/500], Training Loss: 0.8663, Validation Loss: 3.8199, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [280/500], Training Loss: 0.7135, Validation Loss: 3.6612, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [281/500], Training Loss: 0.6078, Validation Loss: 3.8527, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [282/500], Training Loss: 0.6126, Validation Loss: 3.9464, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [283/500], Training Loss: 0.5972, Validation Loss: 3.9107, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [284/500], Training Loss: 0.7134, Validation Loss: 3.8760, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [285/500], Training Loss: 0.6514, Validation Loss: 3.7124, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [286/500], Training Loss: 0.6689, Validation Loss: 3.8026, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [287/500], Training Loss: 0.5994, Validation Loss: 3.6553, Validation Accuracy: 0.4627, Percentage:46.2745%\n",
            "Epoch [288/500], Training Loss: 0.5597, Validation Loss: 3.9779, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [289/500], Training Loss: 0.5911, Validation Loss: 3.7987, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [290/500], Training Loss: 0.6360, Validation Loss: 3.7400, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [291/500], Training Loss: 0.7385, Validation Loss: 3.6790, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [292/500], Training Loss: 0.6766, Validation Loss: 3.7842, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [293/500], Training Loss: 0.5368, Validation Loss: 3.6371, Validation Accuracy: 0.4676, Percentage:46.7647%\n",
            "Epoch [294/500], Training Loss: 0.6361, Validation Loss: 3.8458, Validation Accuracy: 0.4647, Percentage:46.4706%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import Flowers102\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define transforms for data augmentation and normalization\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(128),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(144),\n",
        "    transforms.CenterCrop(128),\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the dataset with train/val/test splits\n",
        "train_dataset = Flowers102(root='./data', split='train', transform=train_transform, download=True)\n",
        "val_dataset = Flowers102(root='./data', split='val', transform=val_transform, download=True)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Define data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "class CNN_NN(nn.Module):\n",
        "    def __init__(self, num_classes=102):\n",
        "        super(CNN_NN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        # Initialize the size of the fully connected layer based on the sample input\n",
        "        self._to_linear = None\n",
        "        self.convs = nn.Sequential(\n",
        "            self.conv1,\n",
        "            nn.ReLU(),\n",
        "            self.pool,\n",
        "            self.conv2,\n",
        "            nn.ReLU(),\n",
        "            self.pool,\n",
        "            self.conv3,\n",
        "            nn.ReLU(),\n",
        "            self.pool\n",
        "        )\n",
        "        self._initialize_linear_layer()\n",
        "\n",
        "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def _initialize_linear_layer(self):\n",
        "        # Create a dummy input tensor to calculate the output size after conv layers\n",
        "        x = torch.randn(1, 3, 128, 128)\n",
        "        x = self.convs(x)\n",
        "        self._to_linear = x.view(1, -1).shape[1]\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor while preserving the batch size\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Define the device (GPU or CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyperparameters\n",
        "num_classes = 102  # Number of output classes\n",
        "learning_rate = 0.001\n",
        "num_epochs = 500\n",
        "\n",
        "# Initialize the model\n",
        "model = CNN_NN(num_classes=num_classes).to(device)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    # Calculate average loss for the epoch\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Calculate average validation loss and accuracy\n",
        "    val_loss = val_loss / len(val_loader.dataset)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "          f'Training Loss: {epoch_loss:.4f}, '\n",
        "          f'Validation Loss: {val_loss:.4f}, '\n",
        "          f'Validation Accuracy: {accuracy:.4f}, '\n",
        "          f'Percentage:{accuracy*100:.4f}%')\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import Flowers102\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define transforms for data augmentation and normalization\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(128),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(144),\n",
        "    transforms.CenterCrop(128),\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the dataset with train/val/test splits\n",
        "train_dataset = Flowers102(root='./data', split='train', transform=train_transform, download=True)\n",
        "val_dataset = Flowers102(root='./data', split='val', transform=val_transform, download=True)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Define data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "class CNN_NN(nn.Module):\n",
        "    def __init__(self, num_classes=102):\n",
        "        super(CNN_NN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv4 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        # Initialize the size of the fully connected layer based on the sample input\n",
        "        self._to_linear = None\n",
        "        self.convs = nn.Sequential(\n",
        "            self.conv1,\n",
        "            nn.ReLU(),\n",
        "            self.pool,\n",
        "            self.conv2,\n",
        "            nn.ReLU(),\n",
        "            self.pool,\n",
        "            self.conv3,\n",
        "            nn.ReLU(),\n",
        "            self.pool\n",
        "        )\n",
        "        self._initialize_linear_layer()\n",
        "\n",
        "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def _initialize_linear_layer(self):\n",
        "        # Create a dummy input tensor to calculate the output size after conv layers\n",
        "        x = torch.randn(1, 3, 128, 128)\n",
        "        x = self.convs(x)\n",
        "        self._to_linear = x.view(1, -1).shape[1]\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor while preserving the batch size\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Define the device (GPU or CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyperparameters\n",
        "num_classes = 102  # Number of output classes\n",
        "learning_rate = 0.0001\n",
        "num_epochs = 1000\n",
        "\n",
        "# Initialize the model\n",
        "model = CNN_NN(num_classes=num_classes).to(device)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    # Calculate average loss for the epoch\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Calculate average validation loss and accuracy\n",
        "    val_loss = val_loss / len(val_loader.dataset)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "          f'Training Loss: {epoch_loss:.4f}, '\n",
        "          f'Validation Loss: {val_loss:.4f}, '\n",
        "          f'Validation Accuracy: {accuracy:.4f}, '\n",
        "          f'Percentage:{accuracy*100:.4f}%')\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BzHJAJn0UDs",
        "outputId": "ab616f4f-50cc-4711-813d-13f7f21bb49d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1000], Training Loss: 4.6325, Validation Loss: 4.6205, Validation Accuracy: 0.0098, Percentage:0.9804%\n",
            "Epoch [2/1000], Training Loss: 4.6146, Validation Loss: 4.5789, Validation Accuracy: 0.0216, Percentage:2.1569%\n",
            "Epoch [3/1000], Training Loss: 4.5498, Validation Loss: 4.4339, Validation Accuracy: 0.0373, Percentage:3.7255%\n",
            "Epoch [4/1000], Training Loss: 4.4109, Validation Loss: 4.2504, Validation Accuracy: 0.0422, Percentage:4.2157%\n",
            "Epoch [5/1000], Training Loss: 4.2824, Validation Loss: 4.1119, Validation Accuracy: 0.0755, Percentage:7.5490%\n",
            "Epoch [6/1000], Training Loss: 4.1974, Validation Loss: 4.0202, Validation Accuracy: 0.0667, Percentage:6.6667%\n",
            "Epoch [7/1000], Training Loss: 4.1308, Validation Loss: 3.9209, Validation Accuracy: 0.0794, Percentage:7.9412%\n",
            "Epoch [8/1000], Training Loss: 3.9953, Validation Loss: 3.8380, Validation Accuracy: 0.1373, Percentage:13.7255%\n",
            "Epoch [9/1000], Training Loss: 3.9801, Validation Loss: 3.7710, Validation Accuracy: 0.1265, Percentage:12.6471%\n",
            "Epoch [10/1000], Training Loss: 3.8750, Validation Loss: 3.6773, Validation Accuracy: 0.1608, Percentage:16.0784%\n",
            "Epoch [11/1000], Training Loss: 3.8469, Validation Loss: 3.6421, Validation Accuracy: 0.1529, Percentage:15.2941%\n",
            "Epoch [12/1000], Training Loss: 3.7955, Validation Loss: 3.6050, Validation Accuracy: 0.1686, Percentage:16.8627%\n",
            "Epoch [13/1000], Training Loss: 3.7710, Validation Loss: 3.5502, Validation Accuracy: 0.1824, Percentage:18.2353%\n",
            "Epoch [14/1000], Training Loss: 3.7130, Validation Loss: 3.4999, Validation Accuracy: 0.1902, Percentage:19.0196%\n",
            "Epoch [15/1000], Training Loss: 3.6747, Validation Loss: 3.4628, Validation Accuracy: 0.1971, Percentage:19.7059%\n",
            "Epoch [16/1000], Training Loss: 3.6405, Validation Loss: 3.4264, Validation Accuracy: 0.1980, Percentage:19.8039%\n",
            "Epoch [17/1000], Training Loss: 3.6553, Validation Loss: 3.4227, Validation Accuracy: 0.1971, Percentage:19.7059%\n",
            "Epoch [18/1000], Training Loss: 3.5591, Validation Loss: 3.3454, Validation Accuracy: 0.2157, Percentage:21.5686%\n",
            "Epoch [19/1000], Training Loss: 3.5517, Validation Loss: 3.3382, Validation Accuracy: 0.2049, Percentage:20.4902%\n",
            "Epoch [20/1000], Training Loss: 3.4850, Validation Loss: 3.2997, Validation Accuracy: 0.2078, Percentage:20.7843%\n",
            "Epoch [21/1000], Training Loss: 3.4342, Validation Loss: 3.2433, Validation Accuracy: 0.2098, Percentage:20.9804%\n",
            "Epoch [22/1000], Training Loss: 3.4394, Validation Loss: 3.2505, Validation Accuracy: 0.2255, Percentage:22.5490%\n",
            "Epoch [23/1000], Training Loss: 3.3875, Validation Loss: 3.2251, Validation Accuracy: 0.2265, Percentage:22.6471%\n",
            "Epoch [24/1000], Training Loss: 3.3924, Validation Loss: 3.1936, Validation Accuracy: 0.2343, Percentage:23.4314%\n",
            "Epoch [25/1000], Training Loss: 3.3557, Validation Loss: 3.1943, Validation Accuracy: 0.2451, Percentage:24.5098%\n",
            "Epoch [26/1000], Training Loss: 3.3520, Validation Loss: 3.1634, Validation Accuracy: 0.2422, Percentage:24.2157%\n",
            "Epoch [27/1000], Training Loss: 3.3460, Validation Loss: 3.1294, Validation Accuracy: 0.2451, Percentage:24.5098%\n",
            "Epoch [28/1000], Training Loss: 3.2944, Validation Loss: 3.1124, Validation Accuracy: 0.2402, Percentage:24.0196%\n",
            "Epoch [29/1000], Training Loss: 3.3193, Validation Loss: 3.1255, Validation Accuracy: 0.2422, Percentage:24.2157%\n",
            "Epoch [30/1000], Training Loss: 3.2229, Validation Loss: 3.0635, Validation Accuracy: 0.2578, Percentage:25.7843%\n",
            "Epoch [31/1000], Training Loss: 3.2083, Validation Loss: 3.0509, Validation Accuracy: 0.2765, Percentage:27.6471%\n",
            "Epoch [32/1000], Training Loss: 3.2345, Validation Loss: 3.0409, Validation Accuracy: 0.2735, Percentage:27.3529%\n",
            "Epoch [33/1000], Training Loss: 3.2061, Validation Loss: 3.0135, Validation Accuracy: 0.2765, Percentage:27.6471%\n",
            "Epoch [34/1000], Training Loss: 3.1474, Validation Loss: 2.9865, Validation Accuracy: 0.2804, Percentage:28.0392%\n",
            "Epoch [35/1000], Training Loss: 3.1329, Validation Loss: 2.9886, Validation Accuracy: 0.2716, Percentage:27.1569%\n",
            "Epoch [36/1000], Training Loss: 3.0957, Validation Loss: 2.9666, Validation Accuracy: 0.2843, Percentage:28.4314%\n",
            "Epoch [37/1000], Training Loss: 3.0602, Validation Loss: 2.9307, Validation Accuracy: 0.2794, Percentage:27.9412%\n",
            "Epoch [38/1000], Training Loss: 3.0295, Validation Loss: 2.9871, Validation Accuracy: 0.2804, Percentage:28.0392%\n",
            "Epoch [39/1000], Training Loss: 3.0423, Validation Loss: 2.9188, Validation Accuracy: 0.2971, Percentage:29.7059%\n",
            "Epoch [40/1000], Training Loss: 2.9588, Validation Loss: 2.8777, Validation Accuracy: 0.3029, Percentage:30.2941%\n",
            "Epoch [41/1000], Training Loss: 2.9295, Validation Loss: 2.8581, Validation Accuracy: 0.3088, Percentage:30.8824%\n",
            "Epoch [42/1000], Training Loss: 2.9008, Validation Loss: 2.8487, Validation Accuracy: 0.3137, Percentage:31.3725%\n",
            "Epoch [43/1000], Training Loss: 2.9273, Validation Loss: 2.8464, Validation Accuracy: 0.3098, Percentage:30.9804%\n",
            "Epoch [44/1000], Training Loss: 2.9797, Validation Loss: 2.8388, Validation Accuracy: 0.3029, Percentage:30.2941%\n",
            "Epoch [45/1000], Training Loss: 2.9374, Validation Loss: 2.8323, Validation Accuracy: 0.3049, Percentage:30.4902%\n",
            "Epoch [46/1000], Training Loss: 2.8109, Validation Loss: 2.8219, Validation Accuracy: 0.3157, Percentage:31.5686%\n",
            "Epoch [47/1000], Training Loss: 2.8410, Validation Loss: 2.8386, Validation Accuracy: 0.2902, Percentage:29.0196%\n",
            "Epoch [48/1000], Training Loss: 2.8932, Validation Loss: 2.8120, Validation Accuracy: 0.3147, Percentage:31.4706%\n",
            "Epoch [49/1000], Training Loss: 2.8270, Validation Loss: 2.7750, Validation Accuracy: 0.3069, Percentage:30.6863%\n",
            "Epoch [50/1000], Training Loss: 2.8403, Validation Loss: 2.7726, Validation Accuracy: 0.3245, Percentage:32.4510%\n",
            "Epoch [51/1000], Training Loss: 2.7974, Validation Loss: 2.7636, Validation Accuracy: 0.3176, Percentage:31.7647%\n",
            "Epoch [52/1000], Training Loss: 2.7052, Validation Loss: 2.7305, Validation Accuracy: 0.3225, Percentage:32.2549%\n",
            "Epoch [53/1000], Training Loss: 2.7172, Validation Loss: 2.7407, Validation Accuracy: 0.3108, Percentage:31.0784%\n",
            "Epoch [54/1000], Training Loss: 2.7584, Validation Loss: 2.7545, Validation Accuracy: 0.3235, Percentage:32.3529%\n",
            "Epoch [55/1000], Training Loss: 2.7355, Validation Loss: 2.7538, Validation Accuracy: 0.3294, Percentage:32.9412%\n",
            "Epoch [56/1000], Training Loss: 2.6843, Validation Loss: 2.7236, Validation Accuracy: 0.3255, Percentage:32.5490%\n",
            "Epoch [57/1000], Training Loss: 2.7284, Validation Loss: 2.6932, Validation Accuracy: 0.3402, Percentage:34.0196%\n",
            "Epoch [58/1000], Training Loss: 2.6279, Validation Loss: 2.7095, Validation Accuracy: 0.3539, Percentage:35.3922%\n",
            "Epoch [59/1000], Training Loss: 2.5978, Validation Loss: 2.6932, Validation Accuracy: 0.3422, Percentage:34.2157%\n",
            "Epoch [60/1000], Training Loss: 2.6933, Validation Loss: 2.6692, Validation Accuracy: 0.3510, Percentage:35.0980%\n",
            "Epoch [61/1000], Training Loss: 2.6566, Validation Loss: 2.6786, Validation Accuracy: 0.3431, Percentage:34.3137%\n",
            "Epoch [62/1000], Training Loss: 2.5697, Validation Loss: 2.6765, Validation Accuracy: 0.3490, Percentage:34.9020%\n",
            "Epoch [63/1000], Training Loss: 2.5673, Validation Loss: 2.6652, Validation Accuracy: 0.3520, Percentage:35.1961%\n",
            "Epoch [64/1000], Training Loss: 2.5909, Validation Loss: 2.6842, Validation Accuracy: 0.3422, Percentage:34.2157%\n",
            "Epoch [65/1000], Training Loss: 2.5367, Validation Loss: 2.7157, Validation Accuracy: 0.3461, Percentage:34.6078%\n",
            "Epoch [66/1000], Training Loss: 2.5029, Validation Loss: 2.6693, Validation Accuracy: 0.3471, Percentage:34.7059%\n",
            "Epoch [67/1000], Training Loss: 2.5411, Validation Loss: 2.6196, Validation Accuracy: 0.3618, Percentage:36.1765%\n",
            "Epoch [68/1000], Training Loss: 2.5445, Validation Loss: 2.6536, Validation Accuracy: 0.3588, Percentage:35.8824%\n",
            "Epoch [69/1000], Training Loss: 2.5052, Validation Loss: 2.6374, Validation Accuracy: 0.3539, Percentage:35.3922%\n",
            "Epoch [70/1000], Training Loss: 2.4903, Validation Loss: 2.6242, Validation Accuracy: 0.3598, Percentage:35.9804%\n",
            "Epoch [71/1000], Training Loss: 2.4248, Validation Loss: 2.6392, Validation Accuracy: 0.3559, Percentage:35.5882%\n",
            "Epoch [72/1000], Training Loss: 2.4671, Validation Loss: 2.6277, Validation Accuracy: 0.3647, Percentage:36.4706%\n",
            "Epoch [73/1000], Training Loss: 2.4161, Validation Loss: 2.5777, Validation Accuracy: 0.3598, Percentage:35.9804%\n",
            "Epoch [74/1000], Training Loss: 2.3677, Validation Loss: 2.6013, Validation Accuracy: 0.3637, Percentage:36.3725%\n",
            "Epoch [75/1000], Training Loss: 2.4367, Validation Loss: 2.6017, Validation Accuracy: 0.3696, Percentage:36.9608%\n",
            "Epoch [76/1000], Training Loss: 2.4667, Validation Loss: 2.6121, Validation Accuracy: 0.3500, Percentage:35.0000%\n",
            "Epoch [77/1000], Training Loss: 2.4198, Validation Loss: 2.6036, Validation Accuracy: 0.3471, Percentage:34.7059%\n",
            "Epoch [78/1000], Training Loss: 2.4132, Validation Loss: 2.5775, Validation Accuracy: 0.3765, Percentage:37.6471%\n",
            "Epoch [79/1000], Training Loss: 2.3709, Validation Loss: 2.6181, Validation Accuracy: 0.3686, Percentage:36.8627%\n",
            "Epoch [80/1000], Training Loss: 2.3226, Validation Loss: 2.5879, Validation Accuracy: 0.3578, Percentage:35.7843%\n",
            "Epoch [81/1000], Training Loss: 2.3641, Validation Loss: 2.6000, Validation Accuracy: 0.3765, Percentage:37.6471%\n",
            "Epoch [82/1000], Training Loss: 2.2831, Validation Loss: 2.5415, Validation Accuracy: 0.3745, Percentage:37.4510%\n",
            "Epoch [83/1000], Training Loss: 2.2590, Validation Loss: 2.5866, Validation Accuracy: 0.3824, Percentage:38.2353%\n",
            "Epoch [84/1000], Training Loss: 2.3333, Validation Loss: 2.5611, Validation Accuracy: 0.3833, Percentage:38.3333%\n",
            "Epoch [85/1000], Training Loss: 2.3089, Validation Loss: 2.5313, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [86/1000], Training Loss: 2.3355, Validation Loss: 2.5364, Validation Accuracy: 0.3824, Percentage:38.2353%\n",
            "Epoch [87/1000], Training Loss: 2.2432, Validation Loss: 2.5731, Validation Accuracy: 0.3725, Percentage:37.2549%\n",
            "Epoch [88/1000], Training Loss: 2.2310, Validation Loss: 2.5625, Validation Accuracy: 0.3794, Percentage:37.9412%\n",
            "Epoch [89/1000], Training Loss: 2.2872, Validation Loss: 2.5328, Validation Accuracy: 0.3775, Percentage:37.7451%\n",
            "Epoch [90/1000], Training Loss: 2.2144, Validation Loss: 2.5426, Validation Accuracy: 0.3814, Percentage:38.1373%\n",
            "Epoch [91/1000], Training Loss: 2.1580, Validation Loss: 2.5219, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [92/1000], Training Loss: 2.1930, Validation Loss: 2.5624, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [93/1000], Training Loss: 2.2019, Validation Loss: 2.5554, Validation Accuracy: 0.3912, Percentage:39.1176%\n",
            "Epoch [94/1000], Training Loss: 2.1613, Validation Loss: 2.5676, Validation Accuracy: 0.3794, Percentage:37.9412%\n",
            "Epoch [95/1000], Training Loss: 2.1969, Validation Loss: 2.5507, Validation Accuracy: 0.3775, Percentage:37.7451%\n",
            "Epoch [96/1000], Training Loss: 2.1837, Validation Loss: 2.5379, Validation Accuracy: 0.3882, Percentage:38.8235%\n",
            "Epoch [97/1000], Training Loss: 2.1301, Validation Loss: 2.5390, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [98/1000], Training Loss: 2.1357, Validation Loss: 2.6048, Validation Accuracy: 0.3794, Percentage:37.9412%\n",
            "Epoch [99/1000], Training Loss: 2.0833, Validation Loss: 2.5478, Validation Accuracy: 0.3882, Percentage:38.8235%\n",
            "Epoch [100/1000], Training Loss: 2.1305, Validation Loss: 2.5081, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [101/1000], Training Loss: 2.0621, Validation Loss: 2.5193, Validation Accuracy: 0.3824, Percentage:38.2353%\n",
            "Epoch [102/1000], Training Loss: 2.1837, Validation Loss: 2.5861, Validation Accuracy: 0.3775, Percentage:37.7451%\n",
            "Epoch [103/1000], Training Loss: 2.0907, Validation Loss: 2.4957, Validation Accuracy: 0.3902, Percentage:39.0196%\n",
            "Epoch [104/1000], Training Loss: 2.0839, Validation Loss: 2.5429, Validation Accuracy: 0.3853, Percentage:38.5294%\n",
            "Epoch [105/1000], Training Loss: 2.1013, Validation Loss: 2.5368, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [106/1000], Training Loss: 2.0962, Validation Loss: 2.5259, Validation Accuracy: 0.3912, Percentage:39.1176%\n",
            "Epoch [107/1000], Training Loss: 2.0429, Validation Loss: 2.5803, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [108/1000], Training Loss: 2.0480, Validation Loss: 2.5190, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [109/1000], Training Loss: 2.0643, Validation Loss: 2.5216, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [110/1000], Training Loss: 2.0711, Validation Loss: 2.5260, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [111/1000], Training Loss: 2.0020, Validation Loss: 2.5033, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [112/1000], Training Loss: 2.0715, Validation Loss: 2.5484, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [113/1000], Training Loss: 2.0194, Validation Loss: 2.5279, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [114/1000], Training Loss: 2.0144, Validation Loss: 2.5419, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [115/1000], Training Loss: 2.0104, Validation Loss: 2.5155, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [116/1000], Training Loss: 1.9601, Validation Loss: 2.5306, Validation Accuracy: 0.3912, Percentage:39.1176%\n",
            "Epoch [117/1000], Training Loss: 2.0694, Validation Loss: 2.5086, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [118/1000], Training Loss: 2.0076, Validation Loss: 2.5526, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [119/1000], Training Loss: 1.9283, Validation Loss: 2.5427, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [120/1000], Training Loss: 1.9392, Validation Loss: 2.5405, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [121/1000], Training Loss: 1.9517, Validation Loss: 2.5718, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [122/1000], Training Loss: 1.9960, Validation Loss: 2.5162, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [123/1000], Training Loss: 1.9299, Validation Loss: 2.5348, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [124/1000], Training Loss: 1.9468, Validation Loss: 2.6360, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [125/1000], Training Loss: 1.9469, Validation Loss: 2.5145, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [126/1000], Training Loss: 1.9406, Validation Loss: 2.5174, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [127/1000], Training Loss: 1.8650, Validation Loss: 2.5310, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [128/1000], Training Loss: 1.9543, Validation Loss: 2.5799, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [129/1000], Training Loss: 1.8315, Validation Loss: 2.5438, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [130/1000], Training Loss: 1.9171, Validation Loss: 2.5039, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [131/1000], Training Loss: 1.8920, Validation Loss: 2.5035, Validation Accuracy: 0.4176, Percentage:41.7647%\n",
            "Epoch [132/1000], Training Loss: 1.8460, Validation Loss: 2.5209, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [133/1000], Training Loss: 1.8505, Validation Loss: 2.5510, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [134/1000], Training Loss: 1.8516, Validation Loss: 2.5533, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [135/1000], Training Loss: 1.8593, Validation Loss: 2.5816, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [136/1000], Training Loss: 1.8717, Validation Loss: 2.6033, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [137/1000], Training Loss: 1.8285, Validation Loss: 2.5401, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [138/1000], Training Loss: 1.8152, Validation Loss: 2.6010, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [139/1000], Training Loss: 1.8137, Validation Loss: 2.5187, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [140/1000], Training Loss: 1.8378, Validation Loss: 2.5437, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [141/1000], Training Loss: 1.7902, Validation Loss: 2.5757, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [142/1000], Training Loss: 1.8126, Validation Loss: 2.5316, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [143/1000], Training Loss: 1.8250, Validation Loss: 2.4987, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [144/1000], Training Loss: 1.8729, Validation Loss: 2.5579, Validation Accuracy: 0.4206, Percentage:42.0588%\n",
            "Epoch [145/1000], Training Loss: 1.6829, Validation Loss: 2.5909, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [146/1000], Training Loss: 1.8410, Validation Loss: 2.5168, Validation Accuracy: 0.4225, Percentage:42.2549%\n",
            "Epoch [147/1000], Training Loss: 1.8259, Validation Loss: 2.5430, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [148/1000], Training Loss: 1.7323, Validation Loss: 2.5937, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [149/1000], Training Loss: 1.7827, Validation Loss: 2.5755, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [150/1000], Training Loss: 1.7658, Validation Loss: 2.5551, Validation Accuracy: 0.4284, Percentage:42.8431%\n",
            "Epoch [151/1000], Training Loss: 1.6903, Validation Loss: 2.5228, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [152/1000], Training Loss: 1.8001, Validation Loss: 2.5394, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [153/1000], Training Loss: 1.6995, Validation Loss: 2.5230, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [154/1000], Training Loss: 1.7337, Validation Loss: 2.5494, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [155/1000], Training Loss: 1.7218, Validation Loss: 2.6161, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [156/1000], Training Loss: 1.7241, Validation Loss: 2.5661, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [157/1000], Training Loss: 1.7301, Validation Loss: 2.5262, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [158/1000], Training Loss: 1.6994, Validation Loss: 2.5086, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [159/1000], Training Loss: 1.6996, Validation Loss: 2.5393, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [160/1000], Training Loss: 1.6784, Validation Loss: 2.5262, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [161/1000], Training Loss: 1.8157, Validation Loss: 2.6616, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [162/1000], Training Loss: 1.6290, Validation Loss: 2.5620, Validation Accuracy: 0.4284, Percentage:42.8431%\n",
            "Epoch [163/1000], Training Loss: 1.6257, Validation Loss: 2.5889, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [164/1000], Training Loss: 1.7261, Validation Loss: 2.5994, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [165/1000], Training Loss: 1.6649, Validation Loss: 2.6168, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [166/1000], Training Loss: 1.6233, Validation Loss: 2.6101, Validation Accuracy: 0.4206, Percentage:42.0588%\n",
            "Epoch [167/1000], Training Loss: 1.7200, Validation Loss: 2.5455, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [168/1000], Training Loss: 1.6685, Validation Loss: 2.6109, Validation Accuracy: 0.4265, Percentage:42.6471%\n",
            "Epoch [169/1000], Training Loss: 1.6818, Validation Loss: 2.5763, Validation Accuracy: 0.4225, Percentage:42.2549%\n",
            "Epoch [170/1000], Training Loss: 1.6964, Validation Loss: 2.5309, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [171/1000], Training Loss: 1.6856, Validation Loss: 2.5739, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [172/1000], Training Loss: 1.5744, Validation Loss: 2.5738, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [173/1000], Training Loss: 1.5804, Validation Loss: 2.6268, Validation Accuracy: 0.4225, Percentage:42.2549%\n",
            "Epoch [174/1000], Training Loss: 1.6143, Validation Loss: 2.6066, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [175/1000], Training Loss: 1.6285, Validation Loss: 2.5700, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [176/1000], Training Loss: 1.6226, Validation Loss: 2.6116, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [177/1000], Training Loss: 1.6683, Validation Loss: 2.5999, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [178/1000], Training Loss: 1.5693, Validation Loss: 2.6006, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [179/1000], Training Loss: 1.5753, Validation Loss: 2.5909, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [180/1000], Training Loss: 1.5008, Validation Loss: 2.5957, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [181/1000], Training Loss: 1.6209, Validation Loss: 2.6549, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [182/1000], Training Loss: 1.6104, Validation Loss: 2.5618, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [183/1000], Training Loss: 1.6328, Validation Loss: 2.5772, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [184/1000], Training Loss: 1.6645, Validation Loss: 2.5885, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [185/1000], Training Loss: 1.5583, Validation Loss: 2.5862, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [186/1000], Training Loss: 1.5524, Validation Loss: 2.6220, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [187/1000], Training Loss: 1.4921, Validation Loss: 2.6610, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [188/1000], Training Loss: 1.6001, Validation Loss: 2.6507, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [189/1000], Training Loss: 1.5041, Validation Loss: 2.6140, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [190/1000], Training Loss: 1.5984, Validation Loss: 2.6118, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [191/1000], Training Loss: 1.5610, Validation Loss: 2.6319, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [192/1000], Training Loss: 1.5229, Validation Loss: 2.6195, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [193/1000], Training Loss: 1.5379, Validation Loss: 2.6473, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [194/1000], Training Loss: 1.5912, Validation Loss: 2.6715, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [195/1000], Training Loss: 1.5012, Validation Loss: 2.6328, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [196/1000], Training Loss: 1.4966, Validation Loss: 2.7156, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [197/1000], Training Loss: 1.4647, Validation Loss: 2.6970, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [198/1000], Training Loss: 1.5261, Validation Loss: 2.6835, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [199/1000], Training Loss: 1.4840, Validation Loss: 2.6548, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [200/1000], Training Loss: 1.5477, Validation Loss: 2.7019, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [201/1000], Training Loss: 1.5546, Validation Loss: 2.6892, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [202/1000], Training Loss: 1.5037, Validation Loss: 2.6508, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [203/1000], Training Loss: 1.5047, Validation Loss: 2.7099, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [204/1000], Training Loss: 1.4991, Validation Loss: 2.7511, Validation Accuracy: 0.4265, Percentage:42.6471%\n",
            "Epoch [205/1000], Training Loss: 1.5573, Validation Loss: 2.6798, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [206/1000], Training Loss: 1.4595, Validation Loss: 2.6000, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [207/1000], Training Loss: 1.4474, Validation Loss: 2.6568, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [208/1000], Training Loss: 1.4809, Validation Loss: 2.6594, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [209/1000], Training Loss: 1.4584, Validation Loss: 2.7248, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [210/1000], Training Loss: 1.5310, Validation Loss: 2.6905, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [211/1000], Training Loss: 1.4329, Validation Loss: 2.6600, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [212/1000], Training Loss: 1.3952, Validation Loss: 2.7068, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [213/1000], Training Loss: 1.5053, Validation Loss: 2.6836, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [214/1000], Training Loss: 1.4267, Validation Loss: 2.7039, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [215/1000], Training Loss: 1.4684, Validation Loss: 2.6059, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [216/1000], Training Loss: 1.4719, Validation Loss: 2.6906, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [217/1000], Training Loss: 1.4226, Validation Loss: 2.7051, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [218/1000], Training Loss: 1.4208, Validation Loss: 2.7072, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [219/1000], Training Loss: 1.4335, Validation Loss: 2.7214, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [220/1000], Training Loss: 1.4171, Validation Loss: 2.6151, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [221/1000], Training Loss: 1.4384, Validation Loss: 2.6506, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [222/1000], Training Loss: 1.3671, Validation Loss: 2.7457, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [223/1000], Training Loss: 1.4040, Validation Loss: 2.6708, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [224/1000], Training Loss: 1.3694, Validation Loss: 2.7764, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [225/1000], Training Loss: 1.4363, Validation Loss: 2.7099, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [226/1000], Training Loss: 1.3186, Validation Loss: 2.6915, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [227/1000], Training Loss: 1.3753, Validation Loss: 2.8042, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [228/1000], Training Loss: 1.3996, Validation Loss: 2.6512, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [229/1000], Training Loss: 1.4882, Validation Loss: 2.7101, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [230/1000], Training Loss: 1.4183, Validation Loss: 2.6420, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [231/1000], Training Loss: 1.3754, Validation Loss: 2.6885, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [232/1000], Training Loss: 1.4791, Validation Loss: 2.6856, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [233/1000], Training Loss: 1.4517, Validation Loss: 2.6704, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [234/1000], Training Loss: 1.3533, Validation Loss: 2.7207, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [235/1000], Training Loss: 1.3751, Validation Loss: 2.7776, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [236/1000], Training Loss: 1.3986, Validation Loss: 2.7582, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [237/1000], Training Loss: 1.3620, Validation Loss: 2.6606, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [238/1000], Training Loss: 1.2996, Validation Loss: 2.7687, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [239/1000], Training Loss: 1.4094, Validation Loss: 2.6806, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [240/1000], Training Loss: 1.3444, Validation Loss: 2.8164, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [241/1000], Training Loss: 1.3723, Validation Loss: 2.7176, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [242/1000], Training Loss: 1.4068, Validation Loss: 2.7622, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [243/1000], Training Loss: 1.4347, Validation Loss: 2.6532, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [244/1000], Training Loss: 1.2913, Validation Loss: 2.7660, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [245/1000], Training Loss: 1.3644, Validation Loss: 2.6512, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [246/1000], Training Loss: 1.3372, Validation Loss: 2.6948, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [247/1000], Training Loss: 1.2819, Validation Loss: 2.7652, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [248/1000], Training Loss: 1.4068, Validation Loss: 2.7166, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [249/1000], Training Loss: 1.4029, Validation Loss: 2.7706, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [250/1000], Training Loss: 1.3658, Validation Loss: 2.7838, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [251/1000], Training Loss: 1.3388, Validation Loss: 2.6942, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [252/1000], Training Loss: 1.3257, Validation Loss: 2.6976, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [253/1000], Training Loss: 1.3679, Validation Loss: 2.7580, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [254/1000], Training Loss: 1.2934, Validation Loss: 2.7524, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [255/1000], Training Loss: 1.3460, Validation Loss: 2.7725, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [256/1000], Training Loss: 1.3673, Validation Loss: 2.8139, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [257/1000], Training Loss: 1.4250, Validation Loss: 2.6964, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [258/1000], Training Loss: 1.2883, Validation Loss: 2.7605, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [259/1000], Training Loss: 1.2693, Validation Loss: 2.7479, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [260/1000], Training Loss: 1.2477, Validation Loss: 2.8175, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [261/1000], Training Loss: 1.2866, Validation Loss: 2.7925, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [262/1000], Training Loss: 1.2688, Validation Loss: 2.7647, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [263/1000], Training Loss: 1.3150, Validation Loss: 2.7603, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [264/1000], Training Loss: 1.2445, Validation Loss: 2.7554, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [265/1000], Training Loss: 1.3292, Validation Loss: 2.8614, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [266/1000], Training Loss: 1.3466, Validation Loss: 2.7468, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [267/1000], Training Loss: 1.3553, Validation Loss: 2.8670, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [268/1000], Training Loss: 1.2707, Validation Loss: 2.7944, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [269/1000], Training Loss: 1.2507, Validation Loss: 2.7301, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [270/1000], Training Loss: 1.3175, Validation Loss: 2.7980, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [271/1000], Training Loss: 1.2858, Validation Loss: 2.7165, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [272/1000], Training Loss: 1.3433, Validation Loss: 2.7271, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [273/1000], Training Loss: 1.2333, Validation Loss: 2.7982, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [274/1000], Training Loss: 1.1846, Validation Loss: 2.8428, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [275/1000], Training Loss: 1.2921, Validation Loss: 2.7466, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [276/1000], Training Loss: 1.2222, Validation Loss: 2.8598, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [277/1000], Training Loss: 1.3314, Validation Loss: 2.8359, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [278/1000], Training Loss: 1.1998, Validation Loss: 2.8316, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [279/1000], Training Loss: 1.2794, Validation Loss: 2.7864, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [280/1000], Training Loss: 1.2429, Validation Loss: 2.9201, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [281/1000], Training Loss: 1.2442, Validation Loss: 2.8168, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [282/1000], Training Loss: 1.2464, Validation Loss: 2.8037, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [283/1000], Training Loss: 1.2752, Validation Loss: 2.7958, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [284/1000], Training Loss: 1.2376, Validation Loss: 2.8702, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [285/1000], Training Loss: 1.2562, Validation Loss: 2.8017, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [286/1000], Training Loss: 1.2241, Validation Loss: 2.8068, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [287/1000], Training Loss: 1.1863, Validation Loss: 2.8203, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [288/1000], Training Loss: 1.1821, Validation Loss: 2.8461, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [289/1000], Training Loss: 1.2367, Validation Loss: 2.8585, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [290/1000], Training Loss: 1.2141, Validation Loss: 2.8173, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [291/1000], Training Loss: 1.2151, Validation Loss: 2.7882, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [292/1000], Training Loss: 1.2430, Validation Loss: 2.8815, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [293/1000], Training Loss: 1.2335, Validation Loss: 2.8537, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [294/1000], Training Loss: 1.1807, Validation Loss: 2.7823, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [295/1000], Training Loss: 1.2380, Validation Loss: 2.8692, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [296/1000], Training Loss: 1.2377, Validation Loss: 2.8312, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [297/1000], Training Loss: 1.1559, Validation Loss: 2.9190, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [298/1000], Training Loss: 1.2281, Validation Loss: 2.9905, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [299/1000], Training Loss: 1.2111, Validation Loss: 2.8746, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [300/1000], Training Loss: 1.2502, Validation Loss: 2.8846, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [301/1000], Training Loss: 1.1655, Validation Loss: 2.8691, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [302/1000], Training Loss: 1.1957, Validation Loss: 2.8852, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [303/1000], Training Loss: 1.1886, Validation Loss: 2.9547, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [304/1000], Training Loss: 1.1513, Validation Loss: 2.8939, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [305/1000], Training Loss: 1.1629, Validation Loss: 2.8737, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [306/1000], Training Loss: 1.1285, Validation Loss: 2.8704, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [307/1000], Training Loss: 1.1468, Validation Loss: 2.9688, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [308/1000], Training Loss: 1.2511, Validation Loss: 2.9347, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [309/1000], Training Loss: 1.1617, Validation Loss: 3.1673, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [310/1000], Training Loss: 1.1220, Validation Loss: 2.9588, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [311/1000], Training Loss: 1.1817, Validation Loss: 2.8549, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [312/1000], Training Loss: 1.2867, Validation Loss: 2.7817, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [313/1000], Training Loss: 1.2198, Validation Loss: 2.8266, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [314/1000], Training Loss: 1.1129, Validation Loss: 2.9539, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [315/1000], Training Loss: 1.2042, Validation Loss: 2.9859, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [316/1000], Training Loss: 1.1567, Validation Loss: 2.8917, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [317/1000], Training Loss: 1.1953, Validation Loss: 2.8538, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [318/1000], Training Loss: 1.1118, Validation Loss: 3.0252, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [319/1000], Training Loss: 1.2744, Validation Loss: 2.8254, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [320/1000], Training Loss: 1.1864, Validation Loss: 2.9167, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [321/1000], Training Loss: 1.1617, Validation Loss: 2.9023, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [322/1000], Training Loss: 1.2444, Validation Loss: 2.9534, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [323/1000], Training Loss: 1.1103, Validation Loss: 3.0066, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [324/1000], Training Loss: 1.1674, Validation Loss: 3.0051, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [325/1000], Training Loss: 1.1575, Validation Loss: 2.9297, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [326/1000], Training Loss: 1.0951, Validation Loss: 2.9856, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [327/1000], Training Loss: 1.1201, Validation Loss: 2.9741, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [328/1000], Training Loss: 1.1288, Validation Loss: 2.8585, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [329/1000], Training Loss: 1.2082, Validation Loss: 2.8080, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [330/1000], Training Loss: 1.1504, Validation Loss: 2.9251, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [331/1000], Training Loss: 1.1297, Validation Loss: 2.9167, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [332/1000], Training Loss: 1.1786, Validation Loss: 2.9813, Validation Accuracy: 0.4608, Percentage:46.0784%\n",
            "Epoch [333/1000], Training Loss: 1.1059, Validation Loss: 2.9364, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [334/1000], Training Loss: 1.0985, Validation Loss: 2.9160, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [335/1000], Training Loss: 1.1431, Validation Loss: 2.9940, Validation Accuracy: 0.4618, Percentage:46.1765%\n",
            "Epoch [336/1000], Training Loss: 1.1201, Validation Loss: 2.9433, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [337/1000], Training Loss: 1.1214, Validation Loss: 3.0308, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [338/1000], Training Loss: 1.1476, Validation Loss: 2.9128, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [339/1000], Training Loss: 1.1707, Validation Loss: 2.9285, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [340/1000], Training Loss: 1.1438, Validation Loss: 3.0361, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [341/1000], Training Loss: 1.0241, Validation Loss: 2.9519, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [342/1000], Training Loss: 1.1203, Validation Loss: 3.0398, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [343/1000], Training Loss: 1.1310, Validation Loss: 3.0469, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [344/1000], Training Loss: 1.1166, Validation Loss: 3.0061, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [345/1000], Training Loss: 1.0957, Validation Loss: 2.9877, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [346/1000], Training Loss: 1.0230, Validation Loss: 2.9860, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [347/1000], Training Loss: 1.0725, Validation Loss: 3.0254, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [348/1000], Training Loss: 1.1004, Validation Loss: 2.9872, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [349/1000], Training Loss: 1.1405, Validation Loss: 3.0506, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [350/1000], Training Loss: 1.0602, Validation Loss: 3.2448, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [351/1000], Training Loss: 1.1447, Validation Loss: 3.0080, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [352/1000], Training Loss: 1.0619, Validation Loss: 2.9966, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [353/1000], Training Loss: 1.0407, Validation Loss: 3.0374, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [354/1000], Training Loss: 1.0420, Validation Loss: 3.0256, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [355/1000], Training Loss: 1.1044, Validation Loss: 3.0846, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [356/1000], Training Loss: 1.0393, Validation Loss: 2.9778, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [357/1000], Training Loss: 1.0974, Validation Loss: 3.0120, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [358/1000], Training Loss: 1.1274, Validation Loss: 3.0920, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [359/1000], Training Loss: 1.1187, Validation Loss: 2.9396, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [360/1000], Training Loss: 1.0517, Validation Loss: 3.0388, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [361/1000], Training Loss: 1.0691, Validation Loss: 2.9460, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [362/1000], Training Loss: 1.1418, Validation Loss: 2.9039, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [363/1000], Training Loss: 1.0674, Validation Loss: 2.9153, Validation Accuracy: 0.4657, Percentage:46.5686%\n",
            "Epoch [364/1000], Training Loss: 1.0575, Validation Loss: 3.1257, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [365/1000], Training Loss: 1.1139, Validation Loss: 2.9831, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [366/1000], Training Loss: 1.0888, Validation Loss: 3.0350, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [367/1000], Training Loss: 1.0403, Validation Loss: 3.0303, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [368/1000], Training Loss: 1.0984, Validation Loss: 3.0284, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [369/1000], Training Loss: 1.1248, Validation Loss: 2.9746, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [370/1000], Training Loss: 1.0523, Validation Loss: 2.9446, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [371/1000], Training Loss: 1.0366, Validation Loss: 2.9810, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [372/1000], Training Loss: 1.1389, Validation Loss: 2.8911, Validation Accuracy: 0.4647, Percentage:46.4706%\n",
            "Epoch [373/1000], Training Loss: 1.0389, Validation Loss: 3.0090, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [374/1000], Training Loss: 1.0137, Validation Loss: 3.0188, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [375/1000], Training Loss: 1.1074, Validation Loss: 3.0924, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [376/1000], Training Loss: 1.0580, Validation Loss: 3.0374, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [377/1000], Training Loss: 1.0640, Validation Loss: 2.9711, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [378/1000], Training Loss: 1.1382, Validation Loss: 3.0041, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [379/1000], Training Loss: 0.9996, Validation Loss: 2.9381, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [380/1000], Training Loss: 1.0318, Validation Loss: 3.0394, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [381/1000], Training Loss: 1.0331, Validation Loss: 3.0293, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [382/1000], Training Loss: 1.0628, Validation Loss: 3.0634, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [383/1000], Training Loss: 1.0124, Validation Loss: 3.0447, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [384/1000], Training Loss: 1.0899, Validation Loss: 2.9623, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [385/1000], Training Loss: 1.0979, Validation Loss: 3.0260, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [386/1000], Training Loss: 1.0530, Validation Loss: 3.0223, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [387/1000], Training Loss: 1.0827, Validation Loss: 3.1288, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [388/1000], Training Loss: 1.0437, Validation Loss: 2.9855, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [389/1000], Training Loss: 1.1002, Validation Loss: 3.0258, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [390/1000], Training Loss: 1.0813, Validation Loss: 3.0316, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [391/1000], Training Loss: 1.0317, Validation Loss: 2.9956, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [392/1000], Training Loss: 1.0193, Validation Loss: 2.9708, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [393/1000], Training Loss: 1.1287, Validation Loss: 3.0465, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [394/1000], Training Loss: 1.0170, Validation Loss: 3.0262, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [395/1000], Training Loss: 0.9866, Validation Loss: 3.0997, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [396/1000], Training Loss: 1.0057, Validation Loss: 3.2114, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [397/1000], Training Loss: 1.0990, Validation Loss: 3.0718, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [398/1000], Training Loss: 1.0406, Validation Loss: 3.0259, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [399/1000], Training Loss: 1.0424, Validation Loss: 3.0322, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [400/1000], Training Loss: 0.9867, Validation Loss: 2.9723, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [401/1000], Training Loss: 0.9503, Validation Loss: 3.1455, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [402/1000], Training Loss: 0.9927, Validation Loss: 3.2883, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [403/1000], Training Loss: 1.0309, Validation Loss: 3.0814, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [404/1000], Training Loss: 1.0408, Validation Loss: 3.0800, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [405/1000], Training Loss: 1.1277, Validation Loss: 3.0406, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [406/1000], Training Loss: 1.0423, Validation Loss: 3.0742, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [407/1000], Training Loss: 0.9843, Validation Loss: 3.1242, Validation Accuracy: 0.4618, Percentage:46.1765%\n",
            "Epoch [408/1000], Training Loss: 1.0119, Validation Loss: 3.2328, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [409/1000], Training Loss: 1.0821, Validation Loss: 3.1556, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [410/1000], Training Loss: 0.9603, Validation Loss: 3.0948, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [411/1000], Training Loss: 0.9651, Validation Loss: 3.0671, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [412/1000], Training Loss: 1.0569, Validation Loss: 3.1032, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [413/1000], Training Loss: 0.9447, Validation Loss: 3.1331, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [414/1000], Training Loss: 1.0859, Validation Loss: 3.2151, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [415/1000], Training Loss: 0.9986, Validation Loss: 3.1144, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [416/1000], Training Loss: 0.9915, Validation Loss: 3.0276, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [417/1000], Training Loss: 1.0701, Validation Loss: 3.0875, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [418/1000], Training Loss: 0.9750, Validation Loss: 3.2230, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [419/1000], Training Loss: 1.0377, Validation Loss: 3.1764, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [420/1000], Training Loss: 1.0073, Validation Loss: 3.0869, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [421/1000], Training Loss: 1.0462, Validation Loss: 3.0790, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [422/1000], Training Loss: 1.0416, Validation Loss: 3.0455, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [423/1000], Training Loss: 0.9859, Validation Loss: 3.0400, Validation Accuracy: 0.4627, Percentage:46.2745%\n",
            "Epoch [424/1000], Training Loss: 0.9477, Validation Loss: 3.0560, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [425/1000], Training Loss: 0.9713, Validation Loss: 3.0645, Validation Accuracy: 0.4608, Percentage:46.0784%\n",
            "Epoch [426/1000], Training Loss: 1.0073, Validation Loss: 2.9819, Validation Accuracy: 0.4667, Percentage:46.6667%\n",
            "Epoch [427/1000], Training Loss: 0.9996, Validation Loss: 3.1556, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [428/1000], Training Loss: 0.9666, Validation Loss: 3.2129, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [429/1000], Training Loss: 1.0054, Validation Loss: 3.1276, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [430/1000], Training Loss: 0.9374, Validation Loss: 3.0809, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [431/1000], Training Loss: 0.9538, Validation Loss: 3.1310, Validation Accuracy: 0.4647, Percentage:46.4706%\n",
            "Epoch [432/1000], Training Loss: 1.0036, Validation Loss: 3.1078, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [433/1000], Training Loss: 1.0918, Validation Loss: 3.1368, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [434/1000], Training Loss: 0.9515, Validation Loss: 3.1191, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [435/1000], Training Loss: 0.9757, Validation Loss: 3.2278, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [436/1000], Training Loss: 0.9530, Validation Loss: 3.2964, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [437/1000], Training Loss: 0.9749, Validation Loss: 3.1675, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [438/1000], Training Loss: 1.0145, Validation Loss: 3.1871, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [439/1000], Training Loss: 1.0407, Validation Loss: 3.2622, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [440/1000], Training Loss: 1.0477, Validation Loss: 3.0515, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [441/1000], Training Loss: 0.9347, Validation Loss: 3.1565, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [442/1000], Training Loss: 0.9464, Validation Loss: 3.1845, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [443/1000], Training Loss: 0.9023, Validation Loss: 3.2299, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [444/1000], Training Loss: 0.9582, Validation Loss: 3.3665, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [445/1000], Training Loss: 1.0473, Validation Loss: 3.3003, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [446/1000], Training Loss: 1.0235, Validation Loss: 3.1652, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [447/1000], Training Loss: 0.9624, Validation Loss: 3.1180, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [448/1000], Training Loss: 0.9824, Validation Loss: 3.1326, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [449/1000], Training Loss: 0.9514, Validation Loss: 3.1811, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [450/1000], Training Loss: 0.9940, Validation Loss: 3.1522, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [451/1000], Training Loss: 0.9445, Validation Loss: 3.1996, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [452/1000], Training Loss: 0.8731, Validation Loss: 3.2892, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [453/1000], Training Loss: 0.9329, Validation Loss: 3.1490, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [454/1000], Training Loss: 0.9584, Validation Loss: 3.3054, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [455/1000], Training Loss: 0.9274, Validation Loss: 3.1990, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [456/1000], Training Loss: 0.9716, Validation Loss: 3.2186, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [457/1000], Training Loss: 0.9762, Validation Loss: 3.2346, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [458/1000], Training Loss: 1.0119, Validation Loss: 3.1120, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [459/1000], Training Loss: 0.9518, Validation Loss: 3.2520, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [460/1000], Training Loss: 0.9776, Validation Loss: 3.2052, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [461/1000], Training Loss: 0.9508, Validation Loss: 3.3121, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [462/1000], Training Loss: 1.0380, Validation Loss: 3.2494, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [463/1000], Training Loss: 1.0412, Validation Loss: 3.0963, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [464/1000], Training Loss: 0.9319, Validation Loss: 3.2666, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [465/1000], Training Loss: 0.8956, Validation Loss: 3.2182, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [466/1000], Training Loss: 0.9573, Validation Loss: 3.1983, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [467/1000], Training Loss: 0.9334, Validation Loss: 3.2242, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [468/1000], Training Loss: 0.9472, Validation Loss: 3.5140, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [469/1000], Training Loss: 1.0161, Validation Loss: 3.2763, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [470/1000], Training Loss: 0.9443, Validation Loss: 3.3642, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [471/1000], Training Loss: 1.0413, Validation Loss: 3.1476, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [472/1000], Training Loss: 0.9571, Validation Loss: 3.1679, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [473/1000], Training Loss: 0.9357, Validation Loss: 3.2334, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [474/1000], Training Loss: 0.9390, Validation Loss: 3.2365, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [475/1000], Training Loss: 0.8965, Validation Loss: 3.1287, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [476/1000], Training Loss: 0.9308, Validation Loss: 3.1688, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [477/1000], Training Loss: 0.9073, Validation Loss: 3.2956, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [478/1000], Training Loss: 0.9612, Validation Loss: 3.0793, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [479/1000], Training Loss: 1.0008, Validation Loss: 3.1280, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [480/1000], Training Loss: 0.8736, Validation Loss: 3.1720, Validation Accuracy: 0.4578, Percentage:45.7843%\n",
            "Epoch [481/1000], Training Loss: 0.9470, Validation Loss: 3.2909, Validation Accuracy: 0.4578, Percentage:45.7843%\n",
            "Epoch [482/1000], Training Loss: 0.9161, Validation Loss: 3.2758, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [483/1000], Training Loss: 0.9322, Validation Loss: 3.1700, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [484/1000], Training Loss: 0.9556, Validation Loss: 3.1846, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [485/1000], Training Loss: 1.0366, Validation Loss: 3.2248, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [486/1000], Training Loss: 0.9170, Validation Loss: 3.1610, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [487/1000], Training Loss: 0.9556, Validation Loss: 3.1709, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [488/1000], Training Loss: 0.8822, Validation Loss: 3.2515, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [489/1000], Training Loss: 0.8807, Validation Loss: 3.2133, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [490/1000], Training Loss: 0.9273, Validation Loss: 3.2779, Validation Accuracy: 0.4618, Percentage:46.1765%\n",
            "Epoch [491/1000], Training Loss: 0.9993, Validation Loss: 3.1614, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [492/1000], Training Loss: 0.9164, Validation Loss: 3.2480, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [493/1000], Training Loss: 0.8432, Validation Loss: 3.3639, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [494/1000], Training Loss: 1.0056, Validation Loss: 3.2209, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [495/1000], Training Loss: 0.9055, Validation Loss: 3.2484, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [496/1000], Training Loss: 0.9309, Validation Loss: 3.4173, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [497/1000], Training Loss: 0.9179, Validation Loss: 3.2751, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [498/1000], Training Loss: 0.9579, Validation Loss: 3.2421, Validation Accuracy: 0.4578, Percentage:45.7843%\n",
            "Epoch [499/1000], Training Loss: 0.9125, Validation Loss: 3.3523, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [500/1000], Training Loss: 0.8677, Validation Loss: 3.2447, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [501/1000], Training Loss: 0.9278, Validation Loss: 3.3714, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [502/1000], Training Loss: 0.8723, Validation Loss: 3.2723, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [503/1000], Training Loss: 0.8641, Validation Loss: 3.2671, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [504/1000], Training Loss: 0.8857, Validation Loss: 3.2051, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [505/1000], Training Loss: 0.9239, Validation Loss: 3.3342, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [506/1000], Training Loss: 0.8533, Validation Loss: 3.3307, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [507/1000], Training Loss: 0.8902, Validation Loss: 3.2502, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [508/1000], Training Loss: 0.9218, Validation Loss: 3.1459, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [509/1000], Training Loss: 0.9319, Validation Loss: 3.2630, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [510/1000], Training Loss: 0.8361, Validation Loss: 3.1892, Validation Accuracy: 0.4657, Percentage:46.5686%\n",
            "Epoch [511/1000], Training Loss: 0.8437, Validation Loss: 3.3365, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [512/1000], Training Loss: 0.9257, Validation Loss: 3.2527, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [513/1000], Training Loss: 0.9748, Validation Loss: 3.1379, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [514/1000], Training Loss: 0.8643, Validation Loss: 3.1200, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [515/1000], Training Loss: 0.8273, Validation Loss: 3.2111, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [516/1000], Training Loss: 0.9440, Validation Loss: 3.2975, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [517/1000], Training Loss: 0.8333, Validation Loss: 3.2073, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [518/1000], Training Loss: 0.8780, Validation Loss: 3.2634, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [519/1000], Training Loss: 0.8985, Validation Loss: 3.3144, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [520/1000], Training Loss: 0.8871, Validation Loss: 3.3221, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [521/1000], Training Loss: 0.8998, Validation Loss: 3.3728, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [522/1000], Training Loss: 0.8349, Validation Loss: 3.1967, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [523/1000], Training Loss: 0.8491, Validation Loss: 3.3310, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [524/1000], Training Loss: 0.9003, Validation Loss: 3.3904, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [525/1000], Training Loss: 0.8067, Validation Loss: 3.3342, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [526/1000], Training Loss: 0.8965, Validation Loss: 3.3759, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [527/1000], Training Loss: 0.8238, Validation Loss: 3.2542, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [528/1000], Training Loss: 0.8962, Validation Loss: 3.3998, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [529/1000], Training Loss: 0.8420, Validation Loss: 3.2808, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [530/1000], Training Loss: 0.8675, Validation Loss: 3.3500, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [531/1000], Training Loss: 0.8851, Validation Loss: 3.4581, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [532/1000], Training Loss: 0.9678, Validation Loss: 3.2894, Validation Accuracy: 0.4598, Percentage:45.9804%\n",
            "Epoch [533/1000], Training Loss: 0.9410, Validation Loss: 3.1528, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [534/1000], Training Loss: 0.9189, Validation Loss: 3.3535, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [535/1000], Training Loss: 0.8897, Validation Loss: 3.4255, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [536/1000], Training Loss: 0.9085, Validation Loss: 3.3306, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [537/1000], Training Loss: 0.8628, Validation Loss: 3.3016, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [538/1000], Training Loss: 0.9239, Validation Loss: 3.2264, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [539/1000], Training Loss: 0.8472, Validation Loss: 3.4331, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [540/1000], Training Loss: 0.8916, Validation Loss: 3.3812, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [541/1000], Training Loss: 0.8896, Validation Loss: 3.2435, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [542/1000], Training Loss: 0.8654, Validation Loss: 3.4276, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [543/1000], Training Loss: 0.8682, Validation Loss: 3.2908, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [544/1000], Training Loss: 0.8854, Validation Loss: 3.2955, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [545/1000], Training Loss: 0.8430, Validation Loss: 3.3842, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [546/1000], Training Loss: 0.8893, Validation Loss: 3.4029, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [547/1000], Training Loss: 0.9247, Validation Loss: 3.3355, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [548/1000], Training Loss: 0.8513, Validation Loss: 3.3897, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [549/1000], Training Loss: 0.7896, Validation Loss: 3.4248, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [550/1000], Training Loss: 0.9107, Validation Loss: 3.3322, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [551/1000], Training Loss: 0.9053, Validation Loss: 3.3473, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [552/1000], Training Loss: 0.8631, Validation Loss: 3.2834, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [553/1000], Training Loss: 0.8510, Validation Loss: 3.5185, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [554/1000], Training Loss: 0.9048, Validation Loss: 3.4090, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [555/1000], Training Loss: 0.8452, Validation Loss: 3.3285, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [556/1000], Training Loss: 0.8771, Validation Loss: 3.3572, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [557/1000], Training Loss: 0.8698, Validation Loss: 3.4287, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [558/1000], Training Loss: 0.8306, Validation Loss: 3.4218, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [559/1000], Training Loss: 0.8102, Validation Loss: 3.4029, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [560/1000], Training Loss: 0.8249, Validation Loss: 3.4419, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [561/1000], Training Loss: 0.8110, Validation Loss: 3.4338, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [562/1000], Training Loss: 0.8445, Validation Loss: 3.4908, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [563/1000], Training Loss: 0.8791, Validation Loss: 3.3801, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [564/1000], Training Loss: 0.8648, Validation Loss: 3.2799, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [565/1000], Training Loss: 0.8497, Validation Loss: 3.5176, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [566/1000], Training Loss: 0.8778, Validation Loss: 3.3745, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [567/1000], Training Loss: 0.8090, Validation Loss: 3.5465, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [568/1000], Training Loss: 0.9052, Validation Loss: 3.3122, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [569/1000], Training Loss: 0.8539, Validation Loss: 3.4296, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [570/1000], Training Loss: 0.7844, Validation Loss: 3.4686, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [571/1000], Training Loss: 0.8423, Validation Loss: 3.4623, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [572/1000], Training Loss: 0.7863, Validation Loss: 3.5164, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [573/1000], Training Loss: 0.8453, Validation Loss: 3.3478, Validation Accuracy: 0.4578, Percentage:45.7843%\n",
            "Epoch [574/1000], Training Loss: 0.8912, Validation Loss: 3.4268, Validation Accuracy: 0.4578, Percentage:45.7843%\n",
            "Epoch [575/1000], Training Loss: 0.8149, Validation Loss: 3.3761, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [576/1000], Training Loss: 0.8157, Validation Loss: 3.4268, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [577/1000], Training Loss: 0.9013, Validation Loss: 3.3762, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [578/1000], Training Loss: 0.8695, Validation Loss: 3.4997, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [579/1000], Training Loss: 0.8744, Validation Loss: 3.3903, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [580/1000], Training Loss: 0.8546, Validation Loss: 3.4000, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [581/1000], Training Loss: 0.8457, Validation Loss: 3.3429, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [582/1000], Training Loss: 0.8321, Validation Loss: 3.2880, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [583/1000], Training Loss: 0.7945, Validation Loss: 3.4314, Validation Accuracy: 0.4608, Percentage:46.0784%\n",
            "Epoch [584/1000], Training Loss: 0.8755, Validation Loss: 3.4407, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [585/1000], Training Loss: 0.7718, Validation Loss: 3.6581, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [586/1000], Training Loss: 0.8891, Validation Loss: 3.5174, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [587/1000], Training Loss: 0.8346, Validation Loss: 3.4529, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [588/1000], Training Loss: 0.8252, Validation Loss: 3.6525, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [589/1000], Training Loss: 0.8210, Validation Loss: 3.3539, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [590/1000], Training Loss: 0.8866, Validation Loss: 3.4657, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [591/1000], Training Loss: 0.8529, Validation Loss: 3.5073, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [592/1000], Training Loss: 0.7631, Validation Loss: 3.4319, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [593/1000], Training Loss: 0.9367, Validation Loss: 3.4060, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [594/1000], Training Loss: 0.8143, Validation Loss: 3.4698, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [595/1000], Training Loss: 0.8462, Validation Loss: 3.4568, Validation Accuracy: 0.4578, Percentage:45.7843%\n",
            "Epoch [596/1000], Training Loss: 0.8173, Validation Loss: 3.5288, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [597/1000], Training Loss: 0.7614, Validation Loss: 3.4497, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [598/1000], Training Loss: 0.7981, Validation Loss: 3.4336, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [599/1000], Training Loss: 0.8658, Validation Loss: 3.5838, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [600/1000], Training Loss: 0.8649, Validation Loss: 3.6036, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [601/1000], Training Loss: 0.8572, Validation Loss: 3.5193, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [602/1000], Training Loss: 0.7847, Validation Loss: 3.3995, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [603/1000], Training Loss: 0.7904, Validation Loss: 3.4004, Validation Accuracy: 0.4598, Percentage:45.9804%\n",
            "Epoch [604/1000], Training Loss: 0.8106, Validation Loss: 3.4923, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [605/1000], Training Loss: 0.8015, Validation Loss: 3.4686, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [606/1000], Training Loss: 0.8979, Validation Loss: 3.5184, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [607/1000], Training Loss: 0.8584, Validation Loss: 3.5244, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [608/1000], Training Loss: 0.7935, Validation Loss: 3.5506, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [609/1000], Training Loss: 0.7600, Validation Loss: 3.4763, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [610/1000], Training Loss: 0.7842, Validation Loss: 3.6570, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [611/1000], Training Loss: 0.7820, Validation Loss: 3.6266, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [612/1000], Training Loss: 0.8204, Validation Loss: 3.6218, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [613/1000], Training Loss: 0.7973, Validation Loss: 3.5655, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [614/1000], Training Loss: 0.8594, Validation Loss: 3.6202, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [615/1000], Training Loss: 0.8035, Validation Loss: 3.5784, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [616/1000], Training Loss: 0.7686, Validation Loss: 3.4837, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [617/1000], Training Loss: 0.7070, Validation Loss: 3.4924, Validation Accuracy: 0.4598, Percentage:45.9804%\n",
            "Epoch [618/1000], Training Loss: 0.7979, Validation Loss: 3.4950, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [619/1000], Training Loss: 0.8199, Validation Loss: 3.5275, Validation Accuracy: 0.4578, Percentage:45.7843%\n",
            "Epoch [620/1000], Training Loss: 0.7885, Validation Loss: 3.5699, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [621/1000], Training Loss: 0.8347, Validation Loss: 3.6295, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [622/1000], Training Loss: 0.8003, Validation Loss: 3.4591, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [623/1000], Training Loss: 0.8110, Validation Loss: 3.5036, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [624/1000], Training Loss: 0.8610, Validation Loss: 3.7862, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [625/1000], Training Loss: 0.7226, Validation Loss: 3.5174, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [626/1000], Training Loss: 0.7795, Validation Loss: 3.5624, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [627/1000], Training Loss: 0.8002, Validation Loss: 3.5605, Validation Accuracy: 0.4608, Percentage:46.0784%\n",
            "Epoch [628/1000], Training Loss: 0.8564, Validation Loss: 3.4556, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [629/1000], Training Loss: 0.8668, Validation Loss: 3.3527, Validation Accuracy: 0.4598, Percentage:45.9804%\n",
            "Epoch [630/1000], Training Loss: 0.7368, Validation Loss: 3.5095, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [631/1000], Training Loss: 0.8455, Validation Loss: 3.5948, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [632/1000], Training Loss: 0.7505, Validation Loss: 3.5167, Validation Accuracy: 0.4667, Percentage:46.6667%\n",
            "Epoch [633/1000], Training Loss: 0.7480, Validation Loss: 3.6963, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [634/1000], Training Loss: 0.8303, Validation Loss: 3.4715, Validation Accuracy: 0.4618, Percentage:46.1765%\n",
            "Epoch [635/1000], Training Loss: 0.7922, Validation Loss: 3.7694, Validation Accuracy: 0.4578, Percentage:45.7843%\n",
            "Epoch [636/1000], Training Loss: 0.7700, Validation Loss: 3.5115, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [637/1000], Training Loss: 0.7941, Validation Loss: 3.5651, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [638/1000], Training Loss: 0.7694, Validation Loss: 3.6080, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [639/1000], Training Loss: 0.8182, Validation Loss: 3.5393, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [640/1000], Training Loss: 0.8266, Validation Loss: 3.5282, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [641/1000], Training Loss: 0.8234, Validation Loss: 3.5240, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [642/1000], Training Loss: 0.7584, Validation Loss: 3.6340, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [643/1000], Training Loss: 0.7373, Validation Loss: 3.6276, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [644/1000], Training Loss: 0.7194, Validation Loss: 3.5458, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [645/1000], Training Loss: 0.8454, Validation Loss: 3.7879, Validation Accuracy: 0.4618, Percentage:46.1765%\n",
            "Epoch [646/1000], Training Loss: 0.8218, Validation Loss: 3.4967, Validation Accuracy: 0.4647, Percentage:46.4706%\n",
            "Epoch [647/1000], Training Loss: 0.7868, Validation Loss: 3.6037, Validation Accuracy: 0.4618, Percentage:46.1765%\n",
            "Epoch [648/1000], Training Loss: 0.7599, Validation Loss: 3.8507, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [649/1000], Training Loss: 0.8719, Validation Loss: 3.4691, Validation Accuracy: 0.4647, Percentage:46.4706%\n",
            "Epoch [650/1000], Training Loss: 0.8628, Validation Loss: 3.5057, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [651/1000], Training Loss: 0.7647, Validation Loss: 3.7270, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [652/1000], Training Loss: 0.7792, Validation Loss: 3.5956, Validation Accuracy: 0.4578, Percentage:45.7843%\n",
            "Epoch [653/1000], Training Loss: 0.7515, Validation Loss: 3.5904, Validation Accuracy: 0.4657, Percentage:46.5686%\n",
            "Epoch [654/1000], Training Loss: 0.7684, Validation Loss: 3.5747, Validation Accuracy: 0.4657, Percentage:46.5686%\n",
            "Epoch [655/1000], Training Loss: 0.8023, Validation Loss: 3.4798, Validation Accuracy: 0.4578, Percentage:45.7843%\n",
            "Epoch [656/1000], Training Loss: 0.7834, Validation Loss: 3.7289, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [657/1000], Training Loss: 0.7302, Validation Loss: 3.4646, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [658/1000], Training Loss: 0.7313, Validation Loss: 3.8097, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [659/1000], Training Loss: 0.8326, Validation Loss: 3.5748, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [660/1000], Training Loss: 0.7501, Validation Loss: 3.5548, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [661/1000], Training Loss: 0.7365, Validation Loss: 3.6889, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [662/1000], Training Loss: 0.7762, Validation Loss: 3.5350, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [663/1000], Training Loss: 0.7976, Validation Loss: 3.5803, Validation Accuracy: 0.4647, Percentage:46.4706%\n",
            "Epoch [664/1000], Training Loss: 0.8122, Validation Loss: 3.5067, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [665/1000], Training Loss: 0.7785, Validation Loss: 3.5699, Validation Accuracy: 0.4608, Percentage:46.0784%\n",
            "Epoch [666/1000], Training Loss: 0.7726, Validation Loss: 3.6359, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [667/1000], Training Loss: 0.7275, Validation Loss: 3.5875, Validation Accuracy: 0.4657, Percentage:46.5686%\n",
            "Epoch [668/1000], Training Loss: 0.7431, Validation Loss: 3.6914, Validation Accuracy: 0.4598, Percentage:45.9804%\n",
            "Epoch [669/1000], Training Loss: 0.7346, Validation Loss: 3.6837, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [670/1000], Training Loss: 0.8135, Validation Loss: 3.5001, Validation Accuracy: 0.4667, Percentage:46.6667%\n",
            "Epoch [671/1000], Training Loss: 0.7727, Validation Loss: 3.5553, Validation Accuracy: 0.4627, Percentage:46.2745%\n",
            "Epoch [672/1000], Training Loss: 0.8068, Validation Loss: 3.6120, Validation Accuracy: 0.4647, Percentage:46.4706%\n",
            "Epoch [673/1000], Training Loss: 0.7662, Validation Loss: 3.4649, Validation Accuracy: 0.4598, Percentage:45.9804%\n",
            "Epoch [674/1000], Training Loss: 0.7936, Validation Loss: 3.5387, Validation Accuracy: 0.4735, Percentage:47.3529%\n",
            "Epoch [675/1000], Training Loss: 0.7492, Validation Loss: 3.5621, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [676/1000], Training Loss: 0.7892, Validation Loss: 3.6168, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [677/1000], Training Loss: 0.7525, Validation Loss: 3.5611, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [678/1000], Training Loss: 0.7240, Validation Loss: 3.5438, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [679/1000], Training Loss: 0.7318, Validation Loss: 3.7467, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [680/1000], Training Loss: 0.7802, Validation Loss: 3.5663, Validation Accuracy: 0.4667, Percentage:46.6667%\n",
            "Epoch [681/1000], Training Loss: 0.7871, Validation Loss: 3.6007, Validation Accuracy: 0.4598, Percentage:45.9804%\n",
            "Epoch [682/1000], Training Loss: 0.7495, Validation Loss: 3.5228, Validation Accuracy: 0.4686, Percentage:46.8627%\n",
            "Epoch [683/1000], Training Loss: 0.7531, Validation Loss: 3.6156, Validation Accuracy: 0.4735, Percentage:47.3529%\n",
            "Epoch [684/1000], Training Loss: 0.7775, Validation Loss: 3.6082, Validation Accuracy: 0.4627, Percentage:46.2745%\n",
            "Epoch [685/1000], Training Loss: 0.7449, Validation Loss: 3.5947, Validation Accuracy: 0.4716, Percentage:47.1569%\n",
            "Epoch [686/1000], Training Loss: 0.7960, Validation Loss: 3.7495, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [687/1000], Training Loss: 0.8419, Validation Loss: 3.4800, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [688/1000], Training Loss: 0.7484, Validation Loss: 3.7011, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [689/1000], Training Loss: 0.7861, Validation Loss: 3.6067, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [690/1000], Training Loss: 0.6866, Validation Loss: 3.7111, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [691/1000], Training Loss: 0.6623, Validation Loss: 3.5581, Validation Accuracy: 0.4657, Percentage:46.5686%\n",
            "Epoch [692/1000], Training Loss: 0.7282, Validation Loss: 3.8433, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [693/1000], Training Loss: 0.7421, Validation Loss: 3.6675, Validation Accuracy: 0.4598, Percentage:45.9804%\n",
            "Epoch [694/1000], Training Loss: 0.7114, Validation Loss: 3.6669, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [695/1000], Training Loss: 0.7488, Validation Loss: 3.6740, Validation Accuracy: 0.4618, Percentage:46.1765%\n",
            "Epoch [696/1000], Training Loss: 0.7034, Validation Loss: 3.6880, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [697/1000], Training Loss: 0.7140, Validation Loss: 3.7068, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [698/1000], Training Loss: 0.7969, Validation Loss: 3.5526, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [699/1000], Training Loss: 0.7586, Validation Loss: 3.5091, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [700/1000], Training Loss: 0.6763, Validation Loss: 3.5932, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [701/1000], Training Loss: 0.6977, Validation Loss: 3.7839, Validation Accuracy: 0.4598, Percentage:45.9804%\n",
            "Epoch [702/1000], Training Loss: 0.7519, Validation Loss: 3.5757, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [703/1000], Training Loss: 0.7566, Validation Loss: 3.7919, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [704/1000], Training Loss: 0.7552, Validation Loss: 3.7926, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [705/1000], Training Loss: 0.6935, Validation Loss: 3.5905, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [706/1000], Training Loss: 0.7258, Validation Loss: 3.5802, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [707/1000], Training Loss: 0.7383, Validation Loss: 3.5397, Validation Accuracy: 0.4647, Percentage:46.4706%\n",
            "Epoch [708/1000], Training Loss: 0.7415, Validation Loss: 3.6847, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [709/1000], Training Loss: 0.7552, Validation Loss: 3.6833, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [710/1000], Training Loss: 0.7558, Validation Loss: 3.6608, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [711/1000], Training Loss: 0.7016, Validation Loss: 3.6799, Validation Accuracy: 0.4637, Percentage:46.3725%\n",
            "Epoch [712/1000], Training Loss: 0.7377, Validation Loss: 3.7989, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [713/1000], Training Loss: 0.7587, Validation Loss: 3.6940, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [714/1000], Training Loss: 0.6883, Validation Loss: 3.7268, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [715/1000], Training Loss: 0.7211, Validation Loss: 3.6075, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [716/1000], Training Loss: 0.6876, Validation Loss: 3.7417, Validation Accuracy: 0.4696, Percentage:46.9608%\n",
            "Epoch [717/1000], Training Loss: 0.8021, Validation Loss: 3.5542, Validation Accuracy: 0.4716, Percentage:47.1569%\n",
            "Epoch [718/1000], Training Loss: 0.7453, Validation Loss: 3.6822, Validation Accuracy: 0.4608, Percentage:46.0784%\n",
            "Epoch [719/1000], Training Loss: 0.7162, Validation Loss: 3.7692, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [720/1000], Training Loss: 0.7082, Validation Loss: 3.7491, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [721/1000], Training Loss: 0.7641, Validation Loss: 3.6838, Validation Accuracy: 0.4647, Percentage:46.4706%\n",
            "Epoch [722/1000], Training Loss: 0.6998, Validation Loss: 3.5437, Validation Accuracy: 0.4647, Percentage:46.4706%\n",
            "Epoch [723/1000], Training Loss: 0.6856, Validation Loss: 3.6372, Validation Accuracy: 0.4637, Percentage:46.3725%\n",
            "Epoch [724/1000], Training Loss: 0.6968, Validation Loss: 3.7685, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [725/1000], Training Loss: 0.7201, Validation Loss: 3.7323, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [726/1000], Training Loss: 0.6734, Validation Loss: 3.8504, Validation Accuracy: 0.4578, Percentage:45.7843%\n",
            "Epoch [727/1000], Training Loss: 0.7015, Validation Loss: 3.6404, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [728/1000], Training Loss: 0.6789, Validation Loss: 3.6393, Validation Accuracy: 0.4578, Percentage:45.7843%\n",
            "Epoch [729/1000], Training Loss: 0.7854, Validation Loss: 3.7419, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [730/1000], Training Loss: 0.7836, Validation Loss: 3.9653, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [731/1000], Training Loss: 0.7519, Validation Loss: 3.7632, Validation Accuracy: 0.4608, Percentage:46.0784%\n",
            "Epoch [732/1000], Training Loss: 0.7357, Validation Loss: 3.6705, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [733/1000], Training Loss: 0.6928, Validation Loss: 3.7405, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [734/1000], Training Loss: 0.7205, Validation Loss: 3.8249, Validation Accuracy: 0.4657, Percentage:46.5686%\n",
            "Epoch [735/1000], Training Loss: 0.7659, Validation Loss: 3.5871, Validation Accuracy: 0.4647, Percentage:46.4706%\n",
            "Epoch [736/1000], Training Loss: 0.6990, Validation Loss: 3.7899, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [737/1000], Training Loss: 0.7609, Validation Loss: 3.9521, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [738/1000], Training Loss: 0.7527, Validation Loss: 3.5796, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [739/1000], Training Loss: 0.7336, Validation Loss: 3.6287, Validation Accuracy: 0.4667, Percentage:46.6667%\n",
            "Epoch [740/1000], Training Loss: 0.6519, Validation Loss: 3.8363, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [741/1000], Training Loss: 0.7254, Validation Loss: 3.7719, Validation Accuracy: 0.4667, Percentage:46.6667%\n",
            "Epoch [742/1000], Training Loss: 0.7491, Validation Loss: 3.7048, Validation Accuracy: 0.4657, Percentage:46.5686%\n",
            "Epoch [743/1000], Training Loss: 0.7530, Validation Loss: 3.8945, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [744/1000], Training Loss: 0.6924, Validation Loss: 3.7684, Validation Accuracy: 0.4578, Percentage:45.7843%\n",
            "Epoch [745/1000], Training Loss: 0.7865, Validation Loss: 3.8068, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [746/1000], Training Loss: 0.6563, Validation Loss: 3.6858, Validation Accuracy: 0.4618, Percentage:46.1765%\n",
            "Epoch [747/1000], Training Loss: 0.8040, Validation Loss: 3.8394, Validation Accuracy: 0.4657, Percentage:46.5686%\n",
            "Epoch [748/1000], Training Loss: 0.6464, Validation Loss: 3.6384, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [749/1000], Training Loss: 0.6748, Validation Loss: 3.6495, Validation Accuracy: 0.4637, Percentage:46.3725%\n",
            "Epoch [750/1000], Training Loss: 0.7472, Validation Loss: 3.7911, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [751/1000], Training Loss: 0.6755, Validation Loss: 3.7919, Validation Accuracy: 0.4578, Percentage:45.7843%\n",
            "Epoch [752/1000], Training Loss: 0.7509, Validation Loss: 3.7235, Validation Accuracy: 0.4657, Percentage:46.5686%\n",
            "Epoch [753/1000], Training Loss: 0.6512, Validation Loss: 3.9022, Validation Accuracy: 0.4637, Percentage:46.3725%\n",
            "Epoch [754/1000], Training Loss: 0.7307, Validation Loss: 3.7298, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [755/1000], Training Loss: 0.7178, Validation Loss: 3.8028, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [756/1000], Training Loss: 0.7010, Validation Loss: 4.0061, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [757/1000], Training Loss: 0.6947, Validation Loss: 3.8032, Validation Accuracy: 0.4618, Percentage:46.1765%\n",
            "Epoch [758/1000], Training Loss: 0.7466, Validation Loss: 3.7336, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [759/1000], Training Loss: 0.7083, Validation Loss: 3.7524, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [760/1000], Training Loss: 0.6989, Validation Loss: 3.9449, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [761/1000], Training Loss: 0.7306, Validation Loss: 3.6897, Validation Accuracy: 0.4696, Percentage:46.9608%\n",
            "Epoch [762/1000], Training Loss: 0.7635, Validation Loss: 3.8827, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [763/1000], Training Loss: 0.6768, Validation Loss: 3.6690, Validation Accuracy: 0.4578, Percentage:45.7843%\n",
            "Epoch [764/1000], Training Loss: 0.6922, Validation Loss: 3.8143, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [765/1000], Training Loss: 0.6670, Validation Loss: 3.7131, Validation Accuracy: 0.4627, Percentage:46.2745%\n",
            "Epoch [766/1000], Training Loss: 0.7287, Validation Loss: 3.7654, Validation Accuracy: 0.4735, Percentage:47.3529%\n",
            "Epoch [767/1000], Training Loss: 0.7163, Validation Loss: 3.8050, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [768/1000], Training Loss: 0.7724, Validation Loss: 3.6320, Validation Accuracy: 0.4627, Percentage:46.2745%\n",
            "Epoch [769/1000], Training Loss: 0.6991, Validation Loss: 3.7587, Validation Accuracy: 0.4608, Percentage:46.0784%\n",
            "Epoch [770/1000], Training Loss: 0.6884, Validation Loss: 3.6341, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [771/1000], Training Loss: 0.7214, Validation Loss: 3.8375, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [772/1000], Training Loss: 0.7413, Validation Loss: 3.5779, Validation Accuracy: 0.4627, Percentage:46.2745%\n",
            "Epoch [773/1000], Training Loss: 0.6727, Validation Loss: 3.5948, Validation Accuracy: 0.4618, Percentage:46.1765%\n",
            "Epoch [774/1000], Training Loss: 0.6534, Validation Loss: 3.8647, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [775/1000], Training Loss: 0.6672, Validation Loss: 3.8949, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [776/1000], Training Loss: 0.7069, Validation Loss: 3.7268, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [777/1000], Training Loss: 0.6873, Validation Loss: 3.7476, Validation Accuracy: 0.4667, Percentage:46.6667%\n",
            "Epoch [778/1000], Training Loss: 0.6888, Validation Loss: 3.6945, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [779/1000], Training Loss: 0.7382, Validation Loss: 3.6534, Validation Accuracy: 0.4735, Percentage:47.3529%\n",
            "Epoch [780/1000], Training Loss: 0.7206, Validation Loss: 3.6160, Validation Accuracy: 0.4676, Percentage:46.7647%\n",
            "Epoch [781/1000], Training Loss: 0.7059, Validation Loss: 3.7414, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [782/1000], Training Loss: 0.6825, Validation Loss: 3.6179, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [783/1000], Training Loss: 0.7029, Validation Loss: 3.8807, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [784/1000], Training Loss: 0.7210, Validation Loss: 3.6450, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [785/1000], Training Loss: 0.6836, Validation Loss: 3.5909, Validation Accuracy: 0.4627, Percentage:46.2745%\n",
            "Epoch [786/1000], Training Loss: 0.7082, Validation Loss: 3.6874, Validation Accuracy: 0.4676, Percentage:46.7647%\n",
            "Epoch [787/1000], Training Loss: 0.6971, Validation Loss: 3.7118, Validation Accuracy: 0.4637, Percentage:46.3725%\n",
            "Epoch [788/1000], Training Loss: 0.6819, Validation Loss: 3.7684, Validation Accuracy: 0.4676, Percentage:46.7647%\n",
            "Epoch [789/1000], Training Loss: 0.6550, Validation Loss: 3.8621, Validation Accuracy: 0.4745, Percentage:47.4510%\n",
            "Epoch [790/1000], Training Loss: 0.7292, Validation Loss: 3.6676, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [791/1000], Training Loss: 0.7050, Validation Loss: 4.0665, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [792/1000], Training Loss: 0.7205, Validation Loss: 3.6753, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [793/1000], Training Loss: 0.7241, Validation Loss: 3.6224, Validation Accuracy: 0.4627, Percentage:46.2745%\n",
            "Epoch [794/1000], Training Loss: 0.6435, Validation Loss: 3.9785, Validation Accuracy: 0.4608, Percentage:46.0784%\n",
            "Epoch [795/1000], Training Loss: 0.7084, Validation Loss: 3.8276, Validation Accuracy: 0.4598, Percentage:45.9804%\n",
            "Epoch [796/1000], Training Loss: 0.6716, Validation Loss: 3.6016, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [797/1000], Training Loss: 0.7864, Validation Loss: 3.8454, Validation Accuracy: 0.4598, Percentage:45.9804%\n",
            "Epoch [798/1000], Training Loss: 0.6295, Validation Loss: 3.7006, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [799/1000], Training Loss: 0.7385, Validation Loss: 4.0273, Validation Accuracy: 0.4608, Percentage:46.0784%\n",
            "Epoch [800/1000], Training Loss: 0.6221, Validation Loss: 3.8842, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [801/1000], Training Loss: 0.6888, Validation Loss: 3.7772, Validation Accuracy: 0.4667, Percentage:46.6667%\n",
            "Epoch [802/1000], Training Loss: 0.7288, Validation Loss: 3.6695, Validation Accuracy: 0.4725, Percentage:47.2549%\n",
            "Epoch [803/1000], Training Loss: 0.7394, Validation Loss: 3.7127, Validation Accuracy: 0.4686, Percentage:46.8627%\n",
            "Epoch [804/1000], Training Loss: 0.6902, Validation Loss: 3.8407, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [805/1000], Training Loss: 0.7046, Validation Loss: 3.6806, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [806/1000], Training Loss: 0.6893, Validation Loss: 3.9423, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [807/1000], Training Loss: 0.7572, Validation Loss: 3.6679, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [808/1000], Training Loss: 0.6837, Validation Loss: 3.7889, Validation Accuracy: 0.4696, Percentage:46.9608%\n",
            "Epoch [809/1000], Training Loss: 0.7085, Validation Loss: 3.9069, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [810/1000], Training Loss: 0.7236, Validation Loss: 3.7857, Validation Accuracy: 0.4637, Percentage:46.3725%\n",
            "Epoch [811/1000], Training Loss: 0.6984, Validation Loss: 3.7745, Validation Accuracy: 0.4647, Percentage:46.4706%\n",
            "Epoch [812/1000], Training Loss: 0.6991, Validation Loss: 3.8683, Validation Accuracy: 0.4686, Percentage:46.8627%\n",
            "Epoch [813/1000], Training Loss: 0.7262, Validation Loss: 3.8013, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [814/1000], Training Loss: 0.6974, Validation Loss: 3.8169, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [815/1000], Training Loss: 0.7280, Validation Loss: 3.9022, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [816/1000], Training Loss: 0.6533, Validation Loss: 3.6747, Validation Accuracy: 0.4608, Percentage:46.0784%\n",
            "Epoch [817/1000], Training Loss: 0.6731, Validation Loss: 3.8467, Validation Accuracy: 0.4647, Percentage:46.4706%\n",
            "Epoch [818/1000], Training Loss: 0.6966, Validation Loss: 3.7283, Validation Accuracy: 0.4647, Percentage:46.4706%\n",
            "Epoch [819/1000], Training Loss: 0.6575, Validation Loss: 3.8337, Validation Accuracy: 0.4647, Percentage:46.4706%\n",
            "Epoch [820/1000], Training Loss: 0.6657, Validation Loss: 4.0849, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [821/1000], Training Loss: 0.6999, Validation Loss: 3.7105, Validation Accuracy: 0.4686, Percentage:46.8627%\n",
            "Epoch [822/1000], Training Loss: 0.7417, Validation Loss: 3.7477, Validation Accuracy: 0.4676, Percentage:46.7647%\n",
            "Epoch [823/1000], Training Loss: 0.6631, Validation Loss: 3.7551, Validation Accuracy: 0.4775, Percentage:47.7451%\n",
            "Epoch [824/1000], Training Loss: 0.6703, Validation Loss: 3.9819, Validation Accuracy: 0.4716, Percentage:47.1569%\n",
            "Epoch [825/1000], Training Loss: 0.7429, Validation Loss: 3.6936, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [826/1000], Training Loss: 0.6590, Validation Loss: 3.7270, Validation Accuracy: 0.4598, Percentage:45.9804%\n",
            "Epoch [827/1000], Training Loss: 0.6985, Validation Loss: 3.6464, Validation Accuracy: 0.4657, Percentage:46.5686%\n",
            "Epoch [828/1000], Training Loss: 0.7289, Validation Loss: 3.8909, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [829/1000], Training Loss: 0.6543, Validation Loss: 3.7578, Validation Accuracy: 0.4598, Percentage:45.9804%\n",
            "Epoch [830/1000], Training Loss: 0.7140, Validation Loss: 3.7230, Validation Accuracy: 0.4637, Percentage:46.3725%\n",
            "Epoch [831/1000], Training Loss: 0.7074, Validation Loss: 3.7332, Validation Accuracy: 0.4667, Percentage:46.6667%\n",
            "Epoch [832/1000], Training Loss: 0.6720, Validation Loss: 3.7174, Validation Accuracy: 0.4667, Percentage:46.6667%\n",
            "Epoch [833/1000], Training Loss: 0.6863, Validation Loss: 3.5920, Validation Accuracy: 0.4637, Percentage:46.3725%\n",
            "Epoch [834/1000], Training Loss: 0.6237, Validation Loss: 3.8158, Validation Accuracy: 0.4647, Percentage:46.4706%\n",
            "Epoch [835/1000], Training Loss: 0.7134, Validation Loss: 3.8599, Validation Accuracy: 0.4686, Percentage:46.8627%\n",
            "Epoch [836/1000], Training Loss: 0.6385, Validation Loss: 3.8516, Validation Accuracy: 0.4618, Percentage:46.1765%\n",
            "Epoch [837/1000], Training Loss: 0.6970, Validation Loss: 3.7300, Validation Accuracy: 0.4608, Percentage:46.0784%\n",
            "Epoch [838/1000], Training Loss: 0.6508, Validation Loss: 3.8529, Validation Accuracy: 0.4716, Percentage:47.1569%\n",
            "Epoch [839/1000], Training Loss: 0.6946, Validation Loss: 3.8944, Validation Accuracy: 0.4745, Percentage:47.4510%\n",
            "Epoch [840/1000], Training Loss: 0.7033, Validation Loss: 3.8040, Validation Accuracy: 0.4598, Percentage:45.9804%\n",
            "Epoch [841/1000], Training Loss: 0.6922, Validation Loss: 3.9623, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [842/1000], Training Loss: 0.7732, Validation Loss: 3.7786, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [843/1000], Training Loss: 0.6697, Validation Loss: 3.7682, Validation Accuracy: 0.4627, Percentage:46.2745%\n",
            "Epoch [844/1000], Training Loss: 0.6363, Validation Loss: 3.8032, Validation Accuracy: 0.4578, Percentage:45.7843%\n",
            "Epoch [845/1000], Training Loss: 0.6946, Validation Loss: 3.7918, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [846/1000], Training Loss: 0.6558, Validation Loss: 4.0634, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [847/1000], Training Loss: 0.6760, Validation Loss: 3.9139, Validation Accuracy: 0.4608, Percentage:46.0784%\n",
            "Epoch [848/1000], Training Loss: 0.6266, Validation Loss: 3.6333, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [849/1000], Training Loss: 0.6432, Validation Loss: 3.8784, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [850/1000], Training Loss: 0.6239, Validation Loss: 3.7954, Validation Accuracy: 0.4755, Percentage:47.5490%\n",
            "Epoch [851/1000], Training Loss: 0.6581, Validation Loss: 3.8205, Validation Accuracy: 0.4657, Percentage:46.5686%\n",
            "Epoch [852/1000], Training Loss: 0.6702, Validation Loss: 3.9922, Validation Accuracy: 0.4667, Percentage:46.6667%\n",
            "Epoch [853/1000], Training Loss: 0.6640, Validation Loss: 3.7046, Validation Accuracy: 0.4725, Percentage:47.2549%\n",
            "Epoch [854/1000], Training Loss: 0.6584, Validation Loss: 4.0584, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [855/1000], Training Loss: 0.7333, Validation Loss: 3.6782, Validation Accuracy: 0.4725, Percentage:47.2549%\n",
            "Epoch [856/1000], Training Loss: 0.6495, Validation Loss: 3.8836, Validation Accuracy: 0.4647, Percentage:46.4706%\n",
            "Epoch [857/1000], Training Loss: 0.6621, Validation Loss: 3.9306, Validation Accuracy: 0.4667, Percentage:46.6667%\n",
            "Epoch [858/1000], Training Loss: 0.6566, Validation Loss: 3.9117, Validation Accuracy: 0.4706, Percentage:47.0588%\n",
            "Epoch [859/1000], Training Loss: 0.6572, Validation Loss: 3.7051, Validation Accuracy: 0.4784, Percentage:47.8431%\n",
            "Epoch [860/1000], Training Loss: 0.6786, Validation Loss: 3.9022, Validation Accuracy: 0.4618, Percentage:46.1765%\n",
            "Epoch [861/1000], Training Loss: 0.5686, Validation Loss: 3.8185, Validation Accuracy: 0.4716, Percentage:47.1569%\n",
            "Epoch [862/1000], Training Loss: 0.6216, Validation Loss: 3.8540, Validation Accuracy: 0.4775, Percentage:47.7451%\n",
            "Epoch [863/1000], Training Loss: 0.6012, Validation Loss: 3.7552, Validation Accuracy: 0.4784, Percentage:47.8431%\n",
            "Epoch [864/1000], Training Loss: 0.7826, Validation Loss: 3.9772, Validation Accuracy: 0.4657, Percentage:46.5686%\n",
            "Epoch [865/1000], Training Loss: 0.6558, Validation Loss: 3.7055, Validation Accuracy: 0.4608, Percentage:46.0784%\n",
            "Epoch [866/1000], Training Loss: 0.6273, Validation Loss: 3.8512, Validation Accuracy: 0.4676, Percentage:46.7647%\n",
            "Epoch [867/1000], Training Loss: 0.6301, Validation Loss: 3.9179, Validation Accuracy: 0.4676, Percentage:46.7647%\n",
            "Epoch [868/1000], Training Loss: 0.6933, Validation Loss: 3.9528, Validation Accuracy: 0.4657, Percentage:46.5686%\n",
            "Epoch [869/1000], Training Loss: 0.5880, Validation Loss: 3.8370, Validation Accuracy: 0.4716, Percentage:47.1569%\n",
            "Epoch [870/1000], Training Loss: 0.7098, Validation Loss: 3.7491, Validation Accuracy: 0.4608, Percentage:46.0784%\n",
            "Epoch [871/1000], Training Loss: 0.6307, Validation Loss: 3.8351, Validation Accuracy: 0.4657, Percentage:46.5686%\n",
            "Epoch [872/1000], Training Loss: 0.6720, Validation Loss: 3.6413, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [873/1000], Training Loss: 0.6682, Validation Loss: 3.8173, Validation Accuracy: 0.4716, Percentage:47.1569%\n",
            "Epoch [874/1000], Training Loss: 0.6253, Validation Loss: 3.8101, Validation Accuracy: 0.4706, Percentage:47.0588%\n",
            "Epoch [875/1000], Training Loss: 0.6423, Validation Loss: 3.9187, Validation Accuracy: 0.4696, Percentage:46.9608%\n",
            "Epoch [876/1000], Training Loss: 0.7345, Validation Loss: 3.8995, Validation Accuracy: 0.4608, Percentage:46.0784%\n",
            "Epoch [877/1000], Training Loss: 0.6527, Validation Loss: 3.8515, Validation Accuracy: 0.4814, Percentage:48.1373%\n",
            "Epoch [878/1000], Training Loss: 0.6426, Validation Loss: 3.8612, Validation Accuracy: 0.4863, Percentage:48.6275%\n",
            "Epoch [879/1000], Training Loss: 0.6318, Validation Loss: 3.8067, Validation Accuracy: 0.4627, Percentage:46.2745%\n",
            "Epoch [880/1000], Training Loss: 0.6545, Validation Loss: 4.1961, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [881/1000], Training Loss: 0.7272, Validation Loss: 3.7099, Validation Accuracy: 0.4775, Percentage:47.7451%\n",
            "Epoch [882/1000], Training Loss: 0.6507, Validation Loss: 3.7431, Validation Accuracy: 0.4686, Percentage:46.8627%\n",
            "Epoch [883/1000], Training Loss: 0.6476, Validation Loss: 3.9010, Validation Accuracy: 0.4637, Percentage:46.3725%\n",
            "Epoch [884/1000], Training Loss: 0.6494, Validation Loss: 3.8702, Validation Accuracy: 0.4745, Percentage:47.4510%\n",
            "Epoch [885/1000], Training Loss: 0.6655, Validation Loss: 3.8744, Validation Accuracy: 0.4598, Percentage:45.9804%\n",
            "Epoch [886/1000], Training Loss: 0.7178, Validation Loss: 3.9540, Validation Accuracy: 0.4627, Percentage:46.2745%\n",
            "Epoch [887/1000], Training Loss: 0.6749, Validation Loss: 3.8431, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [888/1000], Training Loss: 0.6654, Validation Loss: 3.7646, Validation Accuracy: 0.4765, Percentage:47.6471%\n",
            "Epoch [889/1000], Training Loss: 0.6610, Validation Loss: 3.9954, Validation Accuracy: 0.4637, Percentage:46.3725%\n",
            "Epoch [890/1000], Training Loss: 0.6199, Validation Loss: 3.9796, Validation Accuracy: 0.4647, Percentage:46.4706%\n",
            "Epoch [891/1000], Training Loss: 0.5994, Validation Loss: 4.0083, Validation Accuracy: 0.4647, Percentage:46.4706%\n",
            "Epoch [892/1000], Training Loss: 0.6917, Validation Loss: 3.7651, Validation Accuracy: 0.4676, Percentage:46.7647%\n",
            "Epoch [893/1000], Training Loss: 0.6366, Validation Loss: 3.9220, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [894/1000], Training Loss: 0.6225, Validation Loss: 4.0212, Validation Accuracy: 0.4578, Percentage:45.7843%\n",
            "Epoch [895/1000], Training Loss: 0.6615, Validation Loss: 3.8113, Validation Accuracy: 0.4716, Percentage:47.1569%\n",
            "Epoch [896/1000], Training Loss: 0.6045, Validation Loss: 3.8174, Validation Accuracy: 0.4618, Percentage:46.1765%\n",
            "Epoch [897/1000], Training Loss: 0.6881, Validation Loss: 3.9106, Validation Accuracy: 0.4686, Percentage:46.8627%\n",
            "Epoch [898/1000], Training Loss: 0.6065, Validation Loss: 3.9950, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [899/1000], Training Loss: 0.6796, Validation Loss: 3.8880, Validation Accuracy: 0.4667, Percentage:46.6667%\n",
            "Epoch [900/1000], Training Loss: 0.6278, Validation Loss: 3.7582, Validation Accuracy: 0.4775, Percentage:47.7451%\n",
            "Epoch [901/1000], Training Loss: 0.6609, Validation Loss: 3.8814, Validation Accuracy: 0.4637, Percentage:46.3725%\n",
            "Epoch [902/1000], Training Loss: 0.7217, Validation Loss: 3.7565, Validation Accuracy: 0.4735, Percentage:47.3529%\n",
            "Epoch [903/1000], Training Loss: 0.6231, Validation Loss: 3.7959, Validation Accuracy: 0.4667, Percentage:46.6667%\n",
            "Epoch [904/1000], Training Loss: 0.6573, Validation Loss: 3.9959, Validation Accuracy: 0.4735, Percentage:47.3529%\n",
            "Epoch [905/1000], Training Loss: 0.6156, Validation Loss: 3.9954, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [906/1000], Training Loss: 0.6458, Validation Loss: 4.1468, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [907/1000], Training Loss: 0.6656, Validation Loss: 3.8270, Validation Accuracy: 0.4618, Percentage:46.1765%\n",
            "Epoch [908/1000], Training Loss: 0.7056, Validation Loss: 3.7829, Validation Accuracy: 0.4755, Percentage:47.5490%\n",
            "Epoch [909/1000], Training Loss: 0.6330, Validation Loss: 3.7433, Validation Accuracy: 0.4686, Percentage:46.8627%\n",
            "Epoch [910/1000], Training Loss: 0.5821, Validation Loss: 4.1730, Validation Accuracy: 0.4686, Percentage:46.8627%\n",
            "Epoch [911/1000], Training Loss: 0.5816, Validation Loss: 4.1336, Validation Accuracy: 0.4716, Percentage:47.1569%\n",
            "Epoch [912/1000], Training Loss: 0.6747, Validation Loss: 3.8950, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [913/1000], Training Loss: 0.5321, Validation Loss: 3.6638, Validation Accuracy: 0.4676, Percentage:46.7647%\n",
            "Epoch [914/1000], Training Loss: 0.5205, Validation Loss: 4.0326, Validation Accuracy: 0.4608, Percentage:46.0784%\n",
            "Epoch [915/1000], Training Loss: 0.5966, Validation Loss: 3.8240, Validation Accuracy: 0.4578, Percentage:45.7843%\n",
            "Epoch [916/1000], Training Loss: 0.6211, Validation Loss: 3.9867, Validation Accuracy: 0.4657, Percentage:46.5686%\n",
            "Epoch [917/1000], Training Loss: 0.6164, Validation Loss: 3.9187, Validation Accuracy: 0.4706, Percentage:47.0588%\n",
            "Epoch [918/1000], Training Loss: 0.6669, Validation Loss: 3.9459, Validation Accuracy: 0.4618, Percentage:46.1765%\n",
            "Epoch [919/1000], Training Loss: 0.6639, Validation Loss: 3.7314, Validation Accuracy: 0.4676, Percentage:46.7647%\n",
            "Epoch [920/1000], Training Loss: 0.6579, Validation Loss: 3.8974, Validation Accuracy: 0.4657, Percentage:46.5686%\n",
            "Epoch [921/1000], Training Loss: 0.6057, Validation Loss: 3.7810, Validation Accuracy: 0.4667, Percentage:46.6667%\n",
            "Epoch [922/1000], Training Loss: 0.6029, Validation Loss: 4.0121, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [923/1000], Training Loss: 0.6578, Validation Loss: 3.8358, Validation Accuracy: 0.4637, Percentage:46.3725%\n",
            "Epoch [924/1000], Training Loss: 0.5691, Validation Loss: 3.8563, Validation Accuracy: 0.4647, Percentage:46.4706%\n",
            "Epoch [925/1000], Training Loss: 0.6925, Validation Loss: 4.0719, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [926/1000], Training Loss: 0.7076, Validation Loss: 3.8165, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [927/1000], Training Loss: 0.6426, Validation Loss: 3.8765, Validation Accuracy: 0.4716, Percentage:47.1569%\n",
            "Epoch [928/1000], Training Loss: 0.6768, Validation Loss: 3.8592, Validation Accuracy: 0.4824, Percentage:48.2353%\n",
            "Epoch [929/1000], Training Loss: 0.5864, Validation Loss: 3.8705, Validation Accuracy: 0.4833, Percentage:48.3333%\n",
            "Epoch [930/1000], Training Loss: 0.6381, Validation Loss: 3.7983, Validation Accuracy: 0.4745, Percentage:47.4510%\n",
            "Epoch [931/1000], Training Loss: 0.6181, Validation Loss: 4.0136, Validation Accuracy: 0.4676, Percentage:46.7647%\n",
            "Epoch [932/1000], Training Loss: 0.6033, Validation Loss: 3.9283, Validation Accuracy: 0.4608, Percentage:46.0784%\n",
            "Epoch [933/1000], Training Loss: 0.6922, Validation Loss: 3.8671, Validation Accuracy: 0.4804, Percentage:48.0392%\n",
            "Epoch [934/1000], Training Loss: 0.6805, Validation Loss: 3.9379, Validation Accuracy: 0.4784, Percentage:47.8431%\n",
            "Epoch [935/1000], Training Loss: 0.5673, Validation Loss: 3.9047, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [936/1000], Training Loss: 0.6250, Validation Loss: 3.7665, Validation Accuracy: 0.4765, Percentage:47.6471%\n",
            "Epoch [937/1000], Training Loss: 0.6501, Validation Loss: 3.7279, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [938/1000], Training Loss: 0.6137, Validation Loss: 4.0771, Validation Accuracy: 0.4667, Percentage:46.6667%\n",
            "Epoch [939/1000], Training Loss: 0.6130, Validation Loss: 3.9364, Validation Accuracy: 0.4627, Percentage:46.2745%\n",
            "Epoch [940/1000], Training Loss: 0.6590, Validation Loss: 3.9800, Validation Accuracy: 0.4755, Percentage:47.5490%\n",
            "Epoch [941/1000], Training Loss: 0.6081, Validation Loss: 3.9577, Validation Accuracy: 0.4637, Percentage:46.3725%\n",
            "Epoch [942/1000], Training Loss: 0.6164, Validation Loss: 3.6743, Validation Accuracy: 0.4735, Percentage:47.3529%\n",
            "Epoch [943/1000], Training Loss: 0.5942, Validation Loss: 3.9081, Validation Accuracy: 0.4716, Percentage:47.1569%\n",
            "Epoch [944/1000], Training Loss: 0.6199, Validation Loss: 3.9617, Validation Accuracy: 0.4686, Percentage:46.8627%\n",
            "Epoch [945/1000], Training Loss: 0.6573, Validation Loss: 4.0005, Validation Accuracy: 0.4706, Percentage:47.0588%\n",
            "Epoch [946/1000], Training Loss: 0.6575, Validation Loss: 3.9269, Validation Accuracy: 0.4598, Percentage:45.9804%\n",
            "Epoch [947/1000], Training Loss: 0.5953, Validation Loss: 3.9052, Validation Accuracy: 0.4657, Percentage:46.5686%\n",
            "Epoch [948/1000], Training Loss: 0.5896, Validation Loss: 3.9662, Validation Accuracy: 0.4696, Percentage:46.9608%\n",
            "Epoch [949/1000], Training Loss: 0.6495, Validation Loss: 3.9489, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [950/1000], Training Loss: 0.7579, Validation Loss: 4.0012, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [951/1000], Training Loss: 0.5991, Validation Loss: 4.0397, Validation Accuracy: 0.4578, Percentage:45.7843%\n",
            "Epoch [952/1000], Training Loss: 0.6074, Validation Loss: 3.9497, Validation Accuracy: 0.4676, Percentage:46.7647%\n",
            "Epoch [953/1000], Training Loss: 0.6225, Validation Loss: 3.7602, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [954/1000], Training Loss: 0.6387, Validation Loss: 3.7241, Validation Accuracy: 0.4706, Percentage:47.0588%\n",
            "Epoch [955/1000], Training Loss: 0.5709, Validation Loss: 4.1574, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [956/1000], Training Loss: 0.5351, Validation Loss: 4.0236, Validation Accuracy: 0.4755, Percentage:47.5490%\n",
            "Epoch [957/1000], Training Loss: 0.5402, Validation Loss: 4.0113, Validation Accuracy: 0.4735, Percentage:47.3529%\n",
            "Epoch [958/1000], Training Loss: 0.6817, Validation Loss: 4.0484, Validation Accuracy: 0.4735, Percentage:47.3529%\n",
            "Epoch [959/1000], Training Loss: 0.6087, Validation Loss: 3.8473, Validation Accuracy: 0.4706, Percentage:47.0588%\n",
            "Epoch [960/1000], Training Loss: 0.6064, Validation Loss: 3.8770, Validation Accuracy: 0.4784, Percentage:47.8431%\n",
            "Epoch [961/1000], Training Loss: 0.6118, Validation Loss: 3.8660, Validation Accuracy: 0.4755, Percentage:47.5490%\n",
            "Epoch [962/1000], Training Loss: 0.6036, Validation Loss: 3.8747, Validation Accuracy: 0.4686, Percentage:46.8627%\n",
            "Epoch [963/1000], Training Loss: 0.6024, Validation Loss: 3.8328, Validation Accuracy: 0.4716, Percentage:47.1569%\n",
            "Epoch [964/1000], Training Loss: 0.5942, Validation Loss: 3.8006, Validation Accuracy: 0.4618, Percentage:46.1765%\n",
            "Epoch [965/1000], Training Loss: 0.6657, Validation Loss: 4.0335, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [966/1000], Training Loss: 0.6635, Validation Loss: 3.9757, Validation Accuracy: 0.4618, Percentage:46.1765%\n",
            "Epoch [967/1000], Training Loss: 0.6558, Validation Loss: 4.1421, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [968/1000], Training Loss: 0.6040, Validation Loss: 4.0308, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [969/1000], Training Loss: 0.6120, Validation Loss: 4.1332, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [970/1000], Training Loss: 0.6305, Validation Loss: 3.8901, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [971/1000], Training Loss: 0.5671, Validation Loss: 4.0136, Validation Accuracy: 0.4598, Percentage:45.9804%\n",
            "Epoch [972/1000], Training Loss: 0.7511, Validation Loss: 3.8928, Validation Accuracy: 0.4657, Percentage:46.5686%\n",
            "Epoch [973/1000], Training Loss: 0.6211, Validation Loss: 4.0528, Validation Accuracy: 0.4647, Percentage:46.4706%\n",
            "Epoch [974/1000], Training Loss: 0.6249, Validation Loss: 3.8101, Validation Accuracy: 0.4667, Percentage:46.6667%\n",
            "Epoch [975/1000], Training Loss: 0.6308, Validation Loss: 3.7118, Validation Accuracy: 0.4598, Percentage:45.9804%\n",
            "Epoch [976/1000], Training Loss: 0.6887, Validation Loss: 3.9256, Validation Accuracy: 0.4667, Percentage:46.6667%\n",
            "Epoch [977/1000], Training Loss: 0.6523, Validation Loss: 3.7837, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [978/1000], Training Loss: 0.5950, Validation Loss: 4.1094, Validation Accuracy: 0.4627, Percentage:46.2745%\n",
            "Epoch [979/1000], Training Loss: 0.5820, Validation Loss: 3.8726, Validation Accuracy: 0.4657, Percentage:46.5686%\n",
            "Epoch [980/1000], Training Loss: 0.5561, Validation Loss: 3.9082, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [981/1000], Training Loss: 0.5921, Validation Loss: 3.9793, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [982/1000], Training Loss: 0.6214, Validation Loss: 4.1140, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [983/1000], Training Loss: 0.5859, Validation Loss: 4.0180, Validation Accuracy: 0.4627, Percentage:46.2745%\n",
            "Epoch [984/1000], Training Loss: 0.6273, Validation Loss: 3.9013, Validation Accuracy: 0.4667, Percentage:46.6667%\n",
            "Epoch [985/1000], Training Loss: 0.6240, Validation Loss: 3.9527, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [986/1000], Training Loss: 0.6362, Validation Loss: 3.9656, Validation Accuracy: 0.4716, Percentage:47.1569%\n",
            "Epoch [987/1000], Training Loss: 0.6278, Validation Loss: 4.0573, Validation Accuracy: 0.4647, Percentage:46.4706%\n",
            "Epoch [988/1000], Training Loss: 0.6482, Validation Loss: 4.1479, Validation Accuracy: 0.4608, Percentage:46.0784%\n",
            "Epoch [989/1000], Training Loss: 0.5852, Validation Loss: 3.9177, Validation Accuracy: 0.4794, Percentage:47.9412%\n",
            "Epoch [990/1000], Training Loss: 0.5721, Validation Loss: 4.0047, Validation Accuracy: 0.4696, Percentage:46.9608%\n",
            "Epoch [991/1000], Training Loss: 0.5989, Validation Loss: 4.1078, Validation Accuracy: 0.4618, Percentage:46.1765%\n",
            "Epoch [992/1000], Training Loss: 0.5837, Validation Loss: 3.8391, Validation Accuracy: 0.4706, Percentage:47.0588%\n",
            "Epoch [993/1000], Training Loss: 0.6256, Validation Loss: 3.8985, Validation Accuracy: 0.4637, Percentage:46.3725%\n",
            "Epoch [994/1000], Training Loss: 0.5941, Validation Loss: 4.2793, Validation Accuracy: 0.4667, Percentage:46.6667%\n",
            "Epoch [995/1000], Training Loss: 0.5876, Validation Loss: 4.0602, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [996/1000], Training Loss: 0.5610, Validation Loss: 4.1829, Validation Accuracy: 0.4696, Percentage:46.9608%\n",
            "Epoch [997/1000], Training Loss: 0.6052, Validation Loss: 4.1375, Validation Accuracy: 0.4696, Percentage:46.9608%\n",
            "Epoch [998/1000], Training Loss: 0.6887, Validation Loss: 3.9971, Validation Accuracy: 0.4578, Percentage:45.7843%\n",
            "Epoch [999/1000], Training Loss: 0.6413, Validation Loss: 4.0043, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [1000/1000], Training Loss: 0.7201, Validation Loss: 3.8625, Validation Accuracy: 0.4716, Percentage:47.1569%\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import Flowers102\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define transforms for data augmentation and normalization\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(500),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(500),\n",
        "    transforms.CenterCrop(500),\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the dataset with train/val/test splits\n",
        "train_dataset = Flowers102(root='./data', split='train', transform=train_transform, download=True)\n",
        "val_dataset = Flowers102(root='./data', split='val', transform=val_transform, download=True)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Define data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "class CNN_NN(nn.Module):\n",
        "    def __init__(self, num_classes=102):\n",
        "        super(CNN_NN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv5= nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "        # Initialize the size of the fully connected layer based on the sample input\n",
        "        self._to_linear = None\n",
        "        self.convs = nn.Sequential(\n",
        "            self.conv1,\n",
        "            nn.ReLU(),\n",
        "            self.pool,\n",
        "            self.conv2,\n",
        "            nn.ReLU(),\n",
        "            self.pool,\n",
        "            self.conv3,\n",
        "            nn.ReLU(),\n",
        "            self.pool\n",
        "            self.conv4,\n",
        "            nn.ReLu(),\n",
        "            self.pool,\n",
        "            self.conv5,\n",
        "            nn.ReLU(),\n",
        "            self.pool\n",
        "        )\n",
        "        self._initialize_linear_layer()\n",
        "\n",
        "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def _initialize_linear_layer(self):\n",
        "        # Create a dummy input tensor to calculate the output size after conv layers\n",
        "        x = torch.randn(1, 3, 500, 500)\n",
        "        x = self.convs(x)\n",
        "        self._to_linear = x.view(1, -1).shape[1]\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor while preserving the batch size\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Define the device (GPU or CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyperparameters\n",
        "num_classes = 102  # Number of output classes\n",
        "learning_rate = 0.0001\n",
        "num_epochs = 1000\n",
        "\n",
        "# Initialize the model\n",
        "model = CNN_NN(num_classes=num_classes).to(device)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    # Calculate average loss for the epoch\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Calculate average validation loss and accuracy\n",
        "    val_loss = val_loss / len(val_loader.dataset)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "          f'Training Loss: {epoch_loss:.4f}, '\n",
        "          f'Validation Loss: {val_loss:.4f}, '\n",
        "          f'Validation Accuracy: {accuracy:.4f}, '\n",
        "          f'Percentage:{accuracy*100:.4f}%')\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "pivsdl-kciv6",
        "outputId": "7304f646-f776-4357-94ab-f9457c473220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax. Perhaps you forgot a comma? (<ipython-input-1-74d06633dc24>, line 58)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-74d06633dc24>\"\u001b[0;36m, line \u001b[0;32m58\u001b[0m\n\u001b[0;31m    self.pool\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import Flowers102\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define transforms for data augmentation and normalization\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(500),\n",
        "    #transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(500),\n",
        "    transforms.CenterCrop(500),\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the dataset with train/val/test splits\n",
        "train_dataset = Flowers102(root='./data', split='train', transform=train_transform, download=True)\n",
        "val_dataset = Flowers102(root='./data', split='val', transform=val_transform, download=True)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Define data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "class CNN_NN(nn.Module):\n",
        "    def __init__(self, num_classes=102):\n",
        "        super(CNN_NN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv5= nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "        # Initialize the size of the fully connected layer based on the sample input\n",
        "        self._to_linear = None\n",
        "        self.convs = nn.Sequential(\n",
        "            self.conv1,\n",
        "            nn.ReLU(),\n",
        "            self.pool,\n",
        "            self.conv2,\n",
        "            nn.ReLU(),\n",
        "            self.pool,\n",
        "            self.conv3,\n",
        "            nn.ReLU(),\n",
        "            self.pool\n",
        "        )\n",
        "        self._initialize_linear_layer()\n",
        "\n",
        "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def _initialize_linear_layer(self):\n",
        "        # Create a dummy input tensor to calculate the output size after conv layers\n",
        "        x = torch.randn(1, 3, 500, 500)\n",
        "        x = self.convs(x)\n",
        "        self._to_linear = x.view(1, -1).shape[1]\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor while preserving the batch size\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Define the device (GPU or CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyperparameters\n",
        "num_classes = 102  # Number of output classes\n",
        "learning_rate = 0.0001\n",
        "num_epochs = 1500\n",
        "\n",
        "# Initialize the model\n",
        "model = CNN_NN(num_classes=num_classes).to(device)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    # Calculate average loss for the epoch\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Calculate average validation loss and accuracy\n",
        "    val_loss = val_loss / len(val_loader.dataset)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "          f'Training Loss: {epoch_loss:.4f}, '\n",
        "          f'Validation Loss: {val_loss:.4f}, '\n",
        "          f'Validation Accuracy: {accuracy:.4f}, '\n",
        "          f'Percentage:{accuracy*100:.4f}%')\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3k92LH1QuTlX",
        "outputId": "952845ec-a4b3-4a90-9070-40d2c9d7185f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1500], Training Loss: 4.6878, Validation Loss: 4.5681, Validation Accuracy: 0.0265, Percentage:2.6471%\n",
            "Epoch [2/1500], Training Loss: 4.5075, Validation Loss: 4.3194, Validation Accuracy: 0.0382, Percentage:3.8235%\n",
            "Epoch [3/1500], Training Loss: 4.3263, Validation Loss: 4.1694, Validation Accuracy: 0.0520, Percentage:5.1961%\n",
            "Epoch [4/1500], Training Loss: 4.2098, Validation Loss: 4.0545, Validation Accuracy: 0.0833, Percentage:8.3333%\n",
            "Epoch [5/1500], Training Loss: 4.1091, Validation Loss: 3.9238, Validation Accuracy: 0.0922, Percentage:9.2157%\n",
            "Epoch [6/1500], Training Loss: 3.9804, Validation Loss: 3.8217, Validation Accuracy: 0.1147, Percentage:11.4706%\n",
            "Epoch [7/1500], Training Loss: 3.9186, Validation Loss: 3.7628, Validation Accuracy: 0.1216, Percentage:12.1569%\n",
            "Epoch [8/1500], Training Loss: 3.8249, Validation Loss: 3.6922, Validation Accuracy: 0.1412, Percentage:14.1176%\n",
            "Epoch [9/1500], Training Loss: 3.7440, Validation Loss: 3.5856, Validation Accuracy: 0.1343, Percentage:13.4314%\n",
            "Epoch [10/1500], Training Loss: 3.6908, Validation Loss: 3.5682, Validation Accuracy: 0.1569, Percentage:15.6863%\n",
            "Epoch [11/1500], Training Loss: 3.5365, Validation Loss: 3.5174, Validation Accuracy: 0.1696, Percentage:16.9608%\n",
            "Epoch [12/1500], Training Loss: 3.5050, Validation Loss: 3.5100, Validation Accuracy: 0.1647, Percentage:16.4706%\n",
            "Epoch [13/1500], Training Loss: 3.5407, Validation Loss: 3.4494, Validation Accuracy: 0.1735, Percentage:17.3529%\n",
            "Epoch [14/1500], Training Loss: 3.4008, Validation Loss: 3.4082, Validation Accuracy: 0.1853, Percentage:18.5294%\n",
            "Epoch [15/1500], Training Loss: 3.2819, Validation Loss: 3.3265, Validation Accuracy: 0.2098, Percentage:20.9804%\n",
            "Epoch [16/1500], Training Loss: 3.2356, Validation Loss: 3.3156, Validation Accuracy: 0.2255, Percentage:22.5490%\n",
            "Epoch [17/1500], Training Loss: 3.1851, Validation Loss: 3.3099, Validation Accuracy: 0.2010, Percentage:20.0980%\n",
            "Epoch [18/1500], Training Loss: 3.1537, Validation Loss: 3.2319, Validation Accuracy: 0.2500, Percentage:25.0000%\n",
            "Epoch [19/1500], Training Loss: 3.1378, Validation Loss: 3.2464, Validation Accuracy: 0.2304, Percentage:23.0392%\n",
            "Epoch [20/1500], Training Loss: 3.1192, Validation Loss: 3.2332, Validation Accuracy: 0.2137, Percentage:21.3725%\n",
            "Epoch [21/1500], Training Loss: 2.9423, Validation Loss: 3.1544, Validation Accuracy: 0.2725, Percentage:27.2549%\n",
            "Epoch [22/1500], Training Loss: 2.8606, Validation Loss: 3.1913, Validation Accuracy: 0.2275, Percentage:22.7451%\n",
            "Epoch [23/1500], Training Loss: 2.8238, Validation Loss: 3.1553, Validation Accuracy: 0.2402, Percentage:24.0196%\n",
            "Epoch [24/1500], Training Loss: 2.8474, Validation Loss: 3.0976, Validation Accuracy: 0.2490, Percentage:24.9020%\n",
            "Epoch [25/1500], Training Loss: 2.7160, Validation Loss: 3.0838, Validation Accuracy: 0.2608, Percentage:26.0784%\n",
            "Epoch [26/1500], Training Loss: 2.7860, Validation Loss: 3.0313, Validation Accuracy: 0.2735, Percentage:27.3529%\n",
            "Epoch [27/1500], Training Loss: 2.6463, Validation Loss: 3.0646, Validation Accuracy: 0.2725, Percentage:27.2549%\n",
            "Epoch [28/1500], Training Loss: 2.6058, Validation Loss: 3.0031, Validation Accuracy: 0.2784, Percentage:27.8431%\n",
            "Epoch [29/1500], Training Loss: 2.6647, Validation Loss: 3.0291, Validation Accuracy: 0.2853, Percentage:28.5294%\n",
            "Epoch [30/1500], Training Loss: 2.5139, Validation Loss: 2.9734, Validation Accuracy: 0.2931, Percentage:29.3137%\n",
            "Epoch [31/1500], Training Loss: 2.5126, Validation Loss: 3.0381, Validation Accuracy: 0.2706, Percentage:27.0588%\n",
            "Epoch [32/1500], Training Loss: 2.5037, Validation Loss: 2.9543, Validation Accuracy: 0.2814, Percentage:28.1373%\n",
            "Epoch [33/1500], Training Loss: 2.4397, Validation Loss: 2.9656, Validation Accuracy: 0.2941, Percentage:29.4118%\n",
            "Epoch [34/1500], Training Loss: 2.4555, Validation Loss: 2.9992, Validation Accuracy: 0.2902, Percentage:29.0196%\n",
            "Epoch [35/1500], Training Loss: 2.3719, Validation Loss: 2.9339, Validation Accuracy: 0.2843, Percentage:28.4314%\n",
            "Epoch [36/1500], Training Loss: 2.3889, Validation Loss: 2.9630, Validation Accuracy: 0.2804, Percentage:28.0392%\n",
            "Epoch [37/1500], Training Loss: 2.2785, Validation Loss: 3.0118, Validation Accuracy: 0.2951, Percentage:29.5098%\n",
            "Epoch [38/1500], Training Loss: 2.3186, Validation Loss: 2.9831, Validation Accuracy: 0.2941, Percentage:29.4118%\n",
            "Epoch [39/1500], Training Loss: 2.2331, Validation Loss: 2.9917, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [40/1500], Training Loss: 2.2289, Validation Loss: 2.9698, Validation Accuracy: 0.2980, Percentage:29.8039%\n",
            "Epoch [41/1500], Training Loss: 2.1472, Validation Loss: 2.9734, Validation Accuracy: 0.2941, Percentage:29.4118%\n",
            "Epoch [42/1500], Training Loss: 2.0873, Validation Loss: 3.0472, Validation Accuracy: 0.2706, Percentage:27.0588%\n",
            "Epoch [43/1500], Training Loss: 2.1172, Validation Loss: 2.9530, Validation Accuracy: 0.3078, Percentage:30.7843%\n",
            "Epoch [44/1500], Training Loss: 2.1916, Validation Loss: 2.9809, Validation Accuracy: 0.3078, Percentage:30.7843%\n",
            "Epoch [45/1500], Training Loss: 2.1060, Validation Loss: 2.9879, Validation Accuracy: 0.3029, Percentage:30.2941%\n",
            "Epoch [46/1500], Training Loss: 2.0699, Validation Loss: 3.0149, Validation Accuracy: 0.3088, Percentage:30.8824%\n",
            "Epoch [47/1500], Training Loss: 2.0120, Validation Loss: 2.9870, Validation Accuracy: 0.3118, Percentage:31.1765%\n",
            "Epoch [48/1500], Training Loss: 2.0609, Validation Loss: 3.0024, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [49/1500], Training Loss: 2.0428, Validation Loss: 3.0015, Validation Accuracy: 0.2941, Percentage:29.4118%\n",
            "Epoch [50/1500], Training Loss: 1.9763, Validation Loss: 3.0099, Validation Accuracy: 0.3020, Percentage:30.1961%\n",
            "Epoch [51/1500], Training Loss: 1.9160, Validation Loss: 3.0184, Validation Accuracy: 0.3284, Percentage:32.8431%\n",
            "Epoch [52/1500], Training Loss: 1.8574, Validation Loss: 3.0481, Validation Accuracy: 0.3069, Percentage:30.6863%\n",
            "Epoch [53/1500], Training Loss: 1.8882, Validation Loss: 2.9463, Validation Accuracy: 0.3343, Percentage:33.4314%\n",
            "Epoch [54/1500], Training Loss: 1.9067, Validation Loss: 3.0446, Validation Accuracy: 0.3059, Percentage:30.5882%\n",
            "Epoch [55/1500], Training Loss: 1.9730, Validation Loss: 2.9588, Validation Accuracy: 0.3176, Percentage:31.7647%\n",
            "Epoch [56/1500], Training Loss: 1.8988, Validation Loss: 2.9516, Validation Accuracy: 0.3275, Percentage:32.7451%\n",
            "Epoch [57/1500], Training Loss: 1.9182, Validation Loss: 3.1656, Validation Accuracy: 0.3098, Percentage:30.9804%\n",
            "Epoch [58/1500], Training Loss: 1.8459, Validation Loss: 2.9519, Validation Accuracy: 0.3186, Percentage:31.8627%\n",
            "Epoch [59/1500], Training Loss: 1.7970, Validation Loss: 2.9959, Validation Accuracy: 0.3167, Percentage:31.6667%\n",
            "Epoch [60/1500], Training Loss: 1.7371, Validation Loss: 3.0399, Validation Accuracy: 0.3275, Percentage:32.7451%\n",
            "Epoch [61/1500], Training Loss: 1.7958, Validation Loss: 2.9818, Validation Accuracy: 0.3304, Percentage:33.0392%\n",
            "Epoch [62/1500], Training Loss: 1.6507, Validation Loss: 2.9733, Validation Accuracy: 0.3382, Percentage:33.8235%\n",
            "Epoch [63/1500], Training Loss: 1.8237, Validation Loss: 3.0160, Validation Accuracy: 0.3147, Percentage:31.4706%\n",
            "Epoch [64/1500], Training Loss: 1.7477, Validation Loss: 2.9946, Validation Accuracy: 0.3382, Percentage:33.8235%\n",
            "Epoch [65/1500], Training Loss: 1.7693, Validation Loss: 3.0188, Validation Accuracy: 0.3176, Percentage:31.7647%\n",
            "Epoch [66/1500], Training Loss: 1.6790, Validation Loss: 2.9557, Validation Accuracy: 0.3284, Percentage:32.8431%\n",
            "Epoch [67/1500], Training Loss: 1.5924, Validation Loss: 3.0055, Validation Accuracy: 0.3275, Percentage:32.7451%\n",
            "Epoch [68/1500], Training Loss: 1.6574, Validation Loss: 3.0295, Validation Accuracy: 0.3304, Percentage:33.0392%\n",
            "Epoch [69/1500], Training Loss: 1.5449, Validation Loss: 3.0725, Validation Accuracy: 0.3186, Percentage:31.8627%\n",
            "Epoch [70/1500], Training Loss: 1.5655, Validation Loss: 3.0500, Validation Accuracy: 0.3245, Percentage:32.4510%\n",
            "Epoch [71/1500], Training Loss: 1.6791, Validation Loss: 3.1404, Validation Accuracy: 0.3049, Percentage:30.4902%\n",
            "Epoch [72/1500], Training Loss: 1.5797, Validation Loss: 3.0311, Validation Accuracy: 0.3275, Percentage:32.7451%\n",
            "Epoch [73/1500], Training Loss: 1.5888, Validation Loss: 3.1078, Validation Accuracy: 0.3265, Percentage:32.6471%\n",
            "Epoch [74/1500], Training Loss: 1.6135, Validation Loss: 3.0917, Validation Accuracy: 0.3069, Percentage:30.6863%\n",
            "Epoch [75/1500], Training Loss: 1.5899, Validation Loss: 3.1361, Validation Accuracy: 0.3294, Percentage:32.9412%\n",
            "Epoch [76/1500], Training Loss: 1.5692, Validation Loss: 3.0324, Validation Accuracy: 0.3206, Percentage:32.0588%\n",
            "Epoch [77/1500], Training Loss: 1.5242, Validation Loss: 3.0780, Validation Accuracy: 0.3402, Percentage:34.0196%\n",
            "Epoch [78/1500], Training Loss: 1.5726, Validation Loss: 3.0400, Validation Accuracy: 0.3265, Percentage:32.6471%\n",
            "Epoch [79/1500], Training Loss: 1.4565, Validation Loss: 3.1166, Validation Accuracy: 0.3245, Percentage:32.4510%\n",
            "Epoch [80/1500], Training Loss: 1.6031, Validation Loss: 3.0768, Validation Accuracy: 0.3275, Percentage:32.7451%\n",
            "Epoch [81/1500], Training Loss: 1.5129, Validation Loss: 3.0544, Validation Accuracy: 0.3412, Percentage:34.1176%\n",
            "Epoch [82/1500], Training Loss: 1.4512, Validation Loss: 3.0911, Validation Accuracy: 0.3324, Percentage:33.2353%\n",
            "Epoch [83/1500], Training Loss: 1.4616, Validation Loss: 3.0852, Validation Accuracy: 0.3461, Percentage:34.6078%\n",
            "Epoch [84/1500], Training Loss: 1.4596, Validation Loss: 3.1153, Validation Accuracy: 0.3412, Percentage:34.1176%\n",
            "Epoch [85/1500], Training Loss: 1.4416, Validation Loss: 3.1442, Validation Accuracy: 0.3402, Percentage:34.0196%\n",
            "Epoch [86/1500], Training Loss: 1.5281, Validation Loss: 2.9919, Validation Accuracy: 0.3373, Percentage:33.7255%\n",
            "Epoch [87/1500], Training Loss: 1.4594, Validation Loss: 3.0814, Validation Accuracy: 0.3314, Percentage:33.1373%\n",
            "Epoch [88/1500], Training Loss: 1.4282, Validation Loss: 3.1286, Validation Accuracy: 0.3275, Percentage:32.7451%\n",
            "Epoch [89/1500], Training Loss: 1.3335, Validation Loss: 3.1096, Validation Accuracy: 0.3451, Percentage:34.5098%\n",
            "Epoch [90/1500], Training Loss: 1.4100, Validation Loss: 3.2053, Validation Accuracy: 0.3412, Percentage:34.1176%\n",
            "Epoch [91/1500], Training Loss: 1.3327, Validation Loss: 3.2415, Validation Accuracy: 0.3353, Percentage:33.5294%\n",
            "Epoch [92/1500], Training Loss: 1.4535, Validation Loss: 3.0815, Validation Accuracy: 0.3333, Percentage:33.3333%\n",
            "Epoch [93/1500], Training Loss: 1.3918, Validation Loss: 3.1323, Validation Accuracy: 0.3402, Percentage:34.0196%\n",
            "Epoch [94/1500], Training Loss: 1.3670, Validation Loss: 3.1035, Validation Accuracy: 0.3539, Percentage:35.3922%\n",
            "Epoch [95/1500], Training Loss: 1.3225, Validation Loss: 3.0577, Validation Accuracy: 0.3735, Percentage:37.3529%\n",
            "Epoch [96/1500], Training Loss: 1.3080, Validation Loss: 3.0930, Validation Accuracy: 0.3382, Percentage:33.8235%\n",
            "Epoch [97/1500], Training Loss: 1.2546, Validation Loss: 3.0423, Validation Accuracy: 0.3441, Percentage:34.4118%\n",
            "Epoch [98/1500], Training Loss: 1.2580, Validation Loss: 3.1785, Validation Accuracy: 0.3392, Percentage:33.9216%\n",
            "Epoch [99/1500], Training Loss: 1.2893, Validation Loss: 3.1365, Validation Accuracy: 0.3569, Percentage:35.6863%\n",
            "Epoch [100/1500], Training Loss: 1.2844, Validation Loss: 3.1451, Validation Accuracy: 0.3441, Percentage:34.4118%\n",
            "Epoch [101/1500], Training Loss: 1.3475, Validation Loss: 3.2565, Validation Accuracy: 0.3363, Percentage:33.6275%\n",
            "Epoch [102/1500], Training Loss: 1.2050, Validation Loss: 3.0640, Validation Accuracy: 0.3373, Percentage:33.7255%\n",
            "Epoch [103/1500], Training Loss: 1.2908, Validation Loss: 3.2086, Validation Accuracy: 0.3402, Percentage:34.0196%\n",
            "Epoch [104/1500], Training Loss: 1.2856, Validation Loss: 3.2243, Validation Accuracy: 0.3598, Percentage:35.9804%\n",
            "Epoch [105/1500], Training Loss: 1.2386, Validation Loss: 3.1881, Validation Accuracy: 0.3373, Percentage:33.7255%\n",
            "Epoch [106/1500], Training Loss: 1.2627, Validation Loss: 3.0723, Validation Accuracy: 0.3500, Percentage:35.0000%\n",
            "Epoch [107/1500], Training Loss: 1.2791, Validation Loss: 3.1557, Validation Accuracy: 0.3431, Percentage:34.3137%\n",
            "Epoch [108/1500], Training Loss: 1.2257, Validation Loss: 3.1533, Validation Accuracy: 0.3422, Percentage:34.2157%\n",
            "Epoch [109/1500], Training Loss: 1.2576, Validation Loss: 3.0935, Validation Accuracy: 0.3480, Percentage:34.8039%\n",
            "Epoch [110/1500], Training Loss: 1.2246, Validation Loss: 3.1242, Validation Accuracy: 0.3559, Percentage:35.5882%\n",
            "Epoch [111/1500], Training Loss: 1.2096, Validation Loss: 3.1024, Validation Accuracy: 0.3392, Percentage:33.9216%\n",
            "Epoch [112/1500], Training Loss: 1.2092, Validation Loss: 3.0344, Validation Accuracy: 0.3627, Percentage:36.2745%\n",
            "Epoch [113/1500], Training Loss: 1.1670, Validation Loss: 3.1344, Validation Accuracy: 0.3686, Percentage:36.8627%\n",
            "Epoch [114/1500], Training Loss: 1.2359, Validation Loss: 3.1891, Validation Accuracy: 0.3598, Percentage:35.9804%\n",
            "Epoch [115/1500], Training Loss: 1.2031, Validation Loss: 3.2644, Validation Accuracy: 0.3500, Percentage:35.0000%\n",
            "Epoch [116/1500], Training Loss: 1.2293, Validation Loss: 3.1666, Validation Accuracy: 0.3500, Percentage:35.0000%\n",
            "Epoch [117/1500], Training Loss: 1.2231, Validation Loss: 3.2243, Validation Accuracy: 0.3618, Percentage:36.1765%\n",
            "Epoch [118/1500], Training Loss: 1.2658, Validation Loss: 3.1413, Validation Accuracy: 0.3735, Percentage:37.3529%\n",
            "Epoch [119/1500], Training Loss: 1.1548, Validation Loss: 3.3271, Validation Accuracy: 0.3422, Percentage:34.2157%\n",
            "Epoch [120/1500], Training Loss: 1.1792, Validation Loss: 3.2985, Validation Accuracy: 0.3451, Percentage:34.5098%\n",
            "Epoch [121/1500], Training Loss: 1.1115, Validation Loss: 3.2948, Validation Accuracy: 0.3588, Percentage:35.8824%\n",
            "Epoch [122/1500], Training Loss: 1.2596, Validation Loss: 3.2495, Validation Accuracy: 0.3480, Percentage:34.8039%\n",
            "Epoch [123/1500], Training Loss: 1.1210, Validation Loss: 3.2672, Validation Accuracy: 0.3490, Percentage:34.9020%\n",
            "Epoch [124/1500], Training Loss: 1.0650, Validation Loss: 3.2769, Validation Accuracy: 0.3500, Percentage:35.0000%\n",
            "Epoch [125/1500], Training Loss: 1.1544, Validation Loss: 3.1162, Validation Accuracy: 0.3647, Percentage:36.4706%\n",
            "Epoch [126/1500], Training Loss: 1.1150, Validation Loss: 3.3063, Validation Accuracy: 0.3676, Percentage:36.7647%\n",
            "Epoch [127/1500], Training Loss: 1.0735, Validation Loss: 3.3535, Validation Accuracy: 0.3725, Percentage:37.2549%\n",
            "Epoch [128/1500], Training Loss: 1.1226, Validation Loss: 3.2910, Validation Accuracy: 0.3559, Percentage:35.5882%\n",
            "Epoch [129/1500], Training Loss: 1.1892, Validation Loss: 3.1964, Validation Accuracy: 0.3510, Percentage:35.0980%\n",
            "Epoch [130/1500], Training Loss: 1.1557, Validation Loss: 3.2866, Validation Accuracy: 0.3559, Percentage:35.5882%\n",
            "Epoch [131/1500], Training Loss: 1.1399, Validation Loss: 3.2510, Validation Accuracy: 0.3559, Percentage:35.5882%\n",
            "Epoch [132/1500], Training Loss: 1.0599, Validation Loss: 3.2433, Validation Accuracy: 0.3657, Percentage:36.5686%\n",
            "Epoch [133/1500], Training Loss: 1.0389, Validation Loss: 3.3494, Validation Accuracy: 0.3608, Percentage:36.0784%\n",
            "Epoch [134/1500], Training Loss: 1.1141, Validation Loss: 3.4260, Validation Accuracy: 0.3686, Percentage:36.8627%\n",
            "Epoch [135/1500], Training Loss: 1.0719, Validation Loss: 3.2449, Validation Accuracy: 0.3755, Percentage:37.5490%\n",
            "Epoch [136/1500], Training Loss: 1.1457, Validation Loss: 3.2946, Validation Accuracy: 0.3490, Percentage:34.9020%\n",
            "Epoch [137/1500], Training Loss: 1.0889, Validation Loss: 3.2701, Validation Accuracy: 0.3578, Percentage:35.7843%\n",
            "Epoch [138/1500], Training Loss: 0.9964, Validation Loss: 3.3845, Validation Accuracy: 0.3510, Percentage:35.0980%\n",
            "Epoch [139/1500], Training Loss: 1.1318, Validation Loss: 3.3093, Validation Accuracy: 0.3578, Percentage:35.7843%\n",
            "Epoch [140/1500], Training Loss: 1.0589, Validation Loss: 3.3044, Validation Accuracy: 0.3471, Percentage:34.7059%\n",
            "Epoch [141/1500], Training Loss: 1.0953, Validation Loss: 3.4211, Validation Accuracy: 0.3490, Percentage:34.9020%\n",
            "Epoch [142/1500], Training Loss: 1.0915, Validation Loss: 3.3946, Validation Accuracy: 0.3480, Percentage:34.8039%\n",
            "Epoch [143/1500], Training Loss: 1.0996, Validation Loss: 3.3381, Validation Accuracy: 0.3539, Percentage:35.3922%\n",
            "Epoch [144/1500], Training Loss: 1.1201, Validation Loss: 3.2991, Validation Accuracy: 0.3618, Percentage:36.1765%\n",
            "Epoch [145/1500], Training Loss: 1.0260, Validation Loss: 3.3365, Validation Accuracy: 0.3608, Percentage:36.0784%\n",
            "Epoch [146/1500], Training Loss: 1.0681, Validation Loss: 3.5548, Validation Accuracy: 0.3422, Percentage:34.2157%\n",
            "Epoch [147/1500], Training Loss: 0.9924, Validation Loss: 3.2493, Validation Accuracy: 0.3569, Percentage:35.6863%\n",
            "Epoch [148/1500], Training Loss: 1.0320, Validation Loss: 3.3051, Validation Accuracy: 0.3598, Percentage:35.9804%\n",
            "Epoch [149/1500], Training Loss: 1.0774, Validation Loss: 3.2500, Validation Accuracy: 0.3627, Percentage:36.2745%\n",
            "Epoch [150/1500], Training Loss: 1.0695, Validation Loss: 3.1768, Validation Accuracy: 0.3627, Percentage:36.2745%\n",
            "Epoch [151/1500], Training Loss: 1.0457, Validation Loss: 3.2952, Validation Accuracy: 0.3598, Percentage:35.9804%\n",
            "Epoch [152/1500], Training Loss: 0.9862, Validation Loss: 3.3065, Validation Accuracy: 0.3510, Percentage:35.0980%\n",
            "Epoch [153/1500], Training Loss: 0.9778, Validation Loss: 3.3998, Validation Accuracy: 0.3569, Percentage:35.6863%\n",
            "Epoch [154/1500], Training Loss: 0.9544, Validation Loss: 3.3425, Validation Accuracy: 0.3539, Percentage:35.3922%\n",
            "Epoch [155/1500], Training Loss: 0.9460, Validation Loss: 3.2807, Validation Accuracy: 0.3706, Percentage:37.0588%\n",
            "Epoch [156/1500], Training Loss: 1.0521, Validation Loss: 3.3090, Validation Accuracy: 0.3676, Percentage:36.7647%\n",
            "Epoch [157/1500], Training Loss: 1.0685, Validation Loss: 3.5351, Validation Accuracy: 0.3441, Percentage:34.4118%\n",
            "Epoch [158/1500], Training Loss: 1.0037, Validation Loss: 3.2886, Validation Accuracy: 0.3765, Percentage:37.6471%\n",
            "Epoch [159/1500], Training Loss: 0.9853, Validation Loss: 3.4018, Validation Accuracy: 0.3647, Percentage:36.4706%\n",
            "Epoch [160/1500], Training Loss: 0.9575, Validation Loss: 3.4184, Validation Accuracy: 0.3667, Percentage:36.6667%\n",
            "Epoch [161/1500], Training Loss: 0.9890, Validation Loss: 3.4036, Validation Accuracy: 0.3451, Percentage:34.5098%\n",
            "Epoch [162/1500], Training Loss: 0.9961, Validation Loss: 3.2994, Validation Accuracy: 0.3608, Percentage:36.0784%\n",
            "Epoch [163/1500], Training Loss: 0.9729, Validation Loss: 3.3622, Validation Accuracy: 0.3559, Percentage:35.5882%\n",
            "Epoch [164/1500], Training Loss: 0.9502, Validation Loss: 3.4823, Validation Accuracy: 0.3559, Percentage:35.5882%\n",
            "Epoch [165/1500], Training Loss: 0.9603, Validation Loss: 3.2951, Validation Accuracy: 0.3461, Percentage:34.6078%\n",
            "Epoch [166/1500], Training Loss: 0.9434, Validation Loss: 3.5663, Validation Accuracy: 0.3608, Percentage:36.0784%\n",
            "Epoch [167/1500], Training Loss: 0.9429, Validation Loss: 3.4009, Validation Accuracy: 0.3676, Percentage:36.7647%\n",
            "Epoch [168/1500], Training Loss: 0.9418, Validation Loss: 3.4880, Validation Accuracy: 0.3529, Percentage:35.2941%\n",
            "Epoch [169/1500], Training Loss: 0.9294, Validation Loss: 3.4405, Validation Accuracy: 0.3284, Percentage:32.8431%\n",
            "Epoch [170/1500], Training Loss: 1.0296, Validation Loss: 3.3744, Validation Accuracy: 0.3794, Percentage:37.9412%\n",
            "Epoch [171/1500], Training Loss: 0.9436, Validation Loss: 3.3405, Validation Accuracy: 0.3598, Percentage:35.9804%\n",
            "Epoch [172/1500], Training Loss: 0.9445, Validation Loss: 3.4097, Validation Accuracy: 0.3706, Percentage:37.0588%\n",
            "Epoch [173/1500], Training Loss: 1.0012, Validation Loss: 3.6085, Validation Accuracy: 0.3637, Percentage:36.3725%\n",
            "Epoch [174/1500], Training Loss: 0.8827, Validation Loss: 3.4374, Validation Accuracy: 0.3627, Percentage:36.2745%\n",
            "Epoch [175/1500], Training Loss: 0.9947, Validation Loss: 3.3700, Validation Accuracy: 0.3549, Percentage:35.4902%\n",
            "Epoch [176/1500], Training Loss: 1.0548, Validation Loss: 3.3969, Validation Accuracy: 0.3412, Percentage:34.1176%\n",
            "Epoch [177/1500], Training Loss: 0.8900, Validation Loss: 3.3012, Validation Accuracy: 0.3549, Percentage:35.4902%\n",
            "Epoch [178/1500], Training Loss: 0.9391, Validation Loss: 3.5678, Validation Accuracy: 0.3549, Percentage:35.4902%\n",
            "Epoch [179/1500], Training Loss: 0.9023, Validation Loss: 3.4847, Validation Accuracy: 0.3637, Percentage:36.3725%\n",
            "Epoch [180/1500], Training Loss: 0.9030, Validation Loss: 3.4860, Validation Accuracy: 0.3824, Percentage:38.2353%\n",
            "Epoch [181/1500], Training Loss: 0.9387, Validation Loss: 3.3098, Validation Accuracy: 0.3716, Percentage:37.1569%\n",
            "Epoch [182/1500], Training Loss: 0.8630, Validation Loss: 3.4149, Validation Accuracy: 0.3529, Percentage:35.2941%\n",
            "Epoch [183/1500], Training Loss: 0.9355, Validation Loss: 3.3971, Validation Accuracy: 0.3755, Percentage:37.5490%\n",
            "Epoch [184/1500], Training Loss: 0.9815, Validation Loss: 3.4073, Validation Accuracy: 0.3490, Percentage:34.9020%\n",
            "Epoch [185/1500], Training Loss: 0.9041, Validation Loss: 3.3659, Validation Accuracy: 0.3745, Percentage:37.4510%\n",
            "Epoch [186/1500], Training Loss: 0.8835, Validation Loss: 3.6833, Validation Accuracy: 0.3422, Percentage:34.2157%\n",
            "Epoch [187/1500], Training Loss: 0.8384, Validation Loss: 3.4453, Validation Accuracy: 0.3765, Percentage:37.6471%\n",
            "Epoch [188/1500], Training Loss: 0.8307, Validation Loss: 3.4599, Validation Accuracy: 0.3833, Percentage:38.3333%\n",
            "Epoch [189/1500], Training Loss: 0.9091, Validation Loss: 3.3946, Validation Accuracy: 0.3725, Percentage:37.2549%\n",
            "Epoch [190/1500], Training Loss: 0.9420, Validation Loss: 3.5347, Validation Accuracy: 0.3667, Percentage:36.6667%\n",
            "Epoch [191/1500], Training Loss: 0.8615, Validation Loss: 3.3850, Validation Accuracy: 0.3667, Percentage:36.6667%\n",
            "Epoch [192/1500], Training Loss: 0.9292, Validation Loss: 3.4014, Validation Accuracy: 0.3578, Percentage:35.7843%\n",
            "Epoch [193/1500], Training Loss: 0.8526, Validation Loss: 3.5055, Validation Accuracy: 0.3824, Percentage:38.2353%\n",
            "Epoch [194/1500], Training Loss: 0.8686, Validation Loss: 3.4085, Validation Accuracy: 0.3716, Percentage:37.1569%\n",
            "Epoch [195/1500], Training Loss: 0.8382, Validation Loss: 3.5273, Validation Accuracy: 0.3588, Percentage:35.8824%\n",
            "Epoch [196/1500], Training Loss: 0.8996, Validation Loss: 3.4644, Validation Accuracy: 0.3578, Percentage:35.7843%\n",
            "Epoch [197/1500], Training Loss: 0.8449, Validation Loss: 3.5476, Validation Accuracy: 0.3706, Percentage:37.0588%\n",
            "Epoch [198/1500], Training Loss: 0.8248, Validation Loss: 3.4693, Validation Accuracy: 0.3676, Percentage:36.7647%\n",
            "Epoch [199/1500], Training Loss: 0.8689, Validation Loss: 3.4070, Validation Accuracy: 0.3696, Percentage:36.9608%\n",
            "Epoch [200/1500], Training Loss: 0.9121, Validation Loss: 3.5707, Validation Accuracy: 0.3588, Percentage:35.8824%\n",
            "Epoch [201/1500], Training Loss: 0.8493, Validation Loss: 3.4088, Validation Accuracy: 0.3627, Percentage:36.2745%\n",
            "Epoch [202/1500], Training Loss: 0.8077, Validation Loss: 3.4422, Validation Accuracy: 0.3725, Percentage:37.2549%\n",
            "Epoch [203/1500], Training Loss: 0.8558, Validation Loss: 3.5649, Validation Accuracy: 0.3686, Percentage:36.8627%\n",
            "Epoch [204/1500], Training Loss: 0.7261, Validation Loss: 3.6187, Validation Accuracy: 0.3716, Percentage:37.1569%\n",
            "Epoch [205/1500], Training Loss: 0.8718, Validation Loss: 3.6386, Validation Accuracy: 0.3598, Percentage:35.9804%\n",
            "Epoch [206/1500], Training Loss: 0.8317, Validation Loss: 3.4611, Validation Accuracy: 0.3627, Percentage:36.2745%\n",
            "Epoch [207/1500], Training Loss: 0.8371, Validation Loss: 3.5565, Validation Accuracy: 0.3598, Percentage:35.9804%\n",
            "Epoch [208/1500], Training Loss: 0.8623, Validation Loss: 3.6396, Validation Accuracy: 0.3676, Percentage:36.7647%\n",
            "Epoch [209/1500], Training Loss: 0.9322, Validation Loss: 3.5414, Validation Accuracy: 0.3676, Percentage:36.7647%\n",
            "Epoch [210/1500], Training Loss: 0.8321, Validation Loss: 3.4310, Validation Accuracy: 0.3559, Percentage:35.5882%\n",
            "Epoch [211/1500], Training Loss: 0.8731, Validation Loss: 3.5311, Validation Accuracy: 0.3549, Percentage:35.4902%\n",
            "Epoch [212/1500], Training Loss: 0.7789, Validation Loss: 3.5788, Validation Accuracy: 0.3765, Percentage:37.6471%\n",
            "Epoch [213/1500], Training Loss: 0.8449, Validation Loss: 3.5114, Validation Accuracy: 0.3784, Percentage:37.8431%\n",
            "Epoch [214/1500], Training Loss: 0.7950, Validation Loss: 3.5956, Validation Accuracy: 0.3686, Percentage:36.8627%\n",
            "Epoch [215/1500], Training Loss: 0.8699, Validation Loss: 3.6114, Validation Accuracy: 0.3696, Percentage:36.9608%\n",
            "Epoch [216/1500], Training Loss: 0.8061, Validation Loss: 3.5586, Validation Accuracy: 0.3608, Percentage:36.0784%\n",
            "Epoch [217/1500], Training Loss: 0.8259, Validation Loss: 3.4053, Validation Accuracy: 0.3686, Percentage:36.8627%\n",
            "Epoch [218/1500], Training Loss: 0.8301, Validation Loss: 3.5537, Validation Accuracy: 0.3706, Percentage:37.0588%\n",
            "Epoch [219/1500], Training Loss: 0.7705, Validation Loss: 3.6447, Validation Accuracy: 0.3696, Percentage:36.9608%\n",
            "Epoch [220/1500], Training Loss: 0.7510, Validation Loss: 3.7829, Validation Accuracy: 0.3716, Percentage:37.1569%\n",
            "Epoch [221/1500], Training Loss: 0.7866, Validation Loss: 3.5737, Validation Accuracy: 0.3520, Percentage:35.1961%\n",
            "Epoch [222/1500], Training Loss: 0.7892, Validation Loss: 3.5916, Validation Accuracy: 0.3833, Percentage:38.3333%\n",
            "Epoch [223/1500], Training Loss: 0.8366, Validation Loss: 3.7224, Validation Accuracy: 0.3451, Percentage:34.5098%\n",
            "Epoch [224/1500], Training Loss: 0.8301, Validation Loss: 3.4997, Validation Accuracy: 0.3618, Percentage:36.1765%\n",
            "Epoch [225/1500], Training Loss: 0.8657, Validation Loss: 3.5907, Validation Accuracy: 0.3578, Percentage:35.7843%\n",
            "Epoch [226/1500], Training Loss: 0.7923, Validation Loss: 3.6323, Validation Accuracy: 0.3775, Percentage:37.7451%\n",
            "Epoch [227/1500], Training Loss: 0.8082, Validation Loss: 3.5473, Validation Accuracy: 0.3608, Percentage:36.0784%\n",
            "Epoch [228/1500], Training Loss: 0.8060, Validation Loss: 3.6143, Validation Accuracy: 0.3853, Percentage:38.5294%\n",
            "Epoch [229/1500], Training Loss: 0.7136, Validation Loss: 3.5426, Validation Accuracy: 0.3784, Percentage:37.8431%\n",
            "Epoch [230/1500], Training Loss: 0.7996, Validation Loss: 3.5595, Validation Accuracy: 0.3588, Percentage:35.8824%\n",
            "Epoch [231/1500], Training Loss: 0.8795, Validation Loss: 3.6355, Validation Accuracy: 0.3716, Percentage:37.1569%\n",
            "Epoch [232/1500], Training Loss: 0.7736, Validation Loss: 3.6066, Validation Accuracy: 0.3618, Percentage:36.1765%\n",
            "Epoch [233/1500], Training Loss: 0.8220, Validation Loss: 3.5832, Validation Accuracy: 0.3382, Percentage:33.8235%\n",
            "Epoch [234/1500], Training Loss: 0.7891, Validation Loss: 3.6124, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [235/1500], Training Loss: 0.7469, Validation Loss: 3.6903, Validation Accuracy: 0.3598, Percentage:35.9804%\n",
            "Epoch [236/1500], Training Loss: 0.8156, Validation Loss: 3.5665, Validation Accuracy: 0.3814, Percentage:38.1373%\n",
            "Epoch [237/1500], Training Loss: 0.7866, Validation Loss: 3.4994, Validation Accuracy: 0.3686, Percentage:36.8627%\n",
            "Epoch [238/1500], Training Loss: 0.7344, Validation Loss: 3.6636, Validation Accuracy: 0.3716, Percentage:37.1569%\n",
            "Epoch [239/1500], Training Loss: 0.9435, Validation Loss: 3.5802, Validation Accuracy: 0.3647, Percentage:36.4706%\n",
            "Epoch [240/1500], Training Loss: 0.7345, Validation Loss: 3.6916, Validation Accuracy: 0.3627, Percentage:36.2745%\n",
            "Epoch [241/1500], Training Loss: 0.7848, Validation Loss: 3.7640, Validation Accuracy: 0.3588, Percentage:35.8824%\n",
            "Epoch [242/1500], Training Loss: 0.7134, Validation Loss: 3.5283, Validation Accuracy: 0.3588, Percentage:35.8824%\n",
            "Epoch [243/1500], Training Loss: 0.8207, Validation Loss: 3.6567, Validation Accuracy: 0.3863, Percentage:38.6275%\n",
            "Epoch [244/1500], Training Loss: 0.7889, Validation Loss: 3.5822, Validation Accuracy: 0.3775, Percentage:37.7451%\n",
            "Epoch [245/1500], Training Loss: 0.7029, Validation Loss: 3.6054, Validation Accuracy: 0.3794, Percentage:37.9412%\n",
            "Epoch [246/1500], Training Loss: 0.7237, Validation Loss: 3.7831, Validation Accuracy: 0.3618, Percentage:36.1765%\n",
            "Epoch [247/1500], Training Loss: 0.6945, Validation Loss: 3.6722, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [248/1500], Training Loss: 0.7316, Validation Loss: 3.9843, Validation Accuracy: 0.3696, Percentage:36.9608%\n",
            "Epoch [249/1500], Training Loss: 0.8622, Validation Loss: 3.7529, Validation Accuracy: 0.3471, Percentage:34.7059%\n",
            "Epoch [250/1500], Training Loss: 0.7343, Validation Loss: 3.6817, Validation Accuracy: 0.3637, Percentage:36.3725%\n",
            "Epoch [251/1500], Training Loss: 0.7842, Validation Loss: 3.6448, Validation Accuracy: 0.3804, Percentage:38.0392%\n",
            "Epoch [252/1500], Training Loss: 0.7371, Validation Loss: 3.6609, Validation Accuracy: 0.3784, Percentage:37.8431%\n",
            "Epoch [253/1500], Training Loss: 0.7657, Validation Loss: 3.6309, Validation Accuracy: 0.3627, Percentage:36.2745%\n",
            "Epoch [254/1500], Training Loss: 0.7290, Validation Loss: 3.6853, Validation Accuracy: 0.3833, Percentage:38.3333%\n",
            "Epoch [255/1500], Training Loss: 0.7279, Validation Loss: 3.8248, Validation Accuracy: 0.3667, Percentage:36.6667%\n",
            "Epoch [256/1500], Training Loss: 0.8101, Validation Loss: 3.5621, Validation Accuracy: 0.3667, Percentage:36.6667%\n",
            "Epoch [257/1500], Training Loss: 0.8090, Validation Loss: 3.6257, Validation Accuracy: 0.3706, Percentage:37.0588%\n",
            "Epoch [258/1500], Training Loss: 0.6771, Validation Loss: 3.5861, Validation Accuracy: 0.3775, Percentage:37.7451%\n",
            "Epoch [259/1500], Training Loss: 0.7109, Validation Loss: 3.8408, Validation Accuracy: 0.3784, Percentage:37.8431%\n",
            "Epoch [260/1500], Training Loss: 0.7502, Validation Loss: 3.8768, Validation Accuracy: 0.3784, Percentage:37.8431%\n",
            "Epoch [261/1500], Training Loss: 0.7060, Validation Loss: 3.5627, Validation Accuracy: 0.3804, Percentage:38.0392%\n",
            "Epoch [262/1500], Training Loss: 0.6497, Validation Loss: 3.7819, Validation Accuracy: 0.3706, Percentage:37.0588%\n",
            "Epoch [263/1500], Training Loss: 0.7175, Validation Loss: 3.6856, Validation Accuracy: 0.3863, Percentage:38.6275%\n",
            "Epoch [264/1500], Training Loss: 0.7510, Validation Loss: 3.8185, Validation Accuracy: 0.3667, Percentage:36.6667%\n",
            "Epoch [265/1500], Training Loss: 0.7094, Validation Loss: 3.9194, Validation Accuracy: 0.3676, Percentage:36.7647%\n",
            "Epoch [266/1500], Training Loss: 0.8123, Validation Loss: 3.8422, Validation Accuracy: 0.3667, Percentage:36.6667%\n",
            "Epoch [267/1500], Training Loss: 0.7418, Validation Loss: 3.7671, Validation Accuracy: 0.3725, Percentage:37.2549%\n",
            "Epoch [268/1500], Training Loss: 0.7546, Validation Loss: 3.7032, Validation Accuracy: 0.3794, Percentage:37.9412%\n",
            "Epoch [269/1500], Training Loss: 0.7566, Validation Loss: 3.6395, Validation Accuracy: 0.3824, Percentage:38.2353%\n",
            "Epoch [270/1500], Training Loss: 0.7115, Validation Loss: 3.7998, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [271/1500], Training Loss: 0.7592, Validation Loss: 3.7549, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [272/1500], Training Loss: 0.7279, Validation Loss: 3.6332, Validation Accuracy: 0.3804, Percentage:38.0392%\n",
            "Epoch [273/1500], Training Loss: 0.6391, Validation Loss: 3.8190, Validation Accuracy: 0.3784, Percentage:37.8431%\n",
            "Epoch [274/1500], Training Loss: 0.7020, Validation Loss: 3.7018, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [275/1500], Training Loss: 0.6951, Validation Loss: 3.6796, Validation Accuracy: 0.3912, Percentage:39.1176%\n",
            "Epoch [276/1500], Training Loss: 0.7328, Validation Loss: 3.6738, Validation Accuracy: 0.3892, Percentage:38.9216%\n",
            "Epoch [277/1500], Training Loss: 0.7153, Validation Loss: 3.9119, Validation Accuracy: 0.3686, Percentage:36.8627%\n",
            "Epoch [278/1500], Training Loss: 0.6754, Validation Loss: 3.7388, Validation Accuracy: 0.3784, Percentage:37.8431%\n",
            "Epoch [279/1500], Training Loss: 0.6541, Validation Loss: 3.9106, Validation Accuracy: 0.3618, Percentage:36.1765%\n",
            "Epoch [280/1500], Training Loss: 0.7101, Validation Loss: 3.6742, Validation Accuracy: 0.3696, Percentage:36.9608%\n",
            "Epoch [281/1500], Training Loss: 0.6169, Validation Loss: 3.6783, Validation Accuracy: 0.3843, Percentage:38.4314%\n",
            "Epoch [282/1500], Training Loss: 0.6880, Validation Loss: 3.7375, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [283/1500], Training Loss: 0.5832, Validation Loss: 3.9034, Validation Accuracy: 0.3696, Percentage:36.9608%\n",
            "Epoch [284/1500], Training Loss: 0.6736, Validation Loss: 3.7793, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [285/1500], Training Loss: 0.6115, Validation Loss: 3.8591, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [286/1500], Training Loss: 0.6947, Validation Loss: 3.8942, Validation Accuracy: 0.3912, Percentage:39.1176%\n",
            "Epoch [287/1500], Training Loss: 0.6918, Validation Loss: 3.8243, Validation Accuracy: 0.3824, Percentage:38.2353%\n",
            "Epoch [288/1500], Training Loss: 0.5847, Validation Loss: 3.6753, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [289/1500], Training Loss: 0.6213, Validation Loss: 3.8610, Validation Accuracy: 0.3853, Percentage:38.5294%\n",
            "Epoch [290/1500], Training Loss: 0.6772, Validation Loss: 3.7708, Validation Accuracy: 0.3706, Percentage:37.0588%\n",
            "Epoch [291/1500], Training Loss: 0.7392, Validation Loss: 3.8359, Validation Accuracy: 0.3745, Percentage:37.4510%\n",
            "Epoch [292/1500], Training Loss: 0.6581, Validation Loss: 3.7296, Validation Accuracy: 0.3853, Percentage:38.5294%\n",
            "Epoch [293/1500], Training Loss: 0.6402, Validation Loss: 3.7901, Validation Accuracy: 0.3588, Percentage:35.8824%\n",
            "Epoch [294/1500], Training Loss: 0.6303, Validation Loss: 3.7566, Validation Accuracy: 0.3735, Percentage:37.3529%\n",
            "Epoch [295/1500], Training Loss: 0.7069, Validation Loss: 3.6379, Validation Accuracy: 0.3912, Percentage:39.1176%\n",
            "Epoch [296/1500], Training Loss: 0.7166, Validation Loss: 3.7221, Validation Accuracy: 0.3735, Percentage:37.3529%\n",
            "Epoch [297/1500], Training Loss: 0.6802, Validation Loss: 3.6979, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [298/1500], Training Loss: 0.6592, Validation Loss: 3.8909, Validation Accuracy: 0.3745, Percentage:37.4510%\n",
            "Epoch [299/1500], Training Loss: 0.7384, Validation Loss: 3.9020, Validation Accuracy: 0.3735, Percentage:37.3529%\n",
            "Epoch [300/1500], Training Loss: 0.7097, Validation Loss: 3.8508, Validation Accuracy: 0.3539, Percentage:35.3922%\n",
            "Epoch [301/1500], Training Loss: 0.6321, Validation Loss: 3.8877, Validation Accuracy: 0.3598, Percentage:35.9804%\n",
            "Epoch [302/1500], Training Loss: 0.6117, Validation Loss: 3.7125, Validation Accuracy: 0.3725, Percentage:37.2549%\n",
            "Epoch [303/1500], Training Loss: 0.6598, Validation Loss: 3.8576, Validation Accuracy: 0.3902, Percentage:39.0196%\n",
            "Epoch [304/1500], Training Loss: 0.6507, Validation Loss: 3.7621, Validation Accuracy: 0.3755, Percentage:37.5490%\n",
            "Epoch [305/1500], Training Loss: 0.6740, Validation Loss: 3.6788, Validation Accuracy: 0.3735, Percentage:37.3529%\n",
            "Epoch [306/1500], Training Loss: 0.6962, Validation Loss: 3.9013, Validation Accuracy: 0.3696, Percentage:36.9608%\n",
            "Epoch [307/1500], Training Loss: 0.6340, Validation Loss: 3.8287, Validation Accuracy: 0.3912, Percentage:39.1176%\n",
            "Epoch [308/1500], Training Loss: 0.7088, Validation Loss: 3.9206, Validation Accuracy: 0.3775, Percentage:37.7451%\n",
            "Epoch [309/1500], Training Loss: 0.7557, Validation Loss: 3.7428, Validation Accuracy: 0.3676, Percentage:36.7647%\n",
            "Epoch [310/1500], Training Loss: 0.6250, Validation Loss: 3.9015, Validation Accuracy: 0.3618, Percentage:36.1765%\n",
            "Epoch [311/1500], Training Loss: 0.6664, Validation Loss: 3.9385, Validation Accuracy: 0.3863, Percentage:38.6275%\n",
            "Epoch [312/1500], Training Loss: 0.7154, Validation Loss: 3.7544, Validation Accuracy: 0.3549, Percentage:35.4902%\n",
            "Epoch [313/1500], Training Loss: 0.7057, Validation Loss: 3.5830, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [314/1500], Training Loss: 0.5868, Validation Loss: 3.7679, Validation Accuracy: 0.3716, Percentage:37.1569%\n",
            "Epoch [315/1500], Training Loss: 0.6582, Validation Loss: 3.7760, Validation Accuracy: 0.3745, Percentage:37.4510%\n",
            "Epoch [316/1500], Training Loss: 0.6172, Validation Loss: 3.8768, Validation Accuracy: 0.3843, Percentage:38.4314%\n",
            "Epoch [317/1500], Training Loss: 0.7421, Validation Loss: 3.9870, Validation Accuracy: 0.3667, Percentage:36.6667%\n",
            "Epoch [318/1500], Training Loss: 0.6347, Validation Loss: 3.7438, Validation Accuracy: 0.3794, Percentage:37.9412%\n",
            "Epoch [319/1500], Training Loss: 0.6917, Validation Loss: 3.8450, Validation Accuracy: 0.3784, Percentage:37.8431%\n",
            "Epoch [320/1500], Training Loss: 0.6588, Validation Loss: 3.7981, Validation Accuracy: 0.3598, Percentage:35.9804%\n",
            "Epoch [321/1500], Training Loss: 0.6963, Validation Loss: 4.0387, Validation Accuracy: 0.3637, Percentage:36.3725%\n",
            "Epoch [322/1500], Training Loss: 0.7203, Validation Loss: 3.6606, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [323/1500], Training Loss: 0.6238, Validation Loss: 3.7813, Validation Accuracy: 0.3725, Percentage:37.2549%\n",
            "Epoch [324/1500], Training Loss: 0.6311, Validation Loss: 3.7601, Validation Accuracy: 0.3745, Percentage:37.4510%\n",
            "Epoch [325/1500], Training Loss: 0.5983, Validation Loss: 3.8286, Validation Accuracy: 0.3804, Percentage:38.0392%\n",
            "Epoch [326/1500], Training Loss: 0.5835, Validation Loss: 3.7280, Validation Accuracy: 0.3902, Percentage:39.0196%\n",
            "Epoch [327/1500], Training Loss: 0.6682, Validation Loss: 3.7876, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [328/1500], Training Loss: 0.5906, Validation Loss: 3.8392, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [329/1500], Training Loss: 0.6993, Validation Loss: 3.9436, Validation Accuracy: 0.3784, Percentage:37.8431%\n",
            "Epoch [330/1500], Training Loss: 0.7214, Validation Loss: 3.9439, Validation Accuracy: 0.3667, Percentage:36.6667%\n",
            "Epoch [331/1500], Training Loss: 0.6546, Validation Loss: 3.7644, Validation Accuracy: 0.3676, Percentage:36.7647%\n",
            "Epoch [332/1500], Training Loss: 0.6180, Validation Loss: 3.9089, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [333/1500], Training Loss: 0.6086, Validation Loss: 3.8418, Validation Accuracy: 0.3814, Percentage:38.1373%\n",
            "Epoch [334/1500], Training Loss: 0.6624, Validation Loss: 3.8157, Validation Accuracy: 0.3824, Percentage:38.2353%\n",
            "Epoch [335/1500], Training Loss: 0.5442, Validation Loss: 3.9979, Validation Accuracy: 0.3804, Percentage:38.0392%\n",
            "Epoch [336/1500], Training Loss: 0.5498, Validation Loss: 3.9086, Validation Accuracy: 0.3765, Percentage:37.6471%\n",
            "Epoch [337/1500], Training Loss: 0.6245, Validation Loss: 3.9126, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [338/1500], Training Loss: 0.6714, Validation Loss: 3.7732, Validation Accuracy: 0.3706, Percentage:37.0588%\n",
            "Epoch [339/1500], Training Loss: 0.5517, Validation Loss: 4.0174, Validation Accuracy: 0.3824, Percentage:38.2353%\n",
            "Epoch [340/1500], Training Loss: 0.7308, Validation Loss: 3.8028, Validation Accuracy: 0.3882, Percentage:38.8235%\n",
            "Epoch [341/1500], Training Loss: 0.5996, Validation Loss: 3.9833, Validation Accuracy: 0.3735, Percentage:37.3529%\n",
            "Epoch [342/1500], Training Loss: 0.6705, Validation Loss: 3.9183, Validation Accuracy: 0.3706, Percentage:37.0588%\n",
            "Epoch [343/1500], Training Loss: 0.6276, Validation Loss: 3.9859, Validation Accuracy: 0.3725, Percentage:37.2549%\n",
            "Epoch [344/1500], Training Loss: 0.5973, Validation Loss: 4.1022, Validation Accuracy: 0.3588, Percentage:35.8824%\n",
            "Epoch [345/1500], Training Loss: 0.6170, Validation Loss: 3.8972, Validation Accuracy: 0.3755, Percentage:37.5490%\n",
            "Epoch [346/1500], Training Loss: 0.6722, Validation Loss: 3.9600, Validation Accuracy: 0.3686, Percentage:36.8627%\n",
            "Epoch [347/1500], Training Loss: 0.6545, Validation Loss: 3.9727, Validation Accuracy: 0.3814, Percentage:38.1373%\n",
            "Epoch [348/1500], Training Loss: 0.6043, Validation Loss: 3.9903, Validation Accuracy: 0.3794, Percentage:37.9412%\n",
            "Epoch [349/1500], Training Loss: 0.5707, Validation Loss: 3.9287, Validation Accuracy: 0.3745, Percentage:37.4510%\n",
            "Epoch [350/1500], Training Loss: 0.6064, Validation Loss: 3.8775, Validation Accuracy: 0.3814, Percentage:38.1373%\n",
            "Epoch [351/1500], Training Loss: 0.5238, Validation Loss: 4.1734, Validation Accuracy: 0.3735, Percentage:37.3529%\n",
            "Epoch [352/1500], Training Loss: 0.6450, Validation Loss: 3.6756, Validation Accuracy: 0.3735, Percentage:37.3529%\n",
            "Epoch [353/1500], Training Loss: 0.6073, Validation Loss: 3.9124, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [354/1500], Training Loss: 0.6101, Validation Loss: 4.1014, Validation Accuracy: 0.3686, Percentage:36.8627%\n",
            "Epoch [355/1500], Training Loss: 0.6332, Validation Loss: 4.0022, Validation Accuracy: 0.3882, Percentage:38.8235%\n",
            "Epoch [356/1500], Training Loss: 0.6244, Validation Loss: 3.9538, Validation Accuracy: 0.3863, Percentage:38.6275%\n",
            "Epoch [357/1500], Training Loss: 0.5526, Validation Loss: 3.9863, Validation Accuracy: 0.3745, Percentage:37.4510%\n",
            "Epoch [358/1500], Training Loss: 0.5799, Validation Loss: 4.1218, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [359/1500], Training Loss: 0.6337, Validation Loss: 3.8238, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [360/1500], Training Loss: 0.6251, Validation Loss: 3.8845, Validation Accuracy: 0.3755, Percentage:37.5490%\n",
            "Epoch [361/1500], Training Loss: 0.5523, Validation Loss: 3.8706, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [362/1500], Training Loss: 0.5776, Validation Loss: 4.3019, Validation Accuracy: 0.3598, Percentage:35.9804%\n",
            "Epoch [363/1500], Training Loss: 0.5854, Validation Loss: 4.0632, Validation Accuracy: 0.3853, Percentage:38.5294%\n",
            "Epoch [364/1500], Training Loss: 0.5598, Validation Loss: 4.0729, Validation Accuracy: 0.3892, Percentage:38.9216%\n",
            "Epoch [365/1500], Training Loss: 0.6047, Validation Loss: 3.9589, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [366/1500], Training Loss: 0.5883, Validation Loss: 4.2595, Validation Accuracy: 0.3755, Percentage:37.5490%\n",
            "Epoch [367/1500], Training Loss: 0.6261, Validation Loss: 3.8828, Validation Accuracy: 0.3902, Percentage:39.0196%\n",
            "Epoch [368/1500], Training Loss: 0.5678, Validation Loss: 4.2503, Validation Accuracy: 0.3775, Percentage:37.7451%\n",
            "Epoch [369/1500], Training Loss: 0.6097, Validation Loss: 3.8805, Validation Accuracy: 0.3853, Percentage:38.5294%\n",
            "Epoch [370/1500], Training Loss: 0.5923, Validation Loss: 3.9699, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [371/1500], Training Loss: 0.6032, Validation Loss: 3.9409, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [372/1500], Training Loss: 0.5558, Validation Loss: 4.0979, Validation Accuracy: 0.3696, Percentage:36.9608%\n",
            "Epoch [373/1500], Training Loss: 0.5803, Validation Loss: 4.0149, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [374/1500], Training Loss: 0.6516, Validation Loss: 3.9421, Validation Accuracy: 0.3755, Percentage:37.5490%\n",
            "Epoch [375/1500], Training Loss: 0.6049, Validation Loss: 4.0496, Validation Accuracy: 0.3637, Percentage:36.3725%\n",
            "Epoch [376/1500], Training Loss: 0.6552, Validation Loss: 3.9214, Validation Accuracy: 0.3608, Percentage:36.0784%\n",
            "Epoch [377/1500], Training Loss: 0.5441, Validation Loss: 4.4274, Validation Accuracy: 0.3657, Percentage:36.5686%\n",
            "Epoch [378/1500], Training Loss: 0.6555, Validation Loss: 3.9678, Validation Accuracy: 0.3696, Percentage:36.9608%\n",
            "Epoch [379/1500], Training Loss: 0.6097, Validation Loss: 3.8237, Validation Accuracy: 0.3853, Percentage:38.5294%\n",
            "Epoch [380/1500], Training Loss: 0.5317, Validation Loss: 4.0938, Validation Accuracy: 0.3892, Percentage:38.9216%\n",
            "Epoch [381/1500], Training Loss: 0.4608, Validation Loss: 4.4261, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [382/1500], Training Loss: 0.5400, Validation Loss: 4.0274, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [383/1500], Training Loss: 0.5680, Validation Loss: 4.1769, Validation Accuracy: 0.3735, Percentage:37.3529%\n",
            "Epoch [384/1500], Training Loss: 0.5097, Validation Loss: 4.0688, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [385/1500], Training Loss: 0.5040, Validation Loss: 4.2559, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [386/1500], Training Loss: 0.5008, Validation Loss: 4.1132, Validation Accuracy: 0.3745, Percentage:37.4510%\n",
            "Epoch [387/1500], Training Loss: 0.6508, Validation Loss: 4.0936, Validation Accuracy: 0.3843, Percentage:38.4314%\n",
            "Epoch [388/1500], Training Loss: 0.5307, Validation Loss: 4.0754, Validation Accuracy: 0.3804, Percentage:38.0392%\n",
            "Epoch [389/1500], Training Loss: 0.6451, Validation Loss: 3.9909, Validation Accuracy: 0.3804, Percentage:38.0392%\n",
            "Epoch [390/1500], Training Loss: 0.6247, Validation Loss: 3.8625, Validation Accuracy: 0.3892, Percentage:38.9216%\n",
            "Epoch [391/1500], Training Loss: 0.5590, Validation Loss: 4.0390, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [392/1500], Training Loss: 0.5105, Validation Loss: 3.7902, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [393/1500], Training Loss: 0.5657, Validation Loss: 4.1361, Validation Accuracy: 0.3902, Percentage:39.0196%\n",
            "Epoch [394/1500], Training Loss: 0.5871, Validation Loss: 3.9291, Validation Accuracy: 0.3853, Percentage:38.5294%\n",
            "Epoch [395/1500], Training Loss: 0.5598, Validation Loss: 4.0941, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [396/1500], Training Loss: 0.6209, Validation Loss: 4.1809, Validation Accuracy: 0.3824, Percentage:38.2353%\n",
            "Epoch [397/1500], Training Loss: 0.5781, Validation Loss: 4.1862, Validation Accuracy: 0.3784, Percentage:37.8431%\n",
            "Epoch [398/1500], Training Loss: 0.4357, Validation Loss: 4.3599, Validation Accuracy: 0.3833, Percentage:38.3333%\n",
            "Epoch [399/1500], Training Loss: 0.6124, Validation Loss: 4.0783, Validation Accuracy: 0.3912, Percentage:39.1176%\n",
            "Epoch [400/1500], Training Loss: 0.5194, Validation Loss: 4.0965, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [401/1500], Training Loss: 0.5370, Validation Loss: 4.1297, Validation Accuracy: 0.3608, Percentage:36.0784%\n",
            "Epoch [402/1500], Training Loss: 0.5062, Validation Loss: 3.9982, Validation Accuracy: 0.3912, Percentage:39.1176%\n",
            "Epoch [403/1500], Training Loss: 0.5836, Validation Loss: 4.0235, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [404/1500], Training Loss: 0.5417, Validation Loss: 4.0242, Validation Accuracy: 0.3755, Percentage:37.5490%\n",
            "Epoch [405/1500], Training Loss: 0.5222, Validation Loss: 4.0943, Validation Accuracy: 0.3892, Percentage:38.9216%\n",
            "Epoch [406/1500], Training Loss: 0.5956, Validation Loss: 4.0522, Validation Accuracy: 0.3892, Percentage:38.9216%\n",
            "Epoch [407/1500], Training Loss: 0.5722, Validation Loss: 4.1347, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [408/1500], Training Loss: 0.5407, Validation Loss: 3.9132, Validation Accuracy: 0.3608, Percentage:36.0784%\n",
            "Epoch [409/1500], Training Loss: 0.5144, Validation Loss: 4.1508, Validation Accuracy: 0.3814, Percentage:38.1373%\n",
            "Epoch [410/1500], Training Loss: 0.5448, Validation Loss: 4.0833, Validation Accuracy: 0.3725, Percentage:37.2549%\n",
            "Epoch [411/1500], Training Loss: 0.5337, Validation Loss: 4.1801, Validation Accuracy: 0.3735, Percentage:37.3529%\n",
            "Epoch [412/1500], Training Loss: 0.5206, Validation Loss: 4.0856, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [413/1500], Training Loss: 0.5141, Validation Loss: 4.1422, Validation Accuracy: 0.3863, Percentage:38.6275%\n",
            "Epoch [414/1500], Training Loss: 0.6039, Validation Loss: 3.9757, Validation Accuracy: 0.3735, Percentage:37.3529%\n",
            "Epoch [415/1500], Training Loss: 0.4820, Validation Loss: 4.0378, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [416/1500], Training Loss: 0.5815, Validation Loss: 4.0422, Validation Accuracy: 0.3814, Percentage:38.1373%\n",
            "Epoch [417/1500], Training Loss: 0.4594, Validation Loss: 4.0208, Validation Accuracy: 0.3804, Percentage:38.0392%\n",
            "Epoch [418/1500], Training Loss: 0.5402, Validation Loss: 4.1244, Validation Accuracy: 0.3794, Percentage:37.9412%\n",
            "Epoch [419/1500], Training Loss: 0.5543, Validation Loss: 4.0097, Validation Accuracy: 0.3755, Percentage:37.5490%\n",
            "Epoch [420/1500], Training Loss: 0.5640, Validation Loss: 4.4037, Validation Accuracy: 0.3784, Percentage:37.8431%\n",
            "Epoch [421/1500], Training Loss: 0.5526, Validation Loss: 4.1217, Validation Accuracy: 0.3902, Percentage:39.0196%\n",
            "Epoch [422/1500], Training Loss: 0.5814, Validation Loss: 4.1412, Validation Accuracy: 0.3794, Percentage:37.9412%\n",
            "Epoch [423/1500], Training Loss: 0.5725, Validation Loss: 3.9846, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [424/1500], Training Loss: 0.5989, Validation Loss: 4.0551, Validation Accuracy: 0.3882, Percentage:38.8235%\n",
            "Epoch [425/1500], Training Loss: 0.5840, Validation Loss: 4.1332, Validation Accuracy: 0.3696, Percentage:36.9608%\n",
            "Epoch [426/1500], Training Loss: 0.5160, Validation Loss: 3.9244, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [427/1500], Training Loss: 0.5406, Validation Loss: 4.0388, Validation Accuracy: 0.3902, Percentage:39.0196%\n",
            "Epoch [428/1500], Training Loss: 0.4758, Validation Loss: 4.1311, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [429/1500], Training Loss: 0.5459, Validation Loss: 4.3485, Validation Accuracy: 0.3902, Percentage:39.0196%\n",
            "Epoch [430/1500], Training Loss: 0.5271, Validation Loss: 4.2215, Validation Accuracy: 0.3863, Percentage:38.6275%\n",
            "Epoch [431/1500], Training Loss: 0.5238, Validation Loss: 4.1784, Validation Accuracy: 0.3843, Percentage:38.4314%\n",
            "Epoch [432/1500], Training Loss: 0.5841, Validation Loss: 4.1192, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [433/1500], Training Loss: 0.5513, Validation Loss: 3.9437, Validation Accuracy: 0.4225, Percentage:42.2549%\n",
            "Epoch [434/1500], Training Loss: 0.5473, Validation Loss: 4.0697, Validation Accuracy: 0.3833, Percentage:38.3333%\n",
            "Epoch [435/1500], Training Loss: 0.5485, Validation Loss: 4.2473, Validation Accuracy: 0.3902, Percentage:39.0196%\n",
            "Epoch [436/1500], Training Loss: 0.5312, Validation Loss: 4.0871, Validation Accuracy: 0.3902, Percentage:39.0196%\n",
            "Epoch [437/1500], Training Loss: 0.4481, Validation Loss: 4.1268, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [438/1500], Training Loss: 0.5237, Validation Loss: 3.9976, Validation Accuracy: 0.3882, Percentage:38.8235%\n",
            "Epoch [439/1500], Training Loss: 0.5954, Validation Loss: 3.8591, Validation Accuracy: 0.3804, Percentage:38.0392%\n",
            "Epoch [440/1500], Training Loss: 0.5798, Validation Loss: 4.0110, Validation Accuracy: 0.3912, Percentage:39.1176%\n",
            "Epoch [441/1500], Training Loss: 0.5725, Validation Loss: 4.1318, Validation Accuracy: 0.3745, Percentage:37.4510%\n",
            "Epoch [442/1500], Training Loss: 0.5198, Validation Loss: 4.2113, Validation Accuracy: 0.3804, Percentage:38.0392%\n",
            "Epoch [443/1500], Training Loss: 0.4964, Validation Loss: 4.1371, Validation Accuracy: 0.3637, Percentage:36.3725%\n",
            "Epoch [444/1500], Training Loss: 0.4726, Validation Loss: 4.2995, Validation Accuracy: 0.3892, Percentage:38.9216%\n",
            "Epoch [445/1500], Training Loss: 0.5534, Validation Loss: 3.9870, Validation Accuracy: 0.3745, Percentage:37.4510%\n",
            "Epoch [446/1500], Training Loss: 0.5596, Validation Loss: 4.3900, Validation Accuracy: 0.3804, Percentage:38.0392%\n",
            "Epoch [447/1500], Training Loss: 0.5268, Validation Loss: 4.2536, Validation Accuracy: 0.3843, Percentage:38.4314%\n",
            "Epoch [448/1500], Training Loss: 0.5267, Validation Loss: 4.1324, Validation Accuracy: 0.3843, Percentage:38.4314%\n",
            "Epoch [449/1500], Training Loss: 0.4932, Validation Loss: 4.0664, Validation Accuracy: 0.3863, Percentage:38.6275%\n",
            "Epoch [450/1500], Training Loss: 0.5000, Validation Loss: 4.1515, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [451/1500], Training Loss: 0.5037, Validation Loss: 4.1739, Validation Accuracy: 0.3804, Percentage:38.0392%\n",
            "Epoch [452/1500], Training Loss: 0.5810, Validation Loss: 4.0795, Validation Accuracy: 0.3902, Percentage:39.0196%\n",
            "Epoch [453/1500], Training Loss: 0.5791, Validation Loss: 4.1836, Validation Accuracy: 0.3784, Percentage:37.8431%\n",
            "Epoch [454/1500], Training Loss: 0.5356, Validation Loss: 3.9289, Validation Accuracy: 0.3775, Percentage:37.7451%\n",
            "Epoch [455/1500], Training Loss: 0.5930, Validation Loss: 4.0807, Validation Accuracy: 0.3765, Percentage:37.6471%\n",
            "Epoch [456/1500], Training Loss: 0.5224, Validation Loss: 3.9490, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [457/1500], Training Loss: 0.4650, Validation Loss: 4.0664, Validation Accuracy: 0.3725, Percentage:37.2549%\n",
            "Epoch [458/1500], Training Loss: 0.5279, Validation Loss: 4.1906, Validation Accuracy: 0.3775, Percentage:37.7451%\n",
            "Epoch [459/1500], Training Loss: 0.5175, Validation Loss: 4.1579, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [460/1500], Training Loss: 0.5149, Validation Loss: 3.9223, Validation Accuracy: 0.3784, Percentage:37.8431%\n",
            "Epoch [461/1500], Training Loss: 0.5117, Validation Loss: 4.3078, Validation Accuracy: 0.3765, Percentage:37.6471%\n",
            "Epoch [462/1500], Training Loss: 0.5527, Validation Loss: 3.9920, Validation Accuracy: 0.3892, Percentage:38.9216%\n",
            "Epoch [463/1500], Training Loss: 0.5552, Validation Loss: 4.3732, Validation Accuracy: 0.3804, Percentage:38.0392%\n",
            "Epoch [464/1500], Training Loss: 0.4920, Validation Loss: 4.1503, Validation Accuracy: 0.3725, Percentage:37.2549%\n",
            "Epoch [465/1500], Training Loss: 0.4970, Validation Loss: 4.2210, Validation Accuracy: 0.3853, Percentage:38.5294%\n",
            "Epoch [466/1500], Training Loss: 0.4711, Validation Loss: 4.2515, Validation Accuracy: 0.3912, Percentage:39.1176%\n",
            "Epoch [467/1500], Training Loss: 0.4940, Validation Loss: 4.2581, Validation Accuracy: 0.3843, Percentage:38.4314%\n",
            "Epoch [468/1500], Training Loss: 0.4603, Validation Loss: 4.1655, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [469/1500], Training Loss: 0.4741, Validation Loss: 4.2629, Validation Accuracy: 0.3833, Percentage:38.3333%\n",
            "Epoch [470/1500], Training Loss: 0.4686, Validation Loss: 4.1752, Validation Accuracy: 0.3892, Percentage:38.9216%\n",
            "Epoch [471/1500], Training Loss: 0.5830, Validation Loss: 4.3037, Validation Accuracy: 0.3892, Percentage:38.9216%\n",
            "Epoch [472/1500], Training Loss: 0.5221, Validation Loss: 4.1937, Validation Accuracy: 0.3804, Percentage:38.0392%\n",
            "Epoch [473/1500], Training Loss: 0.5305, Validation Loss: 3.9437, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [474/1500], Training Loss: 0.5208, Validation Loss: 4.2588, Validation Accuracy: 0.3814, Percentage:38.1373%\n",
            "Epoch [475/1500], Training Loss: 0.5254, Validation Loss: 4.1387, Validation Accuracy: 0.3863, Percentage:38.6275%\n",
            "Epoch [476/1500], Training Loss: 0.5483, Validation Loss: 4.1382, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [477/1500], Training Loss: 0.5362, Validation Loss: 4.1541, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [478/1500], Training Loss: 0.5239, Validation Loss: 3.9317, Validation Accuracy: 0.3784, Percentage:37.8431%\n",
            "Epoch [479/1500], Training Loss: 0.4341, Validation Loss: 4.3806, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [480/1500], Training Loss: 0.4373, Validation Loss: 4.1935, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [481/1500], Training Loss: 0.5069, Validation Loss: 4.1081, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [482/1500], Training Loss: 0.4939, Validation Loss: 4.0579, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [483/1500], Training Loss: 0.4740, Validation Loss: 4.1984, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [484/1500], Training Loss: 0.4328, Validation Loss: 4.1992, Validation Accuracy: 0.3794, Percentage:37.9412%\n",
            "Epoch [485/1500], Training Loss: 0.5488, Validation Loss: 4.6643, Validation Accuracy: 0.3843, Percentage:38.4314%\n",
            "Epoch [486/1500], Training Loss: 0.5102, Validation Loss: 4.2449, Validation Accuracy: 0.3735, Percentage:37.3529%\n",
            "Epoch [487/1500], Training Loss: 0.4705, Validation Loss: 4.2268, Validation Accuracy: 0.3814, Percentage:38.1373%\n",
            "Epoch [488/1500], Training Loss: 0.5209, Validation Loss: 4.2148, Validation Accuracy: 0.3863, Percentage:38.6275%\n",
            "Epoch [489/1500], Training Loss: 0.4645, Validation Loss: 4.2519, Validation Accuracy: 0.3853, Percentage:38.5294%\n",
            "Epoch [490/1500], Training Loss: 0.5398, Validation Loss: 3.9320, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [491/1500], Training Loss: 0.4523, Validation Loss: 4.0877, Validation Accuracy: 0.3804, Percentage:38.0392%\n",
            "Epoch [492/1500], Training Loss: 0.5591, Validation Loss: 4.2484, Validation Accuracy: 0.3745, Percentage:37.4510%\n",
            "Epoch [493/1500], Training Loss: 0.3873, Validation Loss: 4.5289, Validation Accuracy: 0.3843, Percentage:38.4314%\n",
            "Epoch [494/1500], Training Loss: 0.4912, Validation Loss: 4.2452, Validation Accuracy: 0.3784, Percentage:37.8431%\n",
            "Epoch [495/1500], Training Loss: 0.5156, Validation Loss: 4.1578, Validation Accuracy: 0.3863, Percentage:38.6275%\n",
            "Epoch [496/1500], Training Loss: 0.4635, Validation Loss: 4.4727, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [497/1500], Training Loss: 0.4105, Validation Loss: 4.4168, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [498/1500], Training Loss: 0.4984, Validation Loss: 4.1915, Validation Accuracy: 0.3824, Percentage:38.2353%\n",
            "Epoch [499/1500], Training Loss: 0.5720, Validation Loss: 4.0391, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [500/1500], Training Loss: 0.4742, Validation Loss: 4.0838, Validation Accuracy: 0.3755, Percentage:37.5490%\n",
            "Epoch [501/1500], Training Loss: 0.4394, Validation Loss: 4.3903, Validation Accuracy: 0.3794, Percentage:37.9412%\n",
            "Epoch [502/1500], Training Loss: 0.3949, Validation Loss: 4.1835, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [503/1500], Training Loss: 0.5529, Validation Loss: 4.0605, Validation Accuracy: 0.3824, Percentage:38.2353%\n",
            "Epoch [504/1500], Training Loss: 0.5128, Validation Loss: 4.1891, Validation Accuracy: 0.3902, Percentage:39.0196%\n",
            "Epoch [505/1500], Training Loss: 0.5031, Validation Loss: 4.0359, Validation Accuracy: 0.3902, Percentage:39.0196%\n",
            "Epoch [506/1500], Training Loss: 0.4244, Validation Loss: 4.2211, Validation Accuracy: 0.3902, Percentage:39.0196%\n",
            "Epoch [507/1500], Training Loss: 0.5735, Validation Loss: 3.9752, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [508/1500], Training Loss: 0.5218, Validation Loss: 4.2968, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [509/1500], Training Loss: 0.4917, Validation Loss: 4.3117, Validation Accuracy: 0.3716, Percentage:37.1569%\n",
            "Epoch [510/1500], Training Loss: 0.4871, Validation Loss: 4.0422, Validation Accuracy: 0.3843, Percentage:38.4314%\n",
            "Epoch [511/1500], Training Loss: 0.4353, Validation Loss: 4.2203, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [512/1500], Training Loss: 0.4646, Validation Loss: 4.3408, Validation Accuracy: 0.3833, Percentage:38.3333%\n",
            "Epoch [513/1500], Training Loss: 0.5439, Validation Loss: 4.3787, Validation Accuracy: 0.3794, Percentage:37.9412%\n",
            "Epoch [514/1500], Training Loss: 0.5279, Validation Loss: 4.1577, Validation Accuracy: 0.3765, Percentage:37.6471%\n",
            "Epoch [515/1500], Training Loss: 0.4816, Validation Loss: 4.1035, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [516/1500], Training Loss: 0.4981, Validation Loss: 4.0877, Validation Accuracy: 0.3902, Percentage:39.0196%\n",
            "Epoch [517/1500], Training Loss: 0.4439, Validation Loss: 4.3814, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [518/1500], Training Loss: 0.4777, Validation Loss: 4.2057, Validation Accuracy: 0.3833, Percentage:38.3333%\n",
            "Epoch [519/1500], Training Loss: 0.5214, Validation Loss: 4.3659, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [520/1500], Training Loss: 0.4435, Validation Loss: 4.2026, Validation Accuracy: 0.3902, Percentage:39.0196%\n",
            "Epoch [521/1500], Training Loss: 0.4609, Validation Loss: 4.4166, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [522/1500], Training Loss: 0.4333, Validation Loss: 4.4417, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [523/1500], Training Loss: 0.4827, Validation Loss: 4.1779, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [524/1500], Training Loss: 0.5193, Validation Loss: 4.4971, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [525/1500], Training Loss: 0.4964, Validation Loss: 4.3891, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [526/1500], Training Loss: 0.5375, Validation Loss: 4.5989, Validation Accuracy: 0.3696, Percentage:36.9608%\n",
            "Epoch [527/1500], Training Loss: 0.4275, Validation Loss: 4.2221, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [528/1500], Training Loss: 0.4791, Validation Loss: 4.3614, Validation Accuracy: 0.3892, Percentage:38.9216%\n",
            "Epoch [529/1500], Training Loss: 0.4605, Validation Loss: 4.2451, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [530/1500], Training Loss: 0.4406, Validation Loss: 4.3170, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [531/1500], Training Loss: 0.5048, Validation Loss: 4.3153, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [532/1500], Training Loss: 0.4333, Validation Loss: 4.2645, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [533/1500], Training Loss: 0.5020, Validation Loss: 4.2375, Validation Accuracy: 0.3804, Percentage:38.0392%\n",
            "Epoch [534/1500], Training Loss: 0.5155, Validation Loss: 4.2305, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [535/1500], Training Loss: 0.4488, Validation Loss: 4.4071, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [536/1500], Training Loss: 0.4762, Validation Loss: 4.0840, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [537/1500], Training Loss: 0.4720, Validation Loss: 4.2028, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [538/1500], Training Loss: 0.4038, Validation Loss: 4.3382, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [539/1500], Training Loss: 0.5031, Validation Loss: 4.1763, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [540/1500], Training Loss: 0.4881, Validation Loss: 4.4890, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [541/1500], Training Loss: 0.4751, Validation Loss: 4.3956, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [542/1500], Training Loss: 0.4529, Validation Loss: 4.1415, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [543/1500], Training Loss: 0.4495, Validation Loss: 4.2708, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [544/1500], Training Loss: 0.4770, Validation Loss: 4.2167, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [545/1500], Training Loss: 0.5116, Validation Loss: 4.3886, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [546/1500], Training Loss: 0.4935, Validation Loss: 4.2157, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [547/1500], Training Loss: 0.4245, Validation Loss: 4.2778, Validation Accuracy: 0.3784, Percentage:37.8431%\n",
            "Epoch [548/1500], Training Loss: 0.4852, Validation Loss: 4.2622, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [549/1500], Training Loss: 0.3770, Validation Loss: 4.1480, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [550/1500], Training Loss: 0.4112, Validation Loss: 4.2765, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [551/1500], Training Loss: 0.4468, Validation Loss: 4.2446, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [552/1500], Training Loss: 0.4649, Validation Loss: 4.4118, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [553/1500], Training Loss: 0.4840, Validation Loss: 4.2669, Validation Accuracy: 0.3902, Percentage:39.0196%\n",
            "Epoch [554/1500], Training Loss: 0.4767, Validation Loss: 4.2894, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [555/1500], Training Loss: 0.4331, Validation Loss: 4.1285, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [556/1500], Training Loss: 0.4813, Validation Loss: 4.2542, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [557/1500], Training Loss: 0.4573, Validation Loss: 4.3388, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [558/1500], Training Loss: 0.4893, Validation Loss: 4.0463, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [559/1500], Training Loss: 0.4958, Validation Loss: 4.2475, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [560/1500], Training Loss: 0.5214, Validation Loss: 4.1433, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [561/1500], Training Loss: 0.4187, Validation Loss: 4.0565, Validation Accuracy: 0.4225, Percentage:42.2549%\n",
            "Epoch [562/1500], Training Loss: 0.4711, Validation Loss: 4.3858, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [563/1500], Training Loss: 0.4228, Validation Loss: 4.3195, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [564/1500], Training Loss: 0.4681, Validation Loss: 4.4090, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [565/1500], Training Loss: 0.4162, Validation Loss: 4.2205, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [566/1500], Training Loss: 0.5017, Validation Loss: 4.4744, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [567/1500], Training Loss: 0.4574, Validation Loss: 4.3786, Validation Accuracy: 0.3804, Percentage:38.0392%\n",
            "Epoch [568/1500], Training Loss: 0.4410, Validation Loss: 4.3266, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [569/1500], Training Loss: 0.4503, Validation Loss: 4.2428, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [570/1500], Training Loss: 0.4381, Validation Loss: 4.5194, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [571/1500], Training Loss: 0.4335, Validation Loss: 4.5206, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [572/1500], Training Loss: 0.4413, Validation Loss: 4.4739, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [573/1500], Training Loss: 0.4060, Validation Loss: 4.1949, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [574/1500], Training Loss: 0.4086, Validation Loss: 4.6571, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [575/1500], Training Loss: 0.4408, Validation Loss: 4.3395, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [576/1500], Training Loss: 0.4650, Validation Loss: 4.4503, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [577/1500], Training Loss: 0.4577, Validation Loss: 4.1227, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [578/1500], Training Loss: 0.4323, Validation Loss: 4.5928, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [579/1500], Training Loss: 0.3899, Validation Loss: 4.3619, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [580/1500], Training Loss: 0.3923, Validation Loss: 4.4722, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [581/1500], Training Loss: 0.3941, Validation Loss: 4.6579, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [582/1500], Training Loss: 0.4808, Validation Loss: 4.3458, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [583/1500], Training Loss: 0.4657, Validation Loss: 4.2430, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [584/1500], Training Loss: 0.4550, Validation Loss: 4.1219, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [585/1500], Training Loss: 0.4258, Validation Loss: 4.6152, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [586/1500], Training Loss: 0.4100, Validation Loss: 4.1712, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [587/1500], Training Loss: 0.4082, Validation Loss: 4.4476, Validation Accuracy: 0.3784, Percentage:37.8431%\n",
            "Epoch [588/1500], Training Loss: 0.4568, Validation Loss: 4.3507, Validation Accuracy: 0.3912, Percentage:39.1176%\n",
            "Epoch [589/1500], Training Loss: 0.4633, Validation Loss: 4.4161, Validation Accuracy: 0.3902, Percentage:39.0196%\n",
            "Epoch [590/1500], Training Loss: 0.4831, Validation Loss: 4.3004, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [591/1500], Training Loss: 0.4377, Validation Loss: 4.4631, Validation Accuracy: 0.3853, Percentage:38.5294%\n",
            "Epoch [592/1500], Training Loss: 0.4929, Validation Loss: 4.4219, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [593/1500], Training Loss: 0.4446, Validation Loss: 4.8223, Validation Accuracy: 0.3667, Percentage:36.6667%\n",
            "Epoch [594/1500], Training Loss: 0.4338, Validation Loss: 4.4383, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [595/1500], Training Loss: 0.4866, Validation Loss: 4.2878, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [596/1500], Training Loss: 0.4349, Validation Loss: 4.3292, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [597/1500], Training Loss: 0.4164, Validation Loss: 4.4464, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [598/1500], Training Loss: 0.4456, Validation Loss: 4.5518, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [599/1500], Training Loss: 0.4744, Validation Loss: 4.4813, Validation Accuracy: 0.3843, Percentage:38.4314%\n",
            "Epoch [600/1500], Training Loss: 0.4348, Validation Loss: 4.3078, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [601/1500], Training Loss: 0.5013, Validation Loss: 4.4132, Validation Accuracy: 0.3824, Percentage:38.2353%\n",
            "Epoch [602/1500], Training Loss: 0.3841, Validation Loss: 4.5215, Validation Accuracy: 0.3853, Percentage:38.5294%\n",
            "Epoch [603/1500], Training Loss: 0.4003, Validation Loss: 4.3286, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [604/1500], Training Loss: 0.4532, Validation Loss: 4.4116, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [605/1500], Training Loss: 0.4309, Validation Loss: 4.5418, Validation Accuracy: 0.3863, Percentage:38.6275%\n",
            "Epoch [606/1500], Training Loss: 0.4825, Validation Loss: 4.3933, Validation Accuracy: 0.3814, Percentage:38.1373%\n",
            "Epoch [607/1500], Training Loss: 0.4772, Validation Loss: 4.2410, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [608/1500], Training Loss: 0.3940, Validation Loss: 4.3315, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [609/1500], Training Loss: 0.4630, Validation Loss: 4.3521, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [610/1500], Training Loss: 0.4516, Validation Loss: 4.7089, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [611/1500], Training Loss: 0.4107, Validation Loss: 4.4124, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [612/1500], Training Loss: 0.4030, Validation Loss: 4.5032, Validation Accuracy: 0.3882, Percentage:38.8235%\n",
            "Epoch [613/1500], Training Loss: 0.4428, Validation Loss: 4.3726, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [614/1500], Training Loss: 0.4293, Validation Loss: 4.3421, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [615/1500], Training Loss: 0.4270, Validation Loss: 4.4813, Validation Accuracy: 0.3863, Percentage:38.6275%\n",
            "Epoch [616/1500], Training Loss: 0.4303, Validation Loss: 4.3646, Validation Accuracy: 0.3912, Percentage:39.1176%\n",
            "Epoch [617/1500], Training Loss: 0.4539, Validation Loss: 4.5307, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [618/1500], Training Loss: 0.3496, Validation Loss: 4.4911, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [619/1500], Training Loss: 0.4517, Validation Loss: 4.3640, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [620/1500], Training Loss: 0.4186, Validation Loss: 4.5215, Validation Accuracy: 0.3882, Percentage:38.8235%\n",
            "Epoch [621/1500], Training Loss: 0.3799, Validation Loss: 4.6471, Validation Accuracy: 0.3755, Percentage:37.5490%\n",
            "Epoch [622/1500], Training Loss: 0.3798, Validation Loss: 4.4905, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [623/1500], Training Loss: 0.4123, Validation Loss: 4.3203, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [624/1500], Training Loss: 0.3794, Validation Loss: 4.4740, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [625/1500], Training Loss: 0.4587, Validation Loss: 4.7303, Validation Accuracy: 0.3892, Percentage:38.9216%\n",
            "Epoch [626/1500], Training Loss: 0.3810, Validation Loss: 4.5032, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [627/1500], Training Loss: 0.4094, Validation Loss: 4.6475, Validation Accuracy: 0.3912, Percentage:39.1176%\n",
            "Epoch [628/1500], Training Loss: 0.3670, Validation Loss: 4.9030, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [629/1500], Training Loss: 0.4335, Validation Loss: 4.4384, Validation Accuracy: 0.3902, Percentage:39.0196%\n",
            "Epoch [630/1500], Training Loss: 0.4029, Validation Loss: 4.5400, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [631/1500], Training Loss: 0.4376, Validation Loss: 4.5064, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [632/1500], Training Loss: 0.3973, Validation Loss: 4.3126, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [633/1500], Training Loss: 0.4613, Validation Loss: 4.2596, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [634/1500], Training Loss: 0.4803, Validation Loss: 4.4339, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [635/1500], Training Loss: 0.4605, Validation Loss: 4.3821, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [636/1500], Training Loss: 0.4065, Validation Loss: 4.2132, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [637/1500], Training Loss: 0.3757, Validation Loss: 4.3798, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [638/1500], Training Loss: 0.4456, Validation Loss: 4.0767, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [639/1500], Training Loss: 0.4083, Validation Loss: 4.7422, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [640/1500], Training Loss: 0.4998, Validation Loss: 4.1711, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [641/1500], Training Loss: 0.3922, Validation Loss: 4.4161, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [642/1500], Training Loss: 0.4666, Validation Loss: 4.3595, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [643/1500], Training Loss: 0.4163, Validation Loss: 4.4715, Validation Accuracy: 0.3833, Percentage:38.3333%\n",
            "Epoch [644/1500], Training Loss: 0.4296, Validation Loss: 4.4752, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [645/1500], Training Loss: 0.4662, Validation Loss: 4.6684, Validation Accuracy: 0.3892, Percentage:38.9216%\n",
            "Epoch [646/1500], Training Loss: 0.3922, Validation Loss: 4.5063, Validation Accuracy: 0.3765, Percentage:37.6471%\n",
            "Epoch [647/1500], Training Loss: 0.4342, Validation Loss: 4.3318, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [648/1500], Training Loss: 0.3747, Validation Loss: 4.5467, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [649/1500], Training Loss: 0.4125, Validation Loss: 4.4068, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [650/1500], Training Loss: 0.3584, Validation Loss: 4.6916, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [651/1500], Training Loss: 0.4013, Validation Loss: 4.6465, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [652/1500], Training Loss: 0.4173, Validation Loss: 4.4888, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [653/1500], Training Loss: 0.3952, Validation Loss: 4.5953, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [654/1500], Training Loss: 0.4058, Validation Loss: 4.6441, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [655/1500], Training Loss: 0.4598, Validation Loss: 4.5311, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [656/1500], Training Loss: 0.4564, Validation Loss: 4.4739, Validation Accuracy: 0.3892, Percentage:38.9216%\n",
            "Epoch [657/1500], Training Loss: 0.4008, Validation Loss: 4.4857, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [658/1500], Training Loss: 0.3763, Validation Loss: 4.5583, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [659/1500], Training Loss: 0.4207, Validation Loss: 4.5591, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [660/1500], Training Loss: 0.3174, Validation Loss: 4.4686, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [661/1500], Training Loss: 0.3980, Validation Loss: 4.5412, Validation Accuracy: 0.3814, Percentage:38.1373%\n",
            "Epoch [662/1500], Training Loss: 0.3786, Validation Loss: 4.5422, Validation Accuracy: 0.3882, Percentage:38.8235%\n",
            "Epoch [663/1500], Training Loss: 0.3689, Validation Loss: 4.5248, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [664/1500], Training Loss: 0.3880, Validation Loss: 4.6756, Validation Accuracy: 0.3882, Percentage:38.8235%\n",
            "Epoch [665/1500], Training Loss: 0.4225, Validation Loss: 4.6138, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [666/1500], Training Loss: 0.4441, Validation Loss: 4.7209, Validation Accuracy: 0.3882, Percentage:38.8235%\n",
            "Epoch [667/1500], Training Loss: 0.4691, Validation Loss: 4.5649, Validation Accuracy: 0.3814, Percentage:38.1373%\n",
            "Epoch [668/1500], Training Loss: 0.4456, Validation Loss: 4.3074, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [669/1500], Training Loss: 0.4080, Validation Loss: 4.4667, Validation Accuracy: 0.3833, Percentage:38.3333%\n",
            "Epoch [670/1500], Training Loss: 0.3902, Validation Loss: 4.6358, Validation Accuracy: 0.3892, Percentage:38.9216%\n",
            "Epoch [671/1500], Training Loss: 0.4100, Validation Loss: 4.3848, Validation Accuracy: 0.3892, Percentage:38.9216%\n",
            "Epoch [672/1500], Training Loss: 0.4400, Validation Loss: 4.3381, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [673/1500], Training Loss: 0.4110, Validation Loss: 4.5373, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [674/1500], Training Loss: 0.3555, Validation Loss: 4.2884, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [675/1500], Training Loss: 0.3601, Validation Loss: 4.6713, Validation Accuracy: 0.3882, Percentage:38.8235%\n",
            "Epoch [676/1500], Training Loss: 0.4089, Validation Loss: 4.5447, Validation Accuracy: 0.3814, Percentage:38.1373%\n",
            "Epoch [677/1500], Training Loss: 0.4019, Validation Loss: 4.4830, Validation Accuracy: 0.3902, Percentage:39.0196%\n",
            "Epoch [678/1500], Training Loss: 0.4425, Validation Loss: 4.5296, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [679/1500], Training Loss: 0.4003, Validation Loss: 4.4127, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [680/1500], Training Loss: 0.4417, Validation Loss: 4.3239, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [681/1500], Training Loss: 0.3942, Validation Loss: 4.5771, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [682/1500], Training Loss: 0.3646, Validation Loss: 4.4850, Validation Accuracy: 0.3892, Percentage:38.9216%\n",
            "Epoch [683/1500], Training Loss: 0.4120, Validation Loss: 4.5396, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [684/1500], Training Loss: 0.3584, Validation Loss: 4.6443, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [685/1500], Training Loss: 0.4570, Validation Loss: 4.4335, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [686/1500], Training Loss: 0.4247, Validation Loss: 4.5691, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [687/1500], Training Loss: 0.3841, Validation Loss: 4.6482, Validation Accuracy: 0.3892, Percentage:38.9216%\n",
            "Epoch [688/1500], Training Loss: 0.4139, Validation Loss: 4.5717, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [689/1500], Training Loss: 0.3269, Validation Loss: 4.8640, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [690/1500], Training Loss: 0.4394, Validation Loss: 4.3663, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [691/1500], Training Loss: 0.3439, Validation Loss: 4.5934, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [692/1500], Training Loss: 0.3380, Validation Loss: 4.4150, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [693/1500], Training Loss: 0.3300, Validation Loss: 4.7171, Validation Accuracy: 0.3765, Percentage:37.6471%\n",
            "Epoch [694/1500], Training Loss: 0.3970, Validation Loss: 4.5342, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [695/1500], Training Loss: 0.4158, Validation Loss: 4.2910, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [696/1500], Training Loss: 0.3585, Validation Loss: 4.5196, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [697/1500], Training Loss: 0.3537, Validation Loss: 4.6128, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [698/1500], Training Loss: 0.3760, Validation Loss: 4.5079, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [699/1500], Training Loss: 0.3946, Validation Loss: 4.5628, Validation Accuracy: 0.3882, Percentage:38.8235%\n",
            "Epoch [700/1500], Training Loss: 0.3897, Validation Loss: 4.5349, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [701/1500], Training Loss: 0.3804, Validation Loss: 4.3090, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [702/1500], Training Loss: 0.4339, Validation Loss: 4.6276, Validation Accuracy: 0.3735, Percentage:37.3529%\n",
            "Epoch [703/1500], Training Loss: 0.3786, Validation Loss: 4.6642, Validation Accuracy: 0.3882, Percentage:38.8235%\n",
            "Epoch [704/1500], Training Loss: 0.3596, Validation Loss: 4.8794, Validation Accuracy: 0.3843, Percentage:38.4314%\n",
            "Epoch [705/1500], Training Loss: 0.3902, Validation Loss: 4.6440, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [706/1500], Training Loss: 0.4051, Validation Loss: 4.5322, Validation Accuracy: 0.3863, Percentage:38.6275%\n",
            "Epoch [707/1500], Training Loss: 0.3669, Validation Loss: 4.5738, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [708/1500], Training Loss: 0.3545, Validation Loss: 4.8419, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [709/1500], Training Loss: 0.4068, Validation Loss: 4.8731, Validation Accuracy: 0.3892, Percentage:38.9216%\n",
            "Epoch [710/1500], Training Loss: 0.4311, Validation Loss: 4.7633, Validation Accuracy: 0.3863, Percentage:38.6275%\n",
            "Epoch [711/1500], Training Loss: 0.3358, Validation Loss: 4.8362, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [712/1500], Training Loss: 0.4108, Validation Loss: 4.8071, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [713/1500], Training Loss: 0.4289, Validation Loss: 4.6800, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [714/1500], Training Loss: 0.3367, Validation Loss: 4.6272, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [715/1500], Training Loss: 0.3675, Validation Loss: 4.8480, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [716/1500], Training Loss: 0.4311, Validation Loss: 4.8025, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [717/1500], Training Loss: 0.4073, Validation Loss: 4.8267, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [718/1500], Training Loss: 0.4380, Validation Loss: 4.5404, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [719/1500], Training Loss: 0.4268, Validation Loss: 4.4969, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [720/1500], Training Loss: 0.4755, Validation Loss: 4.4107, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [721/1500], Training Loss: 0.3214, Validation Loss: 5.0526, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [722/1500], Training Loss: 0.2884, Validation Loss: 4.8469, Validation Accuracy: 0.3912, Percentage:39.1176%\n",
            "Epoch [723/1500], Training Loss: 0.4242, Validation Loss: 4.7353, Validation Accuracy: 0.3794, Percentage:37.9412%\n",
            "Epoch [724/1500], Training Loss: 0.3257, Validation Loss: 4.8137, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [725/1500], Training Loss: 0.4265, Validation Loss: 4.3769, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [726/1500], Training Loss: 0.4505, Validation Loss: 4.5310, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [727/1500], Training Loss: 0.3707, Validation Loss: 4.7651, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [728/1500], Training Loss: 0.3412, Validation Loss: 4.6567, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [729/1500], Training Loss: 0.4398, Validation Loss: 4.7770, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [730/1500], Training Loss: 0.4334, Validation Loss: 4.5919, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [731/1500], Training Loss: 0.3027, Validation Loss: 4.5206, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [732/1500], Training Loss: 0.3744, Validation Loss: 4.4316, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [733/1500], Training Loss: 0.4110, Validation Loss: 4.4230, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [734/1500], Training Loss: 0.3559, Validation Loss: 4.5749, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [735/1500], Training Loss: 0.4264, Validation Loss: 4.6167, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [736/1500], Training Loss: 0.3642, Validation Loss: 4.7850, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [737/1500], Training Loss: 0.3866, Validation Loss: 4.4176, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [738/1500], Training Loss: 0.4328, Validation Loss: 4.4520, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [739/1500], Training Loss: 0.4050, Validation Loss: 4.4583, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [740/1500], Training Loss: 0.4613, Validation Loss: 4.5617, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [741/1500], Training Loss: 0.3671, Validation Loss: 4.3673, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [742/1500], Training Loss: 0.3794, Validation Loss: 4.4603, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [743/1500], Training Loss: 0.3776, Validation Loss: 4.6480, Validation Accuracy: 0.3804, Percentage:38.0392%\n",
            "Epoch [744/1500], Training Loss: 0.4035, Validation Loss: 4.3923, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [745/1500], Training Loss: 0.3925, Validation Loss: 4.4835, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [746/1500], Training Loss: 0.3310, Validation Loss: 4.5646, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [747/1500], Training Loss: 0.3765, Validation Loss: 4.4800, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [748/1500], Training Loss: 0.3504, Validation Loss: 4.9138, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [749/1500], Training Loss: 0.3899, Validation Loss: 4.5967, Validation Accuracy: 0.3863, Percentage:38.6275%\n",
            "Epoch [750/1500], Training Loss: 0.3995, Validation Loss: 4.4224, Validation Accuracy: 0.3882, Percentage:38.8235%\n",
            "Epoch [751/1500], Training Loss: 0.3627, Validation Loss: 4.4180, Validation Accuracy: 0.3824, Percentage:38.2353%\n",
            "Epoch [752/1500], Training Loss: 0.3598, Validation Loss: 4.5846, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [753/1500], Training Loss: 0.3824, Validation Loss: 4.2820, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [754/1500], Training Loss: 0.4395, Validation Loss: 4.3302, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [755/1500], Training Loss: 0.3844, Validation Loss: 4.3926, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [756/1500], Training Loss: 0.4080, Validation Loss: 4.6932, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [757/1500], Training Loss: 0.3588, Validation Loss: 4.2659, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [758/1500], Training Loss: 0.3729, Validation Loss: 4.8955, Validation Accuracy: 0.3892, Percentage:38.9216%\n",
            "Epoch [759/1500], Training Loss: 0.3832, Validation Loss: 4.6145, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [760/1500], Training Loss: 0.3807, Validation Loss: 4.6442, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [761/1500], Training Loss: 0.2745, Validation Loss: 4.3544, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [762/1500], Training Loss: 0.3809, Validation Loss: 4.8578, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [763/1500], Training Loss: 0.3453, Validation Loss: 4.6681, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [764/1500], Training Loss: 0.3802, Validation Loss: 4.6622, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [765/1500], Training Loss: 0.3946, Validation Loss: 4.5527, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [766/1500], Training Loss: 0.4636, Validation Loss: 4.4972, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [767/1500], Training Loss: 0.3524, Validation Loss: 4.6875, Validation Accuracy: 0.3912, Percentage:39.1176%\n",
            "Epoch [768/1500], Training Loss: 0.3825, Validation Loss: 4.8480, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [769/1500], Training Loss: 0.2689, Validation Loss: 4.7435, Validation Accuracy: 0.3775, Percentage:37.7451%\n",
            "Epoch [770/1500], Training Loss: 0.3685, Validation Loss: 4.8180, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [771/1500], Training Loss: 0.4010, Validation Loss: 4.6218, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [772/1500], Training Loss: 0.3439, Validation Loss: 4.9252, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [773/1500], Training Loss: 0.3079, Validation Loss: 4.6120, Validation Accuracy: 0.3892, Percentage:38.9216%\n",
            "Epoch [774/1500], Training Loss: 0.3470, Validation Loss: 4.7778, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [775/1500], Training Loss: 0.3368, Validation Loss: 4.8895, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [776/1500], Training Loss: 0.4127, Validation Loss: 4.9300, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [777/1500], Training Loss: 0.3251, Validation Loss: 4.8927, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [778/1500], Training Loss: 0.4232, Validation Loss: 4.6174, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [779/1500], Training Loss: 0.3896, Validation Loss: 4.6571, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [780/1500], Training Loss: 0.3713, Validation Loss: 4.5630, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [781/1500], Training Loss: 0.4051, Validation Loss: 4.6301, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [782/1500], Training Loss: 0.3913, Validation Loss: 4.7304, Validation Accuracy: 0.3902, Percentage:39.0196%\n",
            "Epoch [783/1500], Training Loss: 0.3906, Validation Loss: 4.6153, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [784/1500], Training Loss: 0.3817, Validation Loss: 4.5816, Validation Accuracy: 0.4176, Percentage:41.7647%\n",
            "Epoch [785/1500], Training Loss: 0.3083, Validation Loss: 4.8343, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [786/1500], Training Loss: 0.3081, Validation Loss: 4.9686, Validation Accuracy: 0.3755, Percentage:37.5490%\n",
            "Epoch [787/1500], Training Loss: 0.3324, Validation Loss: 4.7603, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [788/1500], Training Loss: 0.4829, Validation Loss: 4.6007, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [789/1500], Training Loss: 0.3512, Validation Loss: 4.4469, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [790/1500], Training Loss: 0.3730, Validation Loss: 4.4685, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [791/1500], Training Loss: 0.2978, Validation Loss: 4.5715, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [792/1500], Training Loss: 0.3672, Validation Loss: 4.8464, Validation Accuracy: 0.3853, Percentage:38.5294%\n",
            "Epoch [793/1500], Training Loss: 0.3544, Validation Loss: 4.6655, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [794/1500], Training Loss: 0.4047, Validation Loss: 4.7587, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [795/1500], Training Loss: 0.3213, Validation Loss: 4.7265, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [796/1500], Training Loss: 0.3630, Validation Loss: 4.7140, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [797/1500], Training Loss: 0.3499, Validation Loss: 4.8521, Validation Accuracy: 0.3765, Percentage:37.6471%\n",
            "Epoch [798/1500], Training Loss: 0.3264, Validation Loss: 4.7945, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [799/1500], Training Loss: 0.3616, Validation Loss: 4.9579, Validation Accuracy: 0.3882, Percentage:38.8235%\n",
            "Epoch [800/1500], Training Loss: 0.3513, Validation Loss: 4.7967, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [801/1500], Training Loss: 0.3779, Validation Loss: 4.7178, Validation Accuracy: 0.3853, Percentage:38.5294%\n",
            "Epoch [802/1500], Training Loss: 0.3825, Validation Loss: 4.8925, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [803/1500], Training Loss: 0.3524, Validation Loss: 4.5176, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [804/1500], Training Loss: 0.3145, Validation Loss: 4.6401, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [805/1500], Training Loss: 0.3447, Validation Loss: 4.5206, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [806/1500], Training Loss: 0.2940, Validation Loss: 4.9026, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [807/1500], Training Loss: 0.3696, Validation Loss: 4.5928, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [808/1500], Training Loss: 0.3296, Validation Loss: 4.9156, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [809/1500], Training Loss: 0.3505, Validation Loss: 4.8002, Validation Accuracy: 0.3912, Percentage:39.1176%\n",
            "Epoch [810/1500], Training Loss: 0.3340, Validation Loss: 4.6892, Validation Accuracy: 0.3912, Percentage:39.1176%\n",
            "Epoch [811/1500], Training Loss: 0.4052, Validation Loss: 4.5052, Validation Accuracy: 0.3804, Percentage:38.0392%\n",
            "Epoch [812/1500], Training Loss: 0.3563, Validation Loss: 4.6175, Validation Accuracy: 0.4176, Percentage:41.7647%\n",
            "Epoch [813/1500], Training Loss: 0.3377, Validation Loss: 4.5584, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [814/1500], Training Loss: 0.3606, Validation Loss: 4.7171, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [815/1500], Training Loss: 0.3432, Validation Loss: 4.3730, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [816/1500], Training Loss: 0.3871, Validation Loss: 4.9687, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [817/1500], Training Loss: 0.3498, Validation Loss: 4.6036, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [818/1500], Training Loss: 0.3688, Validation Loss: 4.6777, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [819/1500], Training Loss: 0.3071, Validation Loss: 4.9346, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [820/1500], Training Loss: 0.3469, Validation Loss: 4.5081, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [821/1500], Training Loss: 0.3380, Validation Loss: 4.8386, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [822/1500], Training Loss: 0.3745, Validation Loss: 4.7311, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [823/1500], Training Loss: 0.3441, Validation Loss: 4.7366, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [824/1500], Training Loss: 0.3801, Validation Loss: 5.1667, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [825/1500], Training Loss: 0.4275, Validation Loss: 4.4847, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [826/1500], Training Loss: 0.3232, Validation Loss: 4.8761, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [827/1500], Training Loss: 0.3371, Validation Loss: 4.6086, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [828/1500], Training Loss: 0.3799, Validation Loss: 4.5799, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [829/1500], Training Loss: 0.3391, Validation Loss: 4.9242, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [830/1500], Training Loss: 0.3492, Validation Loss: 4.5115, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [831/1500], Training Loss: 0.3363, Validation Loss: 4.8093, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [832/1500], Training Loss: 0.4171, Validation Loss: 4.6803, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [833/1500], Training Loss: 0.3644, Validation Loss: 4.8574, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [834/1500], Training Loss: 0.4140, Validation Loss: 4.6570, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [835/1500], Training Loss: 0.3482, Validation Loss: 4.8663, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [836/1500], Training Loss: 0.3114, Validation Loss: 4.7373, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [837/1500], Training Loss: 0.3311, Validation Loss: 4.7021, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [838/1500], Training Loss: 0.3564, Validation Loss: 4.6377, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [839/1500], Training Loss: 0.3501, Validation Loss: 4.5558, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [840/1500], Training Loss: 0.3648, Validation Loss: 4.7432, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [841/1500], Training Loss: 0.3233, Validation Loss: 4.8550, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [842/1500], Training Loss: 0.2788, Validation Loss: 5.0586, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [843/1500], Training Loss: 0.3301, Validation Loss: 4.8165, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [844/1500], Training Loss: 0.3448, Validation Loss: 4.7711, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [845/1500], Training Loss: 0.3677, Validation Loss: 4.8224, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [846/1500], Training Loss: 0.4024, Validation Loss: 4.5856, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [847/1500], Training Loss: 0.3230, Validation Loss: 4.6124, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [848/1500], Training Loss: 0.3818, Validation Loss: 4.6040, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [849/1500], Training Loss: 0.3535, Validation Loss: 4.7639, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [850/1500], Training Loss: 0.3498, Validation Loss: 4.7912, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [851/1500], Training Loss: 0.3201, Validation Loss: 5.0051, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [852/1500], Training Loss: 0.3299, Validation Loss: 4.7603, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [853/1500], Training Loss: 0.3508, Validation Loss: 4.8898, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [854/1500], Training Loss: 0.3334, Validation Loss: 4.7670, Validation Accuracy: 0.4225, Percentage:42.2549%\n",
            "Epoch [855/1500], Training Loss: 0.3655, Validation Loss: 4.8210, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [856/1500], Training Loss: 0.3206, Validation Loss: 4.6757, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [857/1500], Training Loss: 0.3359, Validation Loss: 5.2646, Validation Accuracy: 0.3686, Percentage:36.8627%\n",
            "Epoch [858/1500], Training Loss: 0.3446, Validation Loss: 5.0653, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [859/1500], Training Loss: 0.3018, Validation Loss: 4.7686, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [860/1500], Training Loss: 0.3566, Validation Loss: 4.9232, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [861/1500], Training Loss: 0.3338, Validation Loss: 4.5589, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [862/1500], Training Loss: 0.3575, Validation Loss: 4.5362, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [863/1500], Training Loss: 0.3795, Validation Loss: 4.6715, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [864/1500], Training Loss: 0.2835, Validation Loss: 4.6551, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [865/1500], Training Loss: 0.3538, Validation Loss: 4.7761, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [866/1500], Training Loss: 0.3233, Validation Loss: 5.1192, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [867/1500], Training Loss: 0.3138, Validation Loss: 4.8058, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [868/1500], Training Loss: 0.3259, Validation Loss: 4.8877, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [869/1500], Training Loss: 0.3697, Validation Loss: 4.8047, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [870/1500], Training Loss: 0.3650, Validation Loss: 4.8416, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [871/1500], Training Loss: 0.2955, Validation Loss: 4.8530, Validation Accuracy: 0.3882, Percentage:38.8235%\n",
            "Epoch [872/1500], Training Loss: 0.3003, Validation Loss: 4.9202, Validation Accuracy: 0.3775, Percentage:37.7451%\n",
            "Epoch [873/1500], Training Loss: 0.2997, Validation Loss: 4.8898, Validation Accuracy: 0.4176, Percentage:41.7647%\n",
            "Epoch [874/1500], Training Loss: 0.3551, Validation Loss: 4.5318, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [875/1500], Training Loss: 0.3605, Validation Loss: 4.7920, Validation Accuracy: 0.3814, Percentage:38.1373%\n",
            "Epoch [876/1500], Training Loss: 0.2995, Validation Loss: 4.8963, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [877/1500], Training Loss: 0.4133, Validation Loss: 4.4852, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [878/1500], Training Loss: 0.2779, Validation Loss: 5.0385, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [879/1500], Training Loss: 0.3044, Validation Loss: 4.8852, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [880/1500], Training Loss: 0.3396, Validation Loss: 5.0913, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [881/1500], Training Loss: 0.3645, Validation Loss: 5.0091, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [882/1500], Training Loss: 0.2934, Validation Loss: 5.0183, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [883/1500], Training Loss: 0.3791, Validation Loss: 4.8174, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [884/1500], Training Loss: 0.3757, Validation Loss: 4.5823, Validation Accuracy: 0.3853, Percentage:38.5294%\n",
            "Epoch [885/1500], Training Loss: 0.2910, Validation Loss: 5.2070, Validation Accuracy: 0.3824, Percentage:38.2353%\n",
            "Epoch [886/1500], Training Loss: 0.3288, Validation Loss: 5.3436, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [887/1500], Training Loss: 0.3469, Validation Loss: 4.9635, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [888/1500], Training Loss: 0.3381, Validation Loss: 4.8688, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [889/1500], Training Loss: 0.3008, Validation Loss: 4.9958, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [890/1500], Training Loss: 0.3401, Validation Loss: 4.8872, Validation Accuracy: 0.3912, Percentage:39.1176%\n",
            "Epoch [891/1500], Training Loss: 0.3370, Validation Loss: 4.8562, Validation Accuracy: 0.3853, Percentage:38.5294%\n",
            "Epoch [892/1500], Training Loss: 0.3459, Validation Loss: 4.9977, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [893/1500], Training Loss: 0.3164, Validation Loss: 5.0242, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [894/1500], Training Loss: 0.3091, Validation Loss: 4.8747, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [895/1500], Training Loss: 0.4274, Validation Loss: 4.5053, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [896/1500], Training Loss: 0.3098, Validation Loss: 4.8070, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [897/1500], Training Loss: 0.3106, Validation Loss: 4.8123, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [898/1500], Training Loss: 0.3309, Validation Loss: 4.7181, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [899/1500], Training Loss: 0.3365, Validation Loss: 4.8196, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [900/1500], Training Loss: 0.3502, Validation Loss: 4.9555, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [901/1500], Training Loss: 0.2936, Validation Loss: 4.9155, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [902/1500], Training Loss: 0.3702, Validation Loss: 5.2265, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [903/1500], Training Loss: 0.3749, Validation Loss: 4.6792, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [904/1500], Training Loss: 0.2967, Validation Loss: 4.5625, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [905/1500], Training Loss: 0.3296, Validation Loss: 4.7711, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [906/1500], Training Loss: 0.4218, Validation Loss: 4.4746, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [907/1500], Training Loss: 0.2833, Validation Loss: 4.5567, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [908/1500], Training Loss: 0.3235, Validation Loss: 4.8304, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [909/1500], Training Loss: 0.3031, Validation Loss: 4.7904, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [910/1500], Training Loss: 0.2906, Validation Loss: 4.9462, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [911/1500], Training Loss: 0.3672, Validation Loss: 4.9187, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [912/1500], Training Loss: 0.3304, Validation Loss: 4.8945, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [913/1500], Training Loss: 0.2994, Validation Loss: 4.8576, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [914/1500], Training Loss: 0.3200, Validation Loss: 4.9661, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [915/1500], Training Loss: 0.3068, Validation Loss: 4.6881, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [916/1500], Training Loss: 0.3138, Validation Loss: 4.9617, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [917/1500], Training Loss: 0.3249, Validation Loss: 4.9594, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [918/1500], Training Loss: 0.3300, Validation Loss: 4.9766, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [919/1500], Training Loss: 0.2983, Validation Loss: 4.7008, Validation Accuracy: 0.4176, Percentage:41.7647%\n",
            "Epoch [920/1500], Training Loss: 0.3305, Validation Loss: 4.8241, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [921/1500], Training Loss: 0.3450, Validation Loss: 4.7553, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [922/1500], Training Loss: 0.3864, Validation Loss: 4.8505, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [923/1500], Training Loss: 0.3456, Validation Loss: 4.9467, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [924/1500], Training Loss: 0.3461, Validation Loss: 5.2283, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [925/1500], Training Loss: 0.3354, Validation Loss: 4.7371, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [926/1500], Training Loss: 0.3830, Validation Loss: 4.7007, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [927/1500], Training Loss: 0.3595, Validation Loss: 4.7242, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [928/1500], Training Loss: 0.3649, Validation Loss: 4.5938, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [929/1500], Training Loss: 0.3044, Validation Loss: 4.6511, Validation Accuracy: 0.4176, Percentage:41.7647%\n",
            "Epoch [930/1500], Training Loss: 0.2908, Validation Loss: 4.7621, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [931/1500], Training Loss: 0.3785, Validation Loss: 4.8570, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [932/1500], Training Loss: 0.3043, Validation Loss: 4.7924, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [933/1500], Training Loss: 0.3257, Validation Loss: 4.4888, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [934/1500], Training Loss: 0.3016, Validation Loss: 4.7576, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [935/1500], Training Loss: 0.3233, Validation Loss: 4.8225, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [936/1500], Training Loss: 0.2953, Validation Loss: 4.6167, Validation Accuracy: 0.4265, Percentage:42.6471%\n",
            "Epoch [937/1500], Training Loss: 0.3575, Validation Loss: 4.8207, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [938/1500], Training Loss: 0.3563, Validation Loss: 4.9396, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [939/1500], Training Loss: 0.3379, Validation Loss: 4.8997, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [940/1500], Training Loss: 0.3657, Validation Loss: 4.7312, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [941/1500], Training Loss: 0.2546, Validation Loss: 4.8227, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [942/1500], Training Loss: 0.3503, Validation Loss: 4.9926, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [943/1500], Training Loss: 0.3317, Validation Loss: 4.9609, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [944/1500], Training Loss: 0.3767, Validation Loss: 4.5474, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [945/1500], Training Loss: 0.3844, Validation Loss: 4.6982, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [946/1500], Training Loss: 0.2973, Validation Loss: 4.6590, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [947/1500], Training Loss: 0.3680, Validation Loss: 4.8583, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [948/1500], Training Loss: 0.2864, Validation Loss: 5.0575, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [949/1500], Training Loss: 0.3531, Validation Loss: 4.8637, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [950/1500], Training Loss: 0.2847, Validation Loss: 5.2157, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [951/1500], Training Loss: 0.3595, Validation Loss: 4.5481, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [952/1500], Training Loss: 0.2798, Validation Loss: 4.9625, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [953/1500], Training Loss: 0.3560, Validation Loss: 4.7403, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [954/1500], Training Loss: 0.3644, Validation Loss: 4.9682, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [955/1500], Training Loss: 0.3261, Validation Loss: 5.2324, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [956/1500], Training Loss: 0.3469, Validation Loss: 4.9878, Validation Accuracy: 0.3745, Percentage:37.4510%\n",
            "Epoch [957/1500], Training Loss: 0.2859, Validation Loss: 4.7260, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [958/1500], Training Loss: 0.3262, Validation Loss: 5.1125, Validation Accuracy: 0.3912, Percentage:39.1176%\n",
            "Epoch [959/1500], Training Loss: 0.3442, Validation Loss: 4.5936, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [960/1500], Training Loss: 0.3042, Validation Loss: 4.9957, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [961/1500], Training Loss: 0.3077, Validation Loss: 5.2986, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [962/1500], Training Loss: 0.3106, Validation Loss: 4.7497, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [963/1500], Training Loss: 0.3494, Validation Loss: 4.9264, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [964/1500], Training Loss: 0.3149, Validation Loss: 4.9490, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [965/1500], Training Loss: 0.3497, Validation Loss: 4.6827, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [966/1500], Training Loss: 0.2792, Validation Loss: 5.5180, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [967/1500], Training Loss: 0.2646, Validation Loss: 4.9065, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [968/1500], Training Loss: 0.2561, Validation Loss: 5.2903, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [969/1500], Training Loss: 0.2761, Validation Loss: 5.1202, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [970/1500], Training Loss: 0.3530, Validation Loss: 5.0465, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [971/1500], Training Loss: 0.3139, Validation Loss: 4.6856, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [972/1500], Training Loss: 0.3063, Validation Loss: 4.9765, Validation Accuracy: 0.4176, Percentage:41.7647%\n",
            "Epoch [973/1500], Training Loss: 0.3194, Validation Loss: 4.6171, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [974/1500], Training Loss: 0.2937, Validation Loss: 5.0500, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [975/1500], Training Loss: 0.2992, Validation Loss: 5.0333, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [976/1500], Training Loss: 0.3343, Validation Loss: 5.3251, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [977/1500], Training Loss: 0.3212, Validation Loss: 4.5790, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [978/1500], Training Loss: 0.3356, Validation Loss: 4.5738, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [979/1500], Training Loss: 0.2563, Validation Loss: 4.7386, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [980/1500], Training Loss: 0.2313, Validation Loss: 5.1071, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [981/1500], Training Loss: 0.3044, Validation Loss: 5.0224, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [982/1500], Training Loss: 0.3267, Validation Loss: 4.8507, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [983/1500], Training Loss: 0.3168, Validation Loss: 5.0385, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [984/1500], Training Loss: 0.3148, Validation Loss: 4.8485, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [985/1500], Training Loss: 0.2909, Validation Loss: 4.9829, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [986/1500], Training Loss: 0.3218, Validation Loss: 4.8631, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [987/1500], Training Loss: 0.3430, Validation Loss: 4.8816, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [988/1500], Training Loss: 0.3656, Validation Loss: 4.8368, Validation Accuracy: 0.3863, Percentage:38.6275%\n",
            "Epoch [989/1500], Training Loss: 0.3550, Validation Loss: 4.8487, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [990/1500], Training Loss: 0.2935, Validation Loss: 4.9115, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [991/1500], Training Loss: 0.3045, Validation Loss: 4.9581, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [992/1500], Training Loss: 0.2697, Validation Loss: 5.2011, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [993/1500], Training Loss: 0.3472, Validation Loss: 5.3025, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [994/1500], Training Loss: 0.2622, Validation Loss: 4.9144, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [995/1500], Training Loss: 0.2881, Validation Loss: 5.0461, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [996/1500], Training Loss: 0.3643, Validation Loss: 5.3491, Validation Accuracy: 0.3902, Percentage:39.0196%\n",
            "Epoch [997/1500], Training Loss: 0.2857, Validation Loss: 4.8761, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [998/1500], Training Loss: 0.3161, Validation Loss: 5.1385, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [999/1500], Training Loss: 0.3836, Validation Loss: 4.8290, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [1000/1500], Training Loss: 0.2668, Validation Loss: 5.0045, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [1001/1500], Training Loss: 0.3016, Validation Loss: 4.9568, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [1002/1500], Training Loss: 0.2855, Validation Loss: 5.0325, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [1003/1500], Training Loss: 0.3333, Validation Loss: 4.9713, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [1004/1500], Training Loss: 0.3011, Validation Loss: 5.3779, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [1005/1500], Training Loss: 0.3027, Validation Loss: 5.0515, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [1006/1500], Training Loss: 0.3271, Validation Loss: 5.0011, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [1007/1500], Training Loss: 0.2848, Validation Loss: 5.0485, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [1008/1500], Training Loss: 0.3006, Validation Loss: 5.2897, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [1009/1500], Training Loss: 0.3308, Validation Loss: 5.1078, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [1010/1500], Training Loss: 0.2736, Validation Loss: 4.9180, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [1011/1500], Training Loss: 0.2980, Validation Loss: 4.7439, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [1012/1500], Training Loss: 0.2902, Validation Loss: 5.4275, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [1013/1500], Training Loss: 0.2761, Validation Loss: 5.1610, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [1014/1500], Training Loss: 0.2715, Validation Loss: 5.4181, Validation Accuracy: 0.4176, Percentage:41.7647%\n",
            "Epoch [1015/1500], Training Loss: 0.3172, Validation Loss: 5.4445, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [1016/1500], Training Loss: 0.3047, Validation Loss: 5.1216, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [1017/1500], Training Loss: 0.3216, Validation Loss: 4.8819, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [1018/1500], Training Loss: 0.3175, Validation Loss: 4.9730, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [1019/1500], Training Loss: 0.2885, Validation Loss: 5.0667, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [1020/1500], Training Loss: 0.3333, Validation Loss: 5.1685, Validation Accuracy: 0.3745, Percentage:37.4510%\n",
            "Epoch [1021/1500], Training Loss: 0.3725, Validation Loss: 4.7466, Validation Accuracy: 0.3863, Percentage:38.6275%\n",
            "Epoch [1022/1500], Training Loss: 0.3491, Validation Loss: 4.7489, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [1023/1500], Training Loss: 0.3739, Validation Loss: 5.0191, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [1024/1500], Training Loss: 0.2752, Validation Loss: 4.9900, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [1025/1500], Training Loss: 0.3423, Validation Loss: 4.9422, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [1026/1500], Training Loss: 0.2721, Validation Loss: 4.8145, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [1027/1500], Training Loss: 0.3083, Validation Loss: 4.8235, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [1028/1500], Training Loss: 0.2414, Validation Loss: 5.2408, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [1029/1500], Training Loss: 0.3355, Validation Loss: 5.2737, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [1030/1500], Training Loss: 0.3206, Validation Loss: 5.0453, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [1031/1500], Training Loss: 0.2636, Validation Loss: 5.2675, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [1032/1500], Training Loss: 0.3466, Validation Loss: 4.9096, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [1033/1500], Training Loss: 0.3228, Validation Loss: 4.8645, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [1034/1500], Training Loss: 0.2728, Validation Loss: 4.9748, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [1035/1500], Training Loss: 0.2583, Validation Loss: 5.0885, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [1036/1500], Training Loss: 0.2939, Validation Loss: 5.0741, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [1037/1500], Training Loss: 0.2424, Validation Loss: 5.2596, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [1038/1500], Training Loss: 0.3406, Validation Loss: 5.1641, Validation Accuracy: 0.3892, Percentage:38.9216%\n",
            "Epoch [1039/1500], Training Loss: 0.3188, Validation Loss: 4.7152, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [1040/1500], Training Loss: 0.3235, Validation Loss: 5.0876, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [1041/1500], Training Loss: 0.2981, Validation Loss: 4.8999, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [1042/1500], Training Loss: 0.3030, Validation Loss: 5.1727, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [1043/1500], Training Loss: 0.2791, Validation Loss: 4.7806, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [1044/1500], Training Loss: 0.3016, Validation Loss: 5.2359, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [1045/1500], Training Loss: 0.2666, Validation Loss: 5.4959, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [1046/1500], Training Loss: 0.3003, Validation Loss: 5.1838, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [1047/1500], Training Loss: 0.2768, Validation Loss: 5.0097, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [1048/1500], Training Loss: 0.2542, Validation Loss: 5.4238, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [1049/1500], Training Loss: 0.2868, Validation Loss: 5.0421, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [1050/1500], Training Loss: 0.3163, Validation Loss: 4.9947, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [1051/1500], Training Loss: 0.2739, Validation Loss: 4.9651, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [1052/1500], Training Loss: 0.2877, Validation Loss: 5.2962, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [1053/1500], Training Loss: 0.2877, Validation Loss: 4.9869, Validation Accuracy: 0.4225, Percentage:42.2549%\n",
            "Epoch [1054/1500], Training Loss: 0.2776, Validation Loss: 4.8710, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [1055/1500], Training Loss: 0.2659, Validation Loss: 5.1543, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [1056/1500], Training Loss: 0.3789, Validation Loss: 5.0421, Validation Accuracy: 0.3892, Percentage:38.9216%\n",
            "Epoch [1057/1500], Training Loss: 0.2944, Validation Loss: 4.8736, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [1058/1500], Training Loss: 0.2962, Validation Loss: 5.1030, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [1059/1500], Training Loss: 0.3199, Validation Loss: 4.8954, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [1060/1500], Training Loss: 0.3108, Validation Loss: 5.1932, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [1061/1500], Training Loss: 0.3091, Validation Loss: 5.2413, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [1062/1500], Training Loss: 0.3558, Validation Loss: 4.9749, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [1063/1500], Training Loss: 0.3204, Validation Loss: 5.1899, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [1064/1500], Training Loss: 0.2660, Validation Loss: 5.0453, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [1065/1500], Training Loss: 0.2948, Validation Loss: 5.3561, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [1066/1500], Training Loss: 0.2952, Validation Loss: 5.0668, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [1067/1500], Training Loss: 0.2502, Validation Loss: 5.6435, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [1068/1500], Training Loss: 0.2572, Validation Loss: 5.4409, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [1069/1500], Training Loss: 0.3211, Validation Loss: 5.2643, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [1070/1500], Training Loss: 0.3092, Validation Loss: 4.7605, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [1071/1500], Training Loss: 0.3569, Validation Loss: 4.7172, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [1072/1500], Training Loss: 0.2393, Validation Loss: 4.8409, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [1073/1500], Training Loss: 0.3282, Validation Loss: 5.0365, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [1074/1500], Training Loss: 0.3256, Validation Loss: 4.8750, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [1075/1500], Training Loss: 0.2806, Validation Loss: 5.0571, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [1076/1500], Training Loss: 0.3202, Validation Loss: 4.9586, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [1077/1500], Training Loss: 0.3170, Validation Loss: 5.1131, Validation Accuracy: 0.3706, Percentage:37.0588%\n",
            "Epoch [1078/1500], Training Loss: 0.3180, Validation Loss: 4.7715, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [1079/1500], Training Loss: 0.3064, Validation Loss: 5.5003, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [1080/1500], Training Loss: 0.3007, Validation Loss: 4.9459, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [1081/1500], Training Loss: 0.2554, Validation Loss: 5.0908, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [1082/1500], Training Loss: 0.2992, Validation Loss: 5.1949, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [1083/1500], Training Loss: 0.3309, Validation Loss: 4.6570, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [1084/1500], Training Loss: 0.3071, Validation Loss: 4.9349, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [1085/1500], Training Loss: 0.3147, Validation Loss: 5.3833, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [1086/1500], Training Loss: 0.2490, Validation Loss: 5.1973, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [1087/1500], Training Loss: 0.2868, Validation Loss: 5.1427, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [1088/1500], Training Loss: 0.2983, Validation Loss: 4.9433, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [1089/1500], Training Loss: 0.2697, Validation Loss: 5.2959, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [1090/1500], Training Loss: 0.3024, Validation Loss: 5.1231, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [1091/1500], Training Loss: 0.2877, Validation Loss: 5.0174, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [1092/1500], Training Loss: 0.2334, Validation Loss: 5.3175, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [1093/1500], Training Loss: 0.2796, Validation Loss: 5.0445, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [1094/1500], Training Loss: 0.3096, Validation Loss: 5.1266, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [1095/1500], Training Loss: 0.2962, Validation Loss: 5.1501, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [1096/1500], Training Loss: 0.2981, Validation Loss: 4.9054, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [1097/1500], Training Loss: 0.3251, Validation Loss: 4.9967, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [1098/1500], Training Loss: 0.3136, Validation Loss: 4.9726, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [1099/1500], Training Loss: 0.2520, Validation Loss: 4.9718, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [1100/1500], Training Loss: 0.2863, Validation Loss: 5.1504, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [1101/1500], Training Loss: 0.3383, Validation Loss: 4.7958, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [1102/1500], Training Loss: 0.2456, Validation Loss: 5.0602, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [1103/1500], Training Loss: 0.3143, Validation Loss: 4.9467, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [1104/1500], Training Loss: 0.2765, Validation Loss: 4.8788, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [1105/1500], Training Loss: 0.3312, Validation Loss: 5.0501, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [1106/1500], Training Loss: 0.2870, Validation Loss: 5.0843, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [1107/1500], Training Loss: 0.3583, Validation Loss: 5.1114, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [1108/1500], Training Loss: 0.2747, Validation Loss: 5.1944, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [1109/1500], Training Loss: 0.2585, Validation Loss: 4.9411, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [1110/1500], Training Loss: 0.3245, Validation Loss: 4.8978, Validation Accuracy: 0.3853, Percentage:38.5294%\n",
            "Epoch [1111/1500], Training Loss: 0.2845, Validation Loss: 4.7761, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [1112/1500], Training Loss: 0.3140, Validation Loss: 5.2828, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [1113/1500], Training Loss: 0.3107, Validation Loss: 5.0637, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [1114/1500], Training Loss: 0.2835, Validation Loss: 5.0584, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [1115/1500], Training Loss: 0.2735, Validation Loss: 4.9500, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [1116/1500], Training Loss: 0.2660, Validation Loss: 5.0165, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [1117/1500], Training Loss: 0.3390, Validation Loss: 5.1324, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [1118/1500], Training Loss: 0.3316, Validation Loss: 4.8145, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [1119/1500], Training Loss: 0.2908, Validation Loss: 4.9958, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [1120/1500], Training Loss: 0.3378, Validation Loss: 4.8966, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [1121/1500], Training Loss: 0.2596, Validation Loss: 4.9837, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [1122/1500], Training Loss: 0.2824, Validation Loss: 5.0128, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [1123/1500], Training Loss: 0.3563, Validation Loss: 4.9770, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [1124/1500], Training Loss: 0.2771, Validation Loss: 5.5476, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [1125/1500], Training Loss: 0.3175, Validation Loss: 4.8086, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [1126/1500], Training Loss: 0.2916, Validation Loss: 5.1624, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [1127/1500], Training Loss: 0.2671, Validation Loss: 5.0055, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [1128/1500], Training Loss: 0.2455, Validation Loss: 4.9857, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [1129/1500], Training Loss: 0.2214, Validation Loss: 5.4926, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [1130/1500], Training Loss: 0.2718, Validation Loss: 5.0531, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [1131/1500], Training Loss: 0.3380, Validation Loss: 4.9215, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [1132/1500], Training Loss: 0.2776, Validation Loss: 5.0724, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [1133/1500], Training Loss: 0.2260, Validation Loss: 5.3472, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [1134/1500], Training Loss: 0.2924, Validation Loss: 5.0227, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [1135/1500], Training Loss: 0.2683, Validation Loss: 5.0158, Validation Accuracy: 0.4284, Percentage:42.8431%\n",
            "Epoch [1136/1500], Training Loss: 0.2718, Validation Loss: 5.0879, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [1137/1500], Training Loss: 0.3743, Validation Loss: 4.8395, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [1138/1500], Training Loss: 0.2421, Validation Loss: 5.0059, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [1139/1500], Training Loss: 0.3542, Validation Loss: 4.9560, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [1140/1500], Training Loss: 0.3321, Validation Loss: 5.1464, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [1141/1500], Training Loss: 0.2625, Validation Loss: 4.8541, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [1142/1500], Training Loss: 0.2330, Validation Loss: 5.2101, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [1143/1500], Training Loss: 0.3228, Validation Loss: 4.9231, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [1144/1500], Training Loss: 0.3309, Validation Loss: 5.0249, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [1145/1500], Training Loss: 0.3035, Validation Loss: 5.1366, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [1146/1500], Training Loss: 0.3051, Validation Loss: 5.3015, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [1147/1500], Training Loss: 0.3219, Validation Loss: 5.0214, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [1148/1500], Training Loss: 0.2567, Validation Loss: 5.0058, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [1149/1500], Training Loss: 0.3096, Validation Loss: 5.0737, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [1150/1500], Training Loss: 0.3024, Validation Loss: 5.0610, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [1151/1500], Training Loss: 0.2893, Validation Loss: 5.1927, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [1152/1500], Training Loss: 0.2915, Validation Loss: 5.1606, Validation Accuracy: 0.3814, Percentage:38.1373%\n",
            "Epoch [1153/1500], Training Loss: 0.2682, Validation Loss: 5.4256, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [1154/1500], Training Loss: 0.2796, Validation Loss: 5.5000, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [1155/1500], Training Loss: 0.2913, Validation Loss: 5.1128, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [1156/1500], Training Loss: 0.3132, Validation Loss: 4.9090, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [1157/1500], Training Loss: 0.3275, Validation Loss: 5.3047, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [1158/1500], Training Loss: 0.2435, Validation Loss: 5.0114, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [1159/1500], Training Loss: 0.2829, Validation Loss: 4.8151, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [1160/1500], Training Loss: 0.2480, Validation Loss: 4.9703, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [1161/1500], Training Loss: 0.2836, Validation Loss: 5.1764, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [1162/1500], Training Loss: 0.2961, Validation Loss: 5.0690, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [1163/1500], Training Loss: 0.3081, Validation Loss: 5.1622, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [1164/1500], Training Loss: 0.3396, Validation Loss: 5.0774, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [1165/1500], Training Loss: 0.2596, Validation Loss: 5.2444, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [1166/1500], Training Loss: 0.2286, Validation Loss: 5.1103, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [1167/1500], Training Loss: 0.2563, Validation Loss: 5.1527, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [1168/1500], Training Loss: 0.1952, Validation Loss: 6.0079, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [1169/1500], Training Loss: 0.2901, Validation Loss: 5.3085, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [1170/1500], Training Loss: 0.2388, Validation Loss: 5.1863, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [1171/1500], Training Loss: 0.2635, Validation Loss: 5.2713, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [1172/1500], Training Loss: 0.2566, Validation Loss: 5.2114, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [1173/1500], Training Loss: 0.2345, Validation Loss: 5.2192, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [1174/1500], Training Loss: 0.2251, Validation Loss: 5.1732, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [1175/1500], Training Loss: 0.2447, Validation Loss: 5.3950, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [1176/1500], Training Loss: 0.3055, Validation Loss: 5.4935, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [1177/1500], Training Loss: 0.2531, Validation Loss: 5.2951, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [1178/1500], Training Loss: 0.3579, Validation Loss: 4.9488, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [1179/1500], Training Loss: 0.2807, Validation Loss: 5.2966, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [1180/1500], Training Loss: 0.2810, Validation Loss: 5.0482, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [1181/1500], Training Loss: 0.3326, Validation Loss: 5.0015, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [1182/1500], Training Loss: 0.2973, Validation Loss: 5.1863, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [1183/1500], Training Loss: 0.2341, Validation Loss: 5.1117, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [1184/1500], Training Loss: 0.2970, Validation Loss: 5.0466, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [1185/1500], Training Loss: 0.3242, Validation Loss: 5.3878, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [1186/1500], Training Loss: 0.2310, Validation Loss: 5.0079, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [1187/1500], Training Loss: 0.3010, Validation Loss: 5.0481, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [1188/1500], Training Loss: 0.2967, Validation Loss: 5.0205, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [1189/1500], Training Loss: 0.3046, Validation Loss: 5.1725, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [1190/1500], Training Loss: 0.2653, Validation Loss: 4.9145, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [1191/1500], Training Loss: 0.2582, Validation Loss: 5.2151, Validation Accuracy: 0.4225, Percentage:42.2549%\n",
            "Epoch [1192/1500], Training Loss: 0.3228, Validation Loss: 4.8861, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [1193/1500], Training Loss: 0.3813, Validation Loss: 5.0236, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [1194/1500], Training Loss: 0.3013, Validation Loss: 4.8022, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [1195/1500], Training Loss: 0.2274, Validation Loss: 5.0592, Validation Accuracy: 0.4206, Percentage:42.0588%\n",
            "Epoch [1196/1500], Training Loss: 0.3103, Validation Loss: 5.2943, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [1197/1500], Training Loss: 0.2599, Validation Loss: 5.1356, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [1198/1500], Training Loss: 0.2677, Validation Loss: 5.0872, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [1199/1500], Training Loss: 0.3120, Validation Loss: 5.5206, Validation Accuracy: 0.3824, Percentage:38.2353%\n",
            "Epoch [1200/1500], Training Loss: 0.2340, Validation Loss: 5.1921, Validation Accuracy: 0.4176, Percentage:41.7647%\n",
            "Epoch [1201/1500], Training Loss: 0.2536, Validation Loss: 5.1630, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [1202/1500], Training Loss: 0.3023, Validation Loss: 5.3984, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [1203/1500], Training Loss: 0.3231, Validation Loss: 4.8286, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [1204/1500], Training Loss: 0.2624, Validation Loss: 5.3830, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [1205/1500], Training Loss: 0.2507, Validation Loss: 5.1564, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [1206/1500], Training Loss: 0.2693, Validation Loss: 5.2875, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [1207/1500], Training Loss: 0.2606, Validation Loss: 5.3951, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [1208/1500], Training Loss: 0.2531, Validation Loss: 5.0938, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [1209/1500], Training Loss: 0.2576, Validation Loss: 5.1549, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [1210/1500], Training Loss: 0.2795, Validation Loss: 5.2405, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [1211/1500], Training Loss: 0.2790, Validation Loss: 4.9922, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [1212/1500], Training Loss: 0.2720, Validation Loss: 5.2040, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [1213/1500], Training Loss: 0.2600, Validation Loss: 5.2869, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [1214/1500], Training Loss: 0.2644, Validation Loss: 5.4017, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [1215/1500], Training Loss: 0.2934, Validation Loss: 5.3177, Validation Accuracy: 0.3882, Percentage:38.8235%\n",
            "Epoch [1216/1500], Training Loss: 0.2628, Validation Loss: 4.9689, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [1217/1500], Training Loss: 0.2610, Validation Loss: 4.8630, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [1218/1500], Training Loss: 0.2474, Validation Loss: 5.3529, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [1219/1500], Training Loss: 0.2839, Validation Loss: 4.9649, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [1220/1500], Training Loss: 0.2588, Validation Loss: 5.1090, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [1221/1500], Training Loss: 0.2638, Validation Loss: 5.2677, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [1222/1500], Training Loss: 0.2902, Validation Loss: 5.0396, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [1223/1500], Training Loss: 0.2524, Validation Loss: 5.1588, Validation Accuracy: 0.3892, Percentage:38.9216%\n",
            "Epoch [1224/1500], Training Loss: 0.2821, Validation Loss: 5.3092, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [1225/1500], Training Loss: 0.2338, Validation Loss: 5.3266, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [1226/1500], Training Loss: 0.3142, Validation Loss: 5.1798, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [1227/1500], Training Loss: 0.2829, Validation Loss: 5.1700, Validation Accuracy: 0.3912, Percentage:39.1176%\n",
            "Epoch [1228/1500], Training Loss: 0.3194, Validation Loss: 5.6609, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [1229/1500], Training Loss: 0.2254, Validation Loss: 5.0149, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [1230/1500], Training Loss: 0.3217, Validation Loss: 4.8974, Validation Accuracy: 0.4284, Percentage:42.8431%\n",
            "Epoch [1231/1500], Training Loss: 0.3094, Validation Loss: 5.0228, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [1232/1500], Training Loss: 0.2549, Validation Loss: 5.1353, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [1233/1500], Training Loss: 0.2399, Validation Loss: 5.4740, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [1234/1500], Training Loss: 0.2583, Validation Loss: 5.0993, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [1235/1500], Training Loss: 0.2294, Validation Loss: 5.5468, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [1236/1500], Training Loss: 0.2419, Validation Loss: 5.5245, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [1237/1500], Training Loss: 0.2486, Validation Loss: 5.5509, Validation Accuracy: 0.3804, Percentage:38.0392%\n",
            "Epoch [1238/1500], Training Loss: 0.2740, Validation Loss: 5.4522, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [1239/1500], Training Loss: 0.2797, Validation Loss: 5.4627, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [1240/1500], Training Loss: 0.3040, Validation Loss: 5.0544, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [1241/1500], Training Loss: 0.3375, Validation Loss: 5.1260, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [1242/1500], Training Loss: 0.3088, Validation Loss: 5.0283, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [1243/1500], Training Loss: 0.2963, Validation Loss: 5.2407, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [1244/1500], Training Loss: 0.2692, Validation Loss: 4.8481, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [1245/1500], Training Loss: 0.2631, Validation Loss: 5.5606, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [1246/1500], Training Loss: 0.3248, Validation Loss: 5.4749, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [1247/1500], Training Loss: 0.2743, Validation Loss: 5.6930, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [1248/1500], Training Loss: 0.2703, Validation Loss: 5.3638, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [1249/1500], Training Loss: 0.2677, Validation Loss: 5.2779, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [1250/1500], Training Loss: 0.2591, Validation Loss: 5.0601, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [1251/1500], Training Loss: 0.2968, Validation Loss: 4.9071, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [1252/1500], Training Loss: 0.3065, Validation Loss: 4.9654, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [1253/1500], Training Loss: 0.2895, Validation Loss: 4.9764, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [1254/1500], Training Loss: 0.2598, Validation Loss: 5.2823, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [1255/1500], Training Loss: 0.2537, Validation Loss: 5.4165, Validation Accuracy: 0.4265, Percentage:42.6471%\n",
            "Epoch [1256/1500], Training Loss: 0.2447, Validation Loss: 5.1568, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [1257/1500], Training Loss: 0.2897, Validation Loss: 5.3841, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [1258/1500], Training Loss: 0.2320, Validation Loss: 5.3892, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [1259/1500], Training Loss: 0.3488, Validation Loss: 4.8502, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [1260/1500], Training Loss: 0.2213, Validation Loss: 4.9839, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [1261/1500], Training Loss: 0.2484, Validation Loss: 5.1389, Validation Accuracy: 0.4176, Percentage:41.7647%\n",
            "Epoch [1262/1500], Training Loss: 0.2467, Validation Loss: 5.4672, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [1263/1500], Training Loss: 0.2547, Validation Loss: 5.0391, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [1264/1500], Training Loss: 0.2498, Validation Loss: 5.3679, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [1265/1500], Training Loss: 0.2676, Validation Loss: 5.1618, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [1266/1500], Training Loss: 0.3113, Validation Loss: 5.1719, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [1267/1500], Training Loss: 0.2734, Validation Loss: 5.0986, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [1268/1500], Training Loss: 0.2697, Validation Loss: 4.8275, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [1269/1500], Training Loss: 0.2165, Validation Loss: 5.1080, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [1270/1500], Training Loss: 0.2592, Validation Loss: 5.5819, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [1271/1500], Training Loss: 0.2409, Validation Loss: 5.7487, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [1272/1500], Training Loss: 0.3222, Validation Loss: 5.1632, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [1273/1500], Training Loss: 0.2491, Validation Loss: 5.3923, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [1274/1500], Training Loss: 0.3129, Validation Loss: 5.1905, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [1275/1500], Training Loss: 0.2677, Validation Loss: 4.9986, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [1276/1500], Training Loss: 0.2669, Validation Loss: 5.1028, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [1277/1500], Training Loss: 0.2969, Validation Loss: 5.3268, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [1278/1500], Training Loss: 0.2780, Validation Loss: 5.2947, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [1279/1500], Training Loss: 0.2758, Validation Loss: 5.0505, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [1280/1500], Training Loss: 0.2796, Validation Loss: 5.0361, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [1281/1500], Training Loss: 0.2543, Validation Loss: 5.2004, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [1282/1500], Training Loss: 0.2714, Validation Loss: 5.4132, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [1283/1500], Training Loss: 0.2788, Validation Loss: 5.3537, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [1284/1500], Training Loss: 0.3057, Validation Loss: 5.4788, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [1285/1500], Training Loss: 0.2659, Validation Loss: 5.4345, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [1286/1500], Training Loss: 0.2486, Validation Loss: 5.2230, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [1287/1500], Training Loss: 0.2161, Validation Loss: 5.4671, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [1288/1500], Training Loss: 0.3083, Validation Loss: 5.2827, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [1289/1500], Training Loss: 0.2533, Validation Loss: 5.2113, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [1290/1500], Training Loss: 0.2338, Validation Loss: 5.1579, Validation Accuracy: 0.4265, Percentage:42.6471%\n",
            "Epoch [1291/1500], Training Loss: 0.2070, Validation Loss: 5.5094, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [1292/1500], Training Loss: 0.1979, Validation Loss: 5.4204, Validation Accuracy: 0.4225, Percentage:42.2549%\n",
            "Epoch [1293/1500], Training Loss: 0.2374, Validation Loss: 5.5262, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [1294/1500], Training Loss: 0.2343, Validation Loss: 5.4876, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [1295/1500], Training Loss: 0.2673, Validation Loss: 5.3435, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [1296/1500], Training Loss: 0.2700, Validation Loss: 5.5260, Validation Accuracy: 0.3853, Percentage:38.5294%\n",
            "Epoch [1297/1500], Training Loss: 0.2749, Validation Loss: 5.3394, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [1298/1500], Training Loss: 0.2066, Validation Loss: 5.4217, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [1299/1500], Training Loss: 0.3068, Validation Loss: 4.9581, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [1300/1500], Training Loss: 0.2558, Validation Loss: 5.4058, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [1301/1500], Training Loss: 0.2966, Validation Loss: 5.2705, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [1302/1500], Training Loss: 0.2356, Validation Loss: 5.3101, Validation Accuracy: 0.3912, Percentage:39.1176%\n",
            "Epoch [1303/1500], Training Loss: 0.2397, Validation Loss: 5.2017, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [1304/1500], Training Loss: 0.3121, Validation Loss: 4.7394, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [1305/1500], Training Loss: 0.2599, Validation Loss: 5.1646, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [1306/1500], Training Loss: 0.2537, Validation Loss: 5.2086, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [1307/1500], Training Loss: 0.2847, Validation Loss: 5.4204, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [1308/1500], Training Loss: 0.2599, Validation Loss: 5.2906, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [1309/1500], Training Loss: 0.2854, Validation Loss: 5.2659, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [1310/1500], Training Loss: 0.2191, Validation Loss: 5.4354, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [1311/1500], Training Loss: 0.2814, Validation Loss: 5.1873, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [1312/1500], Training Loss: 0.2475, Validation Loss: 5.4954, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [1313/1500], Training Loss: 0.2472, Validation Loss: 5.5989, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [1314/1500], Training Loss: 0.2277, Validation Loss: 5.2339, Validation Accuracy: 0.3902, Percentage:39.0196%\n",
            "Epoch [1315/1500], Training Loss: 0.2342, Validation Loss: 5.4450, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [1316/1500], Training Loss: 0.2774, Validation Loss: 5.0980, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [1317/1500], Training Loss: 0.2702, Validation Loss: 5.3467, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [1318/1500], Training Loss: 0.2628, Validation Loss: 5.2818, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [1319/1500], Training Loss: 0.3330, Validation Loss: 5.1237, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [1320/1500], Training Loss: 0.3283, Validation Loss: 5.3603, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [1321/1500], Training Loss: 0.2903, Validation Loss: 5.2661, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [1322/1500], Training Loss: 0.2635, Validation Loss: 5.3991, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [1323/1500], Training Loss: 0.2812, Validation Loss: 5.6957, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [1324/1500], Training Loss: 0.1984, Validation Loss: 5.3744, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [1325/1500], Training Loss: 0.3032, Validation Loss: 5.0237, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [1326/1500], Training Loss: 0.2250, Validation Loss: 5.4705, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [1327/1500], Training Loss: 0.2291, Validation Loss: 5.4652, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [1328/1500], Training Loss: 0.2347, Validation Loss: 5.4346, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [1329/1500], Training Loss: 0.3127, Validation Loss: 5.2218, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [1330/1500], Training Loss: 0.2724, Validation Loss: 5.1291, Validation Accuracy: 0.4265, Percentage:42.6471%\n",
            "Epoch [1331/1500], Training Loss: 0.2671, Validation Loss: 5.4162, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [1332/1500], Training Loss: 0.2917, Validation Loss: 5.2324, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [1333/1500], Training Loss: 0.2274, Validation Loss: 5.2010, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [1334/1500], Training Loss: 0.2357, Validation Loss: 5.5656, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [1335/1500], Training Loss: 0.2667, Validation Loss: 5.3651, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [1336/1500], Training Loss: 0.2327, Validation Loss: 5.7168, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [1337/1500], Training Loss: 0.2687, Validation Loss: 5.1154, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [1338/1500], Training Loss: 0.2018, Validation Loss: 5.4965, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [1339/1500], Training Loss: 0.2333, Validation Loss: 5.2158, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [1340/1500], Training Loss: 0.2910, Validation Loss: 5.5362, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [1341/1500], Training Loss: 0.2964, Validation Loss: 5.2490, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [1342/1500], Training Loss: 0.3357, Validation Loss: 5.3701, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [1343/1500], Training Loss: 0.2587, Validation Loss: 5.0476, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [1344/1500], Training Loss: 0.2648, Validation Loss: 5.2105, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [1345/1500], Training Loss: 0.2536, Validation Loss: 5.3174, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [1346/1500], Training Loss: 0.2412, Validation Loss: 5.3367, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [1347/1500], Training Loss: 0.2271, Validation Loss: 5.5795, Validation Accuracy: 0.4176, Percentage:41.7647%\n",
            "Epoch [1348/1500], Training Loss: 0.3198, Validation Loss: 5.1078, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [1349/1500], Training Loss: 0.2435, Validation Loss: 5.4678, Validation Accuracy: 0.3794, Percentage:37.9412%\n",
            "Epoch [1350/1500], Training Loss: 0.2535, Validation Loss: 5.5955, Validation Accuracy: 0.3882, Percentage:38.8235%\n",
            "Epoch [1351/1500], Training Loss: 0.2285, Validation Loss: 5.3572, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [1352/1500], Training Loss: 0.2272, Validation Loss: 5.4148, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [1353/1500], Training Loss: 0.2931, Validation Loss: 5.3525, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [1354/1500], Training Loss: 0.2321, Validation Loss: 5.2402, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [1355/1500], Training Loss: 0.2713, Validation Loss: 4.9149, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [1356/1500], Training Loss: 0.2592, Validation Loss: 5.2789, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [1357/1500], Training Loss: 0.2387, Validation Loss: 5.0740, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [1358/1500], Training Loss: 0.3127, Validation Loss: 5.2397, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [1359/1500], Training Loss: 0.2068, Validation Loss: 5.1718, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [1360/1500], Training Loss: 0.2017, Validation Loss: 5.5033, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [1361/1500], Training Loss: 0.2240, Validation Loss: 5.4125, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [1362/1500], Training Loss: 0.2316, Validation Loss: 5.0932, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [1363/1500], Training Loss: 0.2432, Validation Loss: 5.2361, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [1364/1500], Training Loss: 0.2084, Validation Loss: 5.7099, Validation Accuracy: 0.4176, Percentage:41.7647%\n",
            "Epoch [1365/1500], Training Loss: 0.2102, Validation Loss: 5.6760, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [1366/1500], Training Loss: 0.3228, Validation Loss: 5.0146, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [1367/1500], Training Loss: 0.2075, Validation Loss: 5.2791, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [1368/1500], Training Loss: 0.3095, Validation Loss: 5.7496, Validation Accuracy: 0.3824, Percentage:38.2353%\n",
            "Epoch [1369/1500], Training Loss: 0.2511, Validation Loss: 5.2476, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [1370/1500], Training Loss: 0.3391, Validation Loss: 5.0711, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [1371/1500], Training Loss: 0.2363, Validation Loss: 5.2287, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [1372/1500], Training Loss: 0.2284, Validation Loss: 5.6529, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [1373/1500], Training Loss: 0.2619, Validation Loss: 5.4959, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [1374/1500], Training Loss: 0.3233, Validation Loss: 5.0039, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [1375/1500], Training Loss: 0.2450, Validation Loss: 5.2555, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [1376/1500], Training Loss: 0.2439, Validation Loss: 5.4497, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [1377/1500], Training Loss: 0.2748, Validation Loss: 5.3457, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [1378/1500], Training Loss: 0.2711, Validation Loss: 5.3127, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [1379/1500], Training Loss: 0.2688, Validation Loss: 5.3287, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [1380/1500], Training Loss: 0.2325, Validation Loss: 5.2491, Validation Accuracy: 0.3892, Percentage:38.9216%\n",
            "Epoch [1381/1500], Training Loss: 0.2658, Validation Loss: 5.0010, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [1382/1500], Training Loss: 0.2583, Validation Loss: 5.6309, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [1383/1500], Training Loss: 0.2552, Validation Loss: 5.1721, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [1384/1500], Training Loss: 0.2549, Validation Loss: 5.3848, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [1385/1500], Training Loss: 0.2493, Validation Loss: 5.4450, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [1386/1500], Training Loss: 0.2177, Validation Loss: 5.1614, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [1387/1500], Training Loss: 0.2497, Validation Loss: 5.6513, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [1388/1500], Training Loss: 0.2352, Validation Loss: 5.3225, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [1389/1500], Training Loss: 0.2896, Validation Loss: 5.1572, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [1390/1500], Training Loss: 0.2831, Validation Loss: 5.1357, Validation Accuracy: 0.4284, Percentage:42.8431%\n",
            "Epoch [1391/1500], Training Loss: 0.2348, Validation Loss: 5.2908, Validation Accuracy: 0.3892, Percentage:38.9216%\n",
            "Epoch [1392/1500], Training Loss: 0.2054, Validation Loss: 5.6289, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [1393/1500], Training Loss: 0.2631, Validation Loss: 5.2122, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [1394/1500], Training Loss: 0.2810, Validation Loss: 5.2634, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [1395/1500], Training Loss: 0.2390, Validation Loss: 5.2125, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [1396/1500], Training Loss: 0.2732, Validation Loss: 5.2184, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [1397/1500], Training Loss: 0.2642, Validation Loss: 5.1342, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [1398/1500], Training Loss: 0.2321, Validation Loss: 5.4133, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [1399/1500], Training Loss: 0.2190, Validation Loss: 5.3418, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [1400/1500], Training Loss: 0.2955, Validation Loss: 5.0683, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [1401/1500], Training Loss: 0.2908, Validation Loss: 5.2818, Validation Accuracy: 0.3833, Percentage:38.3333%\n",
            "Epoch [1402/1500], Training Loss: 0.2334, Validation Loss: 5.3946, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [1403/1500], Training Loss: 0.1656, Validation Loss: 5.3002, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [1404/1500], Training Loss: 0.2475, Validation Loss: 5.2948, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [1405/1500], Training Loss: 0.1726, Validation Loss: 5.4794, Validation Accuracy: 0.4225, Percentage:42.2549%\n",
            "Epoch [1406/1500], Training Loss: 0.2123, Validation Loss: 5.6117, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [1407/1500], Training Loss: 0.2991, Validation Loss: 5.5141, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [1408/1500], Training Loss: 0.2235, Validation Loss: 5.4602, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [1409/1500], Training Loss: 0.2816, Validation Loss: 5.2391, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [1410/1500], Training Loss: 0.2672, Validation Loss: 5.1714, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [1411/1500], Training Loss: 0.2368, Validation Loss: 5.6218, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [1412/1500], Training Loss: 0.1888, Validation Loss: 5.6272, Validation Accuracy: 0.3863, Percentage:38.6275%\n",
            "Epoch [1413/1500], Training Loss: 0.2137, Validation Loss: 5.1893, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [1414/1500], Training Loss: 0.2169, Validation Loss: 5.4444, Validation Accuracy: 0.4225, Percentage:42.2549%\n",
            "Epoch [1415/1500], Training Loss: 0.2584, Validation Loss: 5.6383, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [1416/1500], Training Loss: 0.2343, Validation Loss: 5.4849, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [1417/1500], Training Loss: 0.2924, Validation Loss: 5.2923, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [1418/1500], Training Loss: 0.2688, Validation Loss: 5.4495, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [1419/1500], Training Loss: 0.2694, Validation Loss: 5.0227, Validation Accuracy: 0.3833, Percentage:38.3333%\n",
            "Epoch [1420/1500], Training Loss: 0.2204, Validation Loss: 5.2643, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [1421/1500], Training Loss: 0.2129, Validation Loss: 5.2502, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [1422/1500], Training Loss: 0.2762, Validation Loss: 5.2885, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [1423/1500], Training Loss: 0.2699, Validation Loss: 5.5762, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [1424/1500], Training Loss: 0.2634, Validation Loss: 5.5171, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [1425/1500], Training Loss: 0.2699, Validation Loss: 5.1952, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [1426/1500], Training Loss: 0.2461, Validation Loss: 5.2677, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [1427/1500], Training Loss: 0.1996, Validation Loss: 5.9688, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [1428/1500], Training Loss: 0.2762, Validation Loss: 5.4423, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [1429/1500], Training Loss: 0.1873, Validation Loss: 5.3679, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [1430/1500], Training Loss: 0.2251, Validation Loss: 5.3699, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [1431/1500], Training Loss: 0.2654, Validation Loss: 5.5245, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [1432/1500], Training Loss: 0.2145, Validation Loss: 5.2043, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [1433/1500], Training Loss: 0.2526, Validation Loss: 5.6372, Validation Accuracy: 0.3853, Percentage:38.5294%\n",
            "Epoch [1434/1500], Training Loss: 0.2793, Validation Loss: 5.3920, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [1435/1500], Training Loss: 0.2289, Validation Loss: 5.6852, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [1436/1500], Training Loss: 0.2895, Validation Loss: 5.3516, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [1437/1500], Training Loss: 0.2479, Validation Loss: 5.3322, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [1438/1500], Training Loss: 0.2242, Validation Loss: 5.3344, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [1439/1500], Training Loss: 0.2930, Validation Loss: 5.2455, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [1440/1500], Training Loss: 0.2124, Validation Loss: 5.5752, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [1441/1500], Training Loss: 0.2260, Validation Loss: 5.4389, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [1442/1500], Training Loss: 0.2109, Validation Loss: 5.2273, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [1443/1500], Training Loss: 0.1882, Validation Loss: 5.7902, Validation Accuracy: 0.3853, Percentage:38.5294%\n",
            "Epoch [1444/1500], Training Loss: 0.2450, Validation Loss: 5.7671, Validation Accuracy: 0.3863, Percentage:38.6275%\n",
            "Epoch [1445/1500], Training Loss: 0.2200, Validation Loss: 5.6171, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [1446/1500], Training Loss: 0.3338, Validation Loss: 5.2603, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [1447/1500], Training Loss: 0.2201, Validation Loss: 5.6988, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [1448/1500], Training Loss: 0.2407, Validation Loss: 5.6303, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [1449/1500], Training Loss: 0.2214, Validation Loss: 5.7781, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [1450/1500], Training Loss: 0.1919, Validation Loss: 5.5771, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [1451/1500], Training Loss: 0.2196, Validation Loss: 5.8103, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [1452/1500], Training Loss: 0.3416, Validation Loss: 5.2744, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [1453/1500], Training Loss: 0.1977, Validation Loss: 5.3985, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [1454/1500], Training Loss: 0.2100, Validation Loss: 5.5670, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [1455/1500], Training Loss: 0.2115, Validation Loss: 5.9071, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [1456/1500], Training Loss: 0.2425, Validation Loss: 5.6280, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [1457/1500], Training Loss: 0.2347, Validation Loss: 5.4727, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [1458/1500], Training Loss: 0.2605, Validation Loss: 5.4003, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [1459/1500], Training Loss: 0.2742, Validation Loss: 5.8380, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [1460/1500], Training Loss: 0.2600, Validation Loss: 5.4848, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [1461/1500], Training Loss: 0.2820, Validation Loss: 5.4197, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [1462/1500], Training Loss: 0.2442, Validation Loss: 5.1792, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [1463/1500], Training Loss: 0.2595, Validation Loss: 5.7384, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [1464/1500], Training Loss: 0.2671, Validation Loss: 5.4882, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [1465/1500], Training Loss: 0.2538, Validation Loss: 5.6151, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [1466/1500], Training Loss: 0.2209, Validation Loss: 5.2520, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [1467/1500], Training Loss: 0.2639, Validation Loss: 5.4867, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [1468/1500], Training Loss: 0.2168, Validation Loss: 5.5349, Validation Accuracy: 0.4176, Percentage:41.7647%\n",
            "Epoch [1469/1500], Training Loss: 0.2513, Validation Loss: 5.6357, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [1470/1500], Training Loss: 0.2305, Validation Loss: 5.6195, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [1471/1500], Training Loss: 0.3472, Validation Loss: 5.7420, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [1472/1500], Training Loss: 0.2296, Validation Loss: 5.5126, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [1473/1500], Training Loss: 0.2187, Validation Loss: 5.8922, Validation Accuracy: 0.3863, Percentage:38.6275%\n",
            "Epoch [1474/1500], Training Loss: 0.2944, Validation Loss: 5.1850, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [1475/1500], Training Loss: 0.2810, Validation Loss: 5.2483, Validation Accuracy: 0.3892, Percentage:38.9216%\n",
            "Epoch [1476/1500], Training Loss: 0.2152, Validation Loss: 5.4356, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [1477/1500], Training Loss: 0.2897, Validation Loss: 5.4571, Validation Accuracy: 0.3892, Percentage:38.9216%\n",
            "Epoch [1478/1500], Training Loss: 0.2604, Validation Loss: 5.6919, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [1479/1500], Training Loss: 0.2209, Validation Loss: 5.5766, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [1480/1500], Training Loss: 0.2492, Validation Loss: 5.3620, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [1481/1500], Training Loss: 0.2333, Validation Loss: 5.6056, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [1482/1500], Training Loss: 0.2412, Validation Loss: 5.3672, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [1483/1500], Training Loss: 0.2280, Validation Loss: 5.4979, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [1484/1500], Training Loss: 0.2493, Validation Loss: 5.9790, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [1485/1500], Training Loss: 0.2099, Validation Loss: 5.7347, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [1486/1500], Training Loss: 0.2221, Validation Loss: 5.6035, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [1487/1500], Training Loss: 0.3107, Validation Loss: 5.1574, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [1488/1500], Training Loss: 0.2136, Validation Loss: 5.3576, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [1489/1500], Training Loss: 0.2672, Validation Loss: 5.7822, Validation Accuracy: 0.3824, Percentage:38.2353%\n",
            "Epoch [1490/1500], Training Loss: 0.2145, Validation Loss: 5.3686, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [1491/1500], Training Loss: 0.2292, Validation Loss: 5.3951, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [1492/1500], Training Loss: 0.2088, Validation Loss: 5.7353, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [1493/1500], Training Loss: 0.2855, Validation Loss: 5.3014, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [1494/1500], Training Loss: 0.2333, Validation Loss: 5.4738, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [1495/1500], Training Loss: 0.2065, Validation Loss: 5.8992, Validation Accuracy: 0.3843, Percentage:38.4314%\n",
            "Epoch [1496/1500], Training Loss: 0.2653, Validation Loss: 6.2662, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [1497/1500], Training Loss: 0.2974, Validation Loss: 5.4891, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [1498/1500], Training Loss: 0.2379, Validation Loss: 5.3013, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [1499/1500], Training Loss: 0.2406, Validation Loss: 5.3326, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [1500/1500], Training Loss: 0.2533, Validation Loss: 5.4554, Validation Accuracy: 0.3882, Percentage:38.8235%\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import Flowers102\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define transforms for data augmentation and normalization\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(500),\n",
        "    #transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(500),\n",
        "    transforms.CenterCrop(500),\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the dataset with train/val/test splits\n",
        "train_dataset = Flowers102(root='./data', split='train', transform=train_transform, download=True)\n",
        "val_dataset = Flowers102(root='./data', split='val', transform=val_transform, download=True)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Define data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "class CNN_NN(nn.Module):\n",
        "    def __init__(self, num_classes=102):\n",
        "        super(CNN_NN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv5= nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "        # Initialize the size of the fully connected layer based on the sample input\n",
        "        self._to_linear = None\n",
        "        self.convs = nn.Sequential(\n",
        "            self.conv1,\n",
        "            nn.ReLU(),\n",
        "            self.pool,\n",
        "            self.conv2,\n",
        "            nn.ReLU(),\n",
        "            self.pool,\n",
        "            self.conv3,\n",
        "            nn.ReLU(),\n",
        "            self.pool,\n",
        "            self.conv4,\n",
        "            nn.ReLU(),\n",
        "            self.pool,\n",
        "            self.conv5,\n",
        "            nn.ReLU(),\n",
        "            self.pool\n",
        "        )\n",
        "        self._initialize_linear_layer()\n",
        "\n",
        "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def _initialize_linear_layer(self):\n",
        "        # Create a dummy input tensor to calculate the output size after conv layers\n",
        "        x = torch.randn(1, 3, 500, 500)\n",
        "        x = self.convs(x)\n",
        "        self._to_linear = x.view(1, -1).shape[1]\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor while preserving the batch size\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Define the device (GPU or CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyperparameters\n",
        "num_classes = 102  # Number of output classes\n",
        "learning_rate = 0.0001\n",
        "num_epochs = 1500\n",
        "\n",
        "# Initialize the model\n",
        "model = CNN_NN(num_classes=num_classes).to(device)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    # Calculate average loss for the epoch\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Calculate average validation loss and accuracy\n",
        "    val_loss = val_loss / len(val_loader.dataset)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "          f'Training Loss: {epoch_loss:.4f}, '\n",
        "          f'Validation Loss: {val_loss:.4f}, '\n",
        "          f'Validation Accuracy: {accuracy:.4f}, '\n",
        "          f'Percentage:{accuracy*100:.4f}%')\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "6A2XGzgzZQxl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "424f4597-39dc-4ea1-ee0d-4c997f3e3c3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to data/flowers-102/102flowers.tgz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 344862509/344862509 [00:23<00:00, 14461733.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/flowers-102/102flowers.tgz to data/flowers-102\n",
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to data/flowers-102/imagelabels.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 502/502 [00:00<00:00, 802110.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to data/flowers-102/setid.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14989/14989 [00:00<00:00, 12726401.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1500], Training Loss: 4.6285, Validation Loss: 4.6249, Validation Accuracy: 0.0098, Percentage:0.9804%\n",
            "Epoch [2/1500], Training Loss: 4.6012, Validation Loss: 4.5127, Validation Accuracy: 0.0147, Percentage:1.4706%\n",
            "Epoch [3/1500], Training Loss: 4.4752, Validation Loss: 4.3471, Validation Accuracy: 0.0265, Percentage:2.6471%\n",
            "Epoch [4/1500], Training Loss: 4.3593, Validation Loss: 4.2737, Validation Accuracy: 0.0284, Percentage:2.8431%\n",
            "Epoch [5/1500], Training Loss: 4.2924, Validation Loss: 4.2165, Validation Accuracy: 0.0304, Percentage:3.0392%\n",
            "Epoch [6/1500], Training Loss: 4.2679, Validation Loss: 4.2016, Validation Accuracy: 0.0422, Percentage:4.2157%\n",
            "Epoch [7/1500], Training Loss: 4.1899, Validation Loss: 4.1322, Validation Accuracy: 0.0471, Percentage:4.7059%\n",
            "Epoch [8/1500], Training Loss: 4.1541, Validation Loss: 4.1187, Validation Accuracy: 0.0441, Percentage:4.4118%\n",
            "Epoch [9/1500], Training Loss: 4.1112, Validation Loss: 4.0849, Validation Accuracy: 0.0490, Percentage:4.9020%\n",
            "Epoch [10/1500], Training Loss: 4.0713, Validation Loss: 4.0390, Validation Accuracy: 0.0667, Percentage:6.6667%\n",
            "Epoch [11/1500], Training Loss: 4.0351, Validation Loss: 3.9893, Validation Accuracy: 0.0529, Percentage:5.2941%\n",
            "Epoch [12/1500], Training Loss: 3.9859, Validation Loss: 3.9460, Validation Accuracy: 0.0922, Percentage:9.2157%\n",
            "Epoch [13/1500], Training Loss: 3.9973, Validation Loss: 3.9370, Validation Accuracy: 0.0814, Percentage:8.1373%\n",
            "Epoch [14/1500], Training Loss: 3.8951, Validation Loss: 3.8163, Validation Accuracy: 0.1137, Percentage:11.3725%\n",
            "Epoch [15/1500], Training Loss: 3.8840, Validation Loss: 3.8520, Validation Accuracy: 0.1010, Percentage:10.0980%\n",
            "Epoch [16/1500], Training Loss: 3.7752, Validation Loss: 3.7689, Validation Accuracy: 0.1137, Percentage:11.3725%\n",
            "Epoch [17/1500], Training Loss: 3.7449, Validation Loss: 3.8112, Validation Accuracy: 0.1029, Percentage:10.2941%\n",
            "Epoch [18/1500], Training Loss: 3.6699, Validation Loss: 3.6543, Validation Accuracy: 0.1353, Percentage:13.5294%\n",
            "Epoch [19/1500], Training Loss: 3.5809, Validation Loss: 3.6153, Validation Accuracy: 0.1490, Percentage:14.9020%\n",
            "Epoch [20/1500], Training Loss: 3.5365, Validation Loss: 3.5389, Validation Accuracy: 0.1500, Percentage:15.0000%\n",
            "Epoch [21/1500], Training Loss: 3.5200, Validation Loss: 3.5411, Validation Accuracy: 0.1539, Percentage:15.3922%\n",
            "Epoch [22/1500], Training Loss: 3.4421, Validation Loss: 3.4980, Validation Accuracy: 0.1745, Percentage:17.4510%\n",
            "Epoch [23/1500], Training Loss: 3.4069, Validation Loss: 3.4429, Validation Accuracy: 0.1686, Percentage:16.8627%\n",
            "Epoch [24/1500], Training Loss: 3.3305, Validation Loss: 3.4623, Validation Accuracy: 0.1608, Percentage:16.0784%\n",
            "Epoch [25/1500], Training Loss: 3.2494, Validation Loss: 3.3878, Validation Accuracy: 0.1804, Percentage:18.0392%\n",
            "Epoch [26/1500], Training Loss: 3.2280, Validation Loss: 3.3449, Validation Accuracy: 0.1843, Percentage:18.4314%\n",
            "Epoch [27/1500], Training Loss: 3.1472, Validation Loss: 3.3258, Validation Accuracy: 0.1922, Percentage:19.2157%\n",
            "Epoch [28/1500], Training Loss: 3.1242, Validation Loss: 3.2746, Validation Accuracy: 0.1961, Percentage:19.6078%\n",
            "Epoch [29/1500], Training Loss: 3.1239, Validation Loss: 3.2667, Validation Accuracy: 0.2088, Percentage:20.8824%\n",
            "Epoch [30/1500], Training Loss: 2.9820, Validation Loss: 3.2202, Validation Accuracy: 0.2363, Percentage:23.6275%\n",
            "Epoch [31/1500], Training Loss: 2.8944, Validation Loss: 3.2273, Validation Accuracy: 0.2235, Percentage:22.3529%\n",
            "Epoch [32/1500], Training Loss: 2.9043, Validation Loss: 3.1640, Validation Accuracy: 0.2392, Percentage:23.9216%\n",
            "Epoch [33/1500], Training Loss: 2.8506, Validation Loss: 3.1552, Validation Accuracy: 0.2304, Percentage:23.0392%\n",
            "Epoch [34/1500], Training Loss: 2.8301, Validation Loss: 3.1255, Validation Accuracy: 0.2441, Percentage:24.4118%\n",
            "Epoch [35/1500], Training Loss: 2.7535, Validation Loss: 3.0596, Validation Accuracy: 0.2559, Percentage:25.5882%\n",
            "Epoch [36/1500], Training Loss: 2.7454, Validation Loss: 3.0739, Validation Accuracy: 0.2471, Percentage:24.7059%\n",
            "Epoch [37/1500], Training Loss: 2.6428, Validation Loss: 3.0684, Validation Accuracy: 0.2588, Percentage:25.8824%\n",
            "Epoch [38/1500], Training Loss: 2.6684, Validation Loss: 3.0494, Validation Accuracy: 0.2647, Percentage:26.4706%\n",
            "Epoch [39/1500], Training Loss: 2.4755, Validation Loss: 2.9942, Validation Accuracy: 0.2922, Percentage:29.2157%\n",
            "Epoch [40/1500], Training Loss: 2.6067, Validation Loss: 3.0038, Validation Accuracy: 0.2716, Percentage:27.1569%\n",
            "Epoch [41/1500], Training Loss: 2.4205, Validation Loss: 3.0895, Validation Accuracy: 0.2784, Percentage:27.8431%\n",
            "Epoch [42/1500], Training Loss: 2.4417, Validation Loss: 3.0309, Validation Accuracy: 0.2598, Percentage:25.9804%\n",
            "Epoch [43/1500], Training Loss: 2.3898, Validation Loss: 2.9694, Validation Accuracy: 0.2892, Percentage:28.9216%\n",
            "Epoch [44/1500], Training Loss: 2.3662, Validation Loss: 2.9962, Validation Accuracy: 0.2833, Percentage:28.3333%\n",
            "Epoch [45/1500], Training Loss: 2.3408, Validation Loss: 3.0303, Validation Accuracy: 0.2824, Percentage:28.2353%\n",
            "Epoch [46/1500], Training Loss: 2.3774, Validation Loss: 3.0356, Validation Accuracy: 0.2892, Percentage:28.9216%\n",
            "Epoch [47/1500], Training Loss: 2.3096, Validation Loss: 2.8891, Validation Accuracy: 0.2990, Percentage:29.9020%\n",
            "Epoch [48/1500], Training Loss: 2.2635, Validation Loss: 2.9231, Validation Accuracy: 0.2961, Percentage:29.6078%\n",
            "Epoch [49/1500], Training Loss: 2.2576, Validation Loss: 2.9430, Validation Accuracy: 0.2912, Percentage:29.1176%\n",
            "Epoch [50/1500], Training Loss: 2.2768, Validation Loss: 2.9940, Validation Accuracy: 0.2961, Percentage:29.6078%\n",
            "Epoch [51/1500], Training Loss: 2.1524, Validation Loss: 2.9745, Validation Accuracy: 0.2775, Percentage:27.7451%\n",
            "Epoch [52/1500], Training Loss: 2.1564, Validation Loss: 2.9231, Validation Accuracy: 0.2931, Percentage:29.3137%\n",
            "Epoch [53/1500], Training Loss: 1.9788, Validation Loss: 3.0196, Validation Accuracy: 0.3167, Percentage:31.6667%\n",
            "Epoch [54/1500], Training Loss: 2.0583, Validation Loss: 2.8748, Validation Accuracy: 0.3265, Percentage:32.6471%\n",
            "Epoch [55/1500], Training Loss: 2.0492, Validation Loss: 2.9604, Validation Accuracy: 0.3196, Percentage:31.9608%\n",
            "Epoch [56/1500], Training Loss: 2.0961, Validation Loss: 2.9508, Validation Accuracy: 0.2961, Percentage:29.6078%\n",
            "Epoch [57/1500], Training Loss: 2.0013, Validation Loss: 2.8685, Validation Accuracy: 0.3245, Percentage:32.4510%\n",
            "Epoch [58/1500], Training Loss: 1.9162, Validation Loss: 2.9115, Validation Accuracy: 0.3255, Percentage:32.5490%\n",
            "Epoch [59/1500], Training Loss: 1.9150, Validation Loss: 2.8994, Validation Accuracy: 0.2990, Percentage:29.9020%\n",
            "Epoch [60/1500], Training Loss: 1.9700, Validation Loss: 2.8637, Validation Accuracy: 0.3196, Percentage:31.9608%\n",
            "Epoch [61/1500], Training Loss: 1.9453, Validation Loss: 2.8826, Validation Accuracy: 0.3216, Percentage:32.1569%\n",
            "Epoch [62/1500], Training Loss: 1.9258, Validation Loss: 2.9554, Validation Accuracy: 0.3069, Percentage:30.6863%\n",
            "Epoch [63/1500], Training Loss: 1.7470, Validation Loss: 2.8926, Validation Accuracy: 0.3147, Percentage:31.4706%\n",
            "Epoch [64/1500], Training Loss: 1.8264, Validation Loss: 2.9676, Validation Accuracy: 0.3039, Percentage:30.3922%\n",
            "Epoch [65/1500], Training Loss: 1.8132, Validation Loss: 2.8241, Validation Accuracy: 0.3333, Percentage:33.3333%\n",
            "Epoch [66/1500], Training Loss: 1.7735, Validation Loss: 2.8996, Validation Accuracy: 0.3471, Percentage:34.7059%\n",
            "Epoch [67/1500], Training Loss: 1.7976, Validation Loss: 2.9101, Validation Accuracy: 0.3245, Percentage:32.4510%\n",
            "Epoch [68/1500], Training Loss: 1.7346, Validation Loss: 2.7895, Validation Accuracy: 0.3422, Percentage:34.2157%\n",
            "Epoch [69/1500], Training Loss: 1.6520, Validation Loss: 2.9124, Validation Accuracy: 0.3245, Percentage:32.4510%\n",
            "Epoch [70/1500], Training Loss: 1.6629, Validation Loss: 2.9536, Validation Accuracy: 0.3157, Percentage:31.5686%\n",
            "Epoch [71/1500], Training Loss: 1.7817, Validation Loss: 2.9222, Validation Accuracy: 0.3618, Percentage:36.1765%\n",
            "Epoch [72/1500], Training Loss: 1.6312, Validation Loss: 2.9301, Validation Accuracy: 0.3324, Percentage:33.2353%\n",
            "Epoch [73/1500], Training Loss: 1.6958, Validation Loss: 2.8866, Validation Accuracy: 0.3490, Percentage:34.9020%\n",
            "Epoch [74/1500], Training Loss: 1.5908, Validation Loss: 3.0086, Validation Accuracy: 0.3314, Percentage:33.1373%\n",
            "Epoch [75/1500], Training Loss: 1.5403, Validation Loss: 2.9206, Validation Accuracy: 0.3392, Percentage:33.9216%\n",
            "Epoch [76/1500], Training Loss: 1.5760, Validation Loss: 2.9108, Validation Accuracy: 0.3510, Percentage:35.0980%\n",
            "Epoch [77/1500], Training Loss: 1.6533, Validation Loss: 2.8761, Validation Accuracy: 0.3539, Percentage:35.3922%\n",
            "Epoch [78/1500], Training Loss: 1.6521, Validation Loss: 2.8870, Validation Accuracy: 0.3471, Percentage:34.7059%\n",
            "Epoch [79/1500], Training Loss: 1.6490, Validation Loss: 2.8420, Validation Accuracy: 0.3402, Percentage:34.0196%\n",
            "Epoch [80/1500], Training Loss: 1.5564, Validation Loss: 2.8493, Validation Accuracy: 0.3529, Percentage:35.2941%\n",
            "Epoch [81/1500], Training Loss: 1.5726, Validation Loss: 2.8557, Validation Accuracy: 0.3539, Percentage:35.3922%\n",
            "Epoch [82/1500], Training Loss: 1.5191, Validation Loss: 2.9190, Validation Accuracy: 0.3402, Percentage:34.0196%\n",
            "Epoch [83/1500], Training Loss: 1.4455, Validation Loss: 2.8779, Validation Accuracy: 0.3686, Percentage:36.8627%\n",
            "Epoch [84/1500], Training Loss: 1.5285, Validation Loss: 2.9375, Validation Accuracy: 0.3402, Percentage:34.0196%\n",
            "Epoch [85/1500], Training Loss: 1.5493, Validation Loss: 3.0288, Validation Accuracy: 0.3559, Percentage:35.5882%\n",
            "Epoch [86/1500], Training Loss: 1.5286, Validation Loss: 2.8705, Validation Accuracy: 0.3471, Percentage:34.7059%\n",
            "Epoch [87/1500], Training Loss: 1.3988, Validation Loss: 3.0499, Validation Accuracy: 0.3627, Percentage:36.2745%\n",
            "Epoch [88/1500], Training Loss: 1.4533, Validation Loss: 2.9001, Validation Accuracy: 0.3588, Percentage:35.8824%\n",
            "Epoch [89/1500], Training Loss: 1.5202, Validation Loss: 2.9586, Validation Accuracy: 0.3461, Percentage:34.6078%\n",
            "Epoch [90/1500], Training Loss: 1.3304, Validation Loss: 2.9830, Validation Accuracy: 0.3618, Percentage:36.1765%\n",
            "Epoch [91/1500], Training Loss: 1.4529, Validation Loss: 2.9065, Validation Accuracy: 0.3647, Percentage:36.4706%\n",
            "Epoch [92/1500], Training Loss: 1.4216, Validation Loss: 2.9330, Validation Accuracy: 0.3578, Percentage:35.7843%\n",
            "Epoch [93/1500], Training Loss: 1.4358, Validation Loss: 2.8614, Validation Accuracy: 0.3735, Percentage:37.3529%\n",
            "Epoch [94/1500], Training Loss: 1.3202, Validation Loss: 2.9170, Validation Accuracy: 0.3559, Percentage:35.5882%\n",
            "Epoch [95/1500], Training Loss: 1.3159, Validation Loss: 2.9717, Validation Accuracy: 0.3657, Percentage:36.5686%\n",
            "Epoch [96/1500], Training Loss: 1.3194, Validation Loss: 2.9663, Validation Accuracy: 0.3608, Percentage:36.0784%\n",
            "Epoch [97/1500], Training Loss: 1.2617, Validation Loss: 2.9829, Validation Accuracy: 0.3725, Percentage:37.2549%\n",
            "Epoch [98/1500], Training Loss: 1.3446, Validation Loss: 2.9633, Validation Accuracy: 0.3657, Percentage:36.5686%\n",
            "Epoch [99/1500], Training Loss: 1.3095, Validation Loss: 2.9331, Validation Accuracy: 0.3716, Percentage:37.1569%\n",
            "Epoch [100/1500], Training Loss: 1.3571, Validation Loss: 3.0041, Validation Accuracy: 0.3490, Percentage:34.9020%\n",
            "Epoch [101/1500], Training Loss: 1.2534, Validation Loss: 2.9635, Validation Accuracy: 0.3725, Percentage:37.2549%\n",
            "Epoch [102/1500], Training Loss: 1.2613, Validation Loss: 2.9941, Validation Accuracy: 0.3549, Percentage:35.4902%\n",
            "Epoch [103/1500], Training Loss: 1.2960, Validation Loss: 3.1079, Validation Accuracy: 0.3500, Percentage:35.0000%\n",
            "Epoch [104/1500], Training Loss: 1.3179, Validation Loss: 2.8422, Validation Accuracy: 0.3647, Percentage:36.4706%\n",
            "Epoch [105/1500], Training Loss: 1.3210, Validation Loss: 2.8866, Validation Accuracy: 0.3647, Percentage:36.4706%\n",
            "Epoch [106/1500], Training Loss: 1.1338, Validation Loss: 3.0114, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [107/1500], Training Loss: 1.2446, Validation Loss: 3.0028, Validation Accuracy: 0.3784, Percentage:37.8431%\n",
            "Epoch [108/1500], Training Loss: 1.2586, Validation Loss: 2.9902, Validation Accuracy: 0.3539, Percentage:35.3922%\n",
            "Epoch [109/1500], Training Loss: 1.2520, Validation Loss: 2.9858, Validation Accuracy: 0.3804, Percentage:38.0392%\n",
            "Epoch [110/1500], Training Loss: 1.1439, Validation Loss: 3.0288, Validation Accuracy: 0.3882, Percentage:38.8235%\n",
            "Epoch [111/1500], Training Loss: 1.2151, Validation Loss: 3.1115, Validation Accuracy: 0.3451, Percentage:34.5098%\n",
            "Epoch [112/1500], Training Loss: 1.1995, Validation Loss: 2.9981, Validation Accuracy: 0.3627, Percentage:36.2745%\n",
            "Epoch [113/1500], Training Loss: 1.1181, Validation Loss: 2.9671, Validation Accuracy: 0.3735, Percentage:37.3529%\n",
            "Epoch [114/1500], Training Loss: 1.1674, Validation Loss: 3.0582, Validation Accuracy: 0.3735, Percentage:37.3529%\n",
            "Epoch [115/1500], Training Loss: 1.2346, Validation Loss: 2.9487, Validation Accuracy: 0.3657, Percentage:36.5686%\n",
            "Epoch [116/1500], Training Loss: 1.1985, Validation Loss: 2.9647, Validation Accuracy: 0.3794, Percentage:37.9412%\n",
            "Epoch [117/1500], Training Loss: 1.1842, Validation Loss: 3.0242, Validation Accuracy: 0.3882, Percentage:38.8235%\n",
            "Epoch [118/1500], Training Loss: 1.0975, Validation Loss: 2.9831, Validation Accuracy: 0.3735, Percentage:37.3529%\n",
            "Epoch [119/1500], Training Loss: 1.1662, Validation Loss: 3.0245, Validation Accuracy: 0.3716, Percentage:37.1569%\n",
            "Epoch [120/1500], Training Loss: 1.1190, Validation Loss: 3.0385, Validation Accuracy: 0.3784, Percentage:37.8431%\n",
            "Epoch [121/1500], Training Loss: 1.1851, Validation Loss: 3.0696, Validation Accuracy: 0.3667, Percentage:36.6667%\n",
            "Epoch [122/1500], Training Loss: 1.1286, Validation Loss: 3.1249, Validation Accuracy: 0.3775, Percentage:37.7451%\n",
            "Epoch [123/1500], Training Loss: 1.0777, Validation Loss: 3.1121, Validation Accuracy: 0.3569, Percentage:35.6863%\n",
            "Epoch [124/1500], Training Loss: 1.1313, Validation Loss: 2.9816, Validation Accuracy: 0.3706, Percentage:37.0588%\n",
            "Epoch [125/1500], Training Loss: 1.0658, Validation Loss: 3.1202, Validation Accuracy: 0.3716, Percentage:37.1569%\n",
            "Epoch [126/1500], Training Loss: 1.0867, Validation Loss: 3.0221, Validation Accuracy: 0.3765, Percentage:37.6471%\n",
            "Epoch [127/1500], Training Loss: 1.0841, Validation Loss: 3.0776, Validation Accuracy: 0.3765, Percentage:37.6471%\n",
            "Epoch [128/1500], Training Loss: 1.0989, Validation Loss: 2.8240, Validation Accuracy: 0.3853, Percentage:38.5294%\n",
            "Epoch [129/1500], Training Loss: 1.0384, Validation Loss: 3.0269, Validation Accuracy: 0.3765, Percentage:37.6471%\n",
            "Epoch [130/1500], Training Loss: 1.0458, Validation Loss: 3.0414, Validation Accuracy: 0.3794, Percentage:37.9412%\n",
            "Epoch [131/1500], Training Loss: 1.0315, Validation Loss: 3.2213, Validation Accuracy: 0.3706, Percentage:37.0588%\n",
            "Epoch [132/1500], Training Loss: 1.0521, Validation Loss: 3.1486, Validation Accuracy: 0.3784, Percentage:37.8431%\n",
            "Epoch [133/1500], Training Loss: 1.1581, Validation Loss: 3.0329, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [134/1500], Training Loss: 1.0596, Validation Loss: 3.1339, Validation Accuracy: 0.3824, Percentage:38.2353%\n",
            "Epoch [135/1500], Training Loss: 1.0447, Validation Loss: 3.1103, Validation Accuracy: 0.3765, Percentage:37.6471%\n",
            "Epoch [136/1500], Training Loss: 1.0093, Validation Loss: 3.1685, Validation Accuracy: 0.3696, Percentage:36.9608%\n",
            "Epoch [137/1500], Training Loss: 0.9920, Validation Loss: 3.1071, Validation Accuracy: 0.3794, Percentage:37.9412%\n",
            "Epoch [138/1500], Training Loss: 1.0078, Validation Loss: 2.9786, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [139/1500], Training Loss: 1.0450, Validation Loss: 3.0967, Validation Accuracy: 0.3706, Percentage:37.0588%\n",
            "Epoch [140/1500], Training Loss: 0.9813, Validation Loss: 3.1914, Validation Accuracy: 0.3912, Percentage:39.1176%\n",
            "Epoch [141/1500], Training Loss: 0.9358, Validation Loss: 3.0465, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [142/1500], Training Loss: 1.0356, Validation Loss: 3.0322, Validation Accuracy: 0.4225, Percentage:42.2549%\n",
            "Epoch [143/1500], Training Loss: 0.9494, Validation Loss: 3.0131, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [144/1500], Training Loss: 1.0681, Validation Loss: 2.9709, Validation Accuracy: 0.3804, Percentage:38.0392%\n",
            "Epoch [145/1500], Training Loss: 0.9244, Validation Loss: 3.1262, Validation Accuracy: 0.3755, Percentage:37.5490%\n",
            "Epoch [146/1500], Training Loss: 1.0689, Validation Loss: 3.0426, Validation Accuracy: 0.3824, Percentage:38.2353%\n",
            "Epoch [147/1500], Training Loss: 0.9662, Validation Loss: 3.0267, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [148/1500], Training Loss: 0.9934, Validation Loss: 3.1115, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [149/1500], Training Loss: 0.9418, Validation Loss: 3.1443, Validation Accuracy: 0.3804, Percentage:38.0392%\n",
            "Epoch [150/1500], Training Loss: 0.9403, Validation Loss: 3.2137, Validation Accuracy: 0.3755, Percentage:37.5490%\n",
            "Epoch [151/1500], Training Loss: 0.9127, Validation Loss: 3.1383, Validation Accuracy: 0.3843, Percentage:38.4314%\n",
            "Epoch [152/1500], Training Loss: 0.9250, Validation Loss: 3.1949, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [153/1500], Training Loss: 0.9631, Validation Loss: 3.0974, Validation Accuracy: 0.3637, Percentage:36.3725%\n",
            "Epoch [154/1500], Training Loss: 0.9101, Validation Loss: 3.2358, Validation Accuracy: 0.3863, Percentage:38.6275%\n",
            "Epoch [155/1500], Training Loss: 0.9547, Validation Loss: 3.0980, Validation Accuracy: 0.3882, Percentage:38.8235%\n",
            "Epoch [156/1500], Training Loss: 0.9448, Validation Loss: 3.1297, Validation Accuracy: 0.3882, Percentage:38.8235%\n",
            "Epoch [157/1500], Training Loss: 0.9088, Validation Loss: 3.1685, Validation Accuracy: 0.3902, Percentage:39.0196%\n",
            "Epoch [158/1500], Training Loss: 0.9502, Validation Loss: 3.1222, Validation Accuracy: 0.3804, Percentage:38.0392%\n",
            "Epoch [159/1500], Training Loss: 0.9196, Validation Loss: 3.1577, Validation Accuracy: 0.3765, Percentage:37.6471%\n",
            "Epoch [160/1500], Training Loss: 0.8822, Validation Loss: 3.4032, Validation Accuracy: 0.3667, Percentage:36.6667%\n",
            "Epoch [161/1500], Training Loss: 0.8563, Validation Loss: 3.2281, Validation Accuracy: 0.3863, Percentage:38.6275%\n",
            "Epoch [162/1500], Training Loss: 0.9728, Validation Loss: 3.1200, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [163/1500], Training Loss: 0.9152, Validation Loss: 3.1016, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [164/1500], Training Loss: 0.8609, Validation Loss: 3.0375, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [165/1500], Training Loss: 0.8498, Validation Loss: 3.0789, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [166/1500], Training Loss: 0.8691, Validation Loss: 3.2030, Validation Accuracy: 0.3765, Percentage:37.6471%\n",
            "Epoch [167/1500], Training Loss: 0.8668, Validation Loss: 3.1234, Validation Accuracy: 0.3902, Percentage:39.0196%\n",
            "Epoch [168/1500], Training Loss: 0.9287, Validation Loss: 3.1149, Validation Accuracy: 0.3892, Percentage:38.9216%\n",
            "Epoch [169/1500], Training Loss: 0.8809, Validation Loss: 3.1465, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [170/1500], Training Loss: 0.9015, Validation Loss: 3.1072, Validation Accuracy: 0.3843, Percentage:38.4314%\n",
            "Epoch [171/1500], Training Loss: 0.8513, Validation Loss: 3.1560, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [172/1500], Training Loss: 0.8752, Validation Loss: 3.0839, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [173/1500], Training Loss: 0.8488, Validation Loss: 3.0360, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [174/1500], Training Loss: 0.8931, Validation Loss: 3.1022, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [175/1500], Training Loss: 0.9331, Validation Loss: 2.9986, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [176/1500], Training Loss: 0.8792, Validation Loss: 3.0133, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [177/1500], Training Loss: 0.8038, Validation Loss: 3.1379, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [178/1500], Training Loss: 0.8696, Validation Loss: 3.1986, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [179/1500], Training Loss: 0.8177, Validation Loss: 3.1890, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [180/1500], Training Loss: 0.8261, Validation Loss: 3.2763, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [181/1500], Training Loss: 0.8427, Validation Loss: 3.1762, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [182/1500], Training Loss: 0.7691, Validation Loss: 3.2314, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [183/1500], Training Loss: 0.8342, Validation Loss: 3.2261, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [184/1500], Training Loss: 0.7498, Validation Loss: 3.4951, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [185/1500], Training Loss: 0.8295, Validation Loss: 3.1632, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [186/1500], Training Loss: 0.7210, Validation Loss: 3.3564, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [187/1500], Training Loss: 0.7967, Validation Loss: 3.3260, Validation Accuracy: 0.3892, Percentage:38.9216%\n",
            "Epoch [188/1500], Training Loss: 0.7187, Validation Loss: 3.2461, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [189/1500], Training Loss: 0.7124, Validation Loss: 3.2989, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [190/1500], Training Loss: 0.7269, Validation Loss: 3.3724, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [191/1500], Training Loss: 0.8564, Validation Loss: 3.1730, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [192/1500], Training Loss: 0.8086, Validation Loss: 3.2216, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [193/1500], Training Loss: 0.7513, Validation Loss: 3.1114, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [194/1500], Training Loss: 0.7685, Validation Loss: 3.1651, Validation Accuracy: 0.3912, Percentage:39.1176%\n",
            "Epoch [195/1500], Training Loss: 0.8129, Validation Loss: 3.3391, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [196/1500], Training Loss: 0.7685, Validation Loss: 3.1639, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [197/1500], Training Loss: 0.8235, Validation Loss: 3.1854, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [198/1500], Training Loss: 0.7108, Validation Loss: 3.3259, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [199/1500], Training Loss: 0.7319, Validation Loss: 3.3578, Validation Accuracy: 0.3882, Percentage:38.8235%\n",
            "Epoch [200/1500], Training Loss: 0.7317, Validation Loss: 3.3936, Validation Accuracy: 0.3843, Percentage:38.4314%\n",
            "Epoch [201/1500], Training Loss: 0.8364, Validation Loss: 3.4185, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [202/1500], Training Loss: 0.7105, Validation Loss: 3.3534, Validation Accuracy: 0.3902, Percentage:39.0196%\n",
            "Epoch [203/1500], Training Loss: 0.7885, Validation Loss: 3.2527, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [204/1500], Training Loss: 0.7798, Validation Loss: 3.2091, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [205/1500], Training Loss: 0.7676, Validation Loss: 3.0251, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [206/1500], Training Loss: 0.7074, Validation Loss: 3.3228, Validation Accuracy: 0.3892, Percentage:38.9216%\n",
            "Epoch [207/1500], Training Loss: 0.7699, Validation Loss: 3.3936, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [208/1500], Training Loss: 0.7526, Validation Loss: 3.1469, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [209/1500], Training Loss: 0.7219, Validation Loss: 3.2152, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [210/1500], Training Loss: 0.7458, Validation Loss: 3.3040, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [211/1500], Training Loss: 0.7650, Validation Loss: 3.1208, Validation Accuracy: 0.3882, Percentage:38.8235%\n",
            "Epoch [212/1500], Training Loss: 0.8060, Validation Loss: 3.1608, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [213/1500], Training Loss: 0.7125, Validation Loss: 3.1597, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [214/1500], Training Loss: 0.6351, Validation Loss: 3.2753, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [215/1500], Training Loss: 0.6649, Validation Loss: 3.2088, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [216/1500], Training Loss: 0.7651, Validation Loss: 3.2054, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [217/1500], Training Loss: 0.6547, Validation Loss: 3.1620, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [218/1500], Training Loss: 0.6320, Validation Loss: 3.1890, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [219/1500], Training Loss: 0.7174, Validation Loss: 3.3004, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [220/1500], Training Loss: 0.7797, Validation Loss: 3.3519, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [221/1500], Training Loss: 0.7125, Validation Loss: 3.2711, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [222/1500], Training Loss: 0.6976, Validation Loss: 3.4222, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [223/1500], Training Loss: 0.6303, Validation Loss: 3.2479, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [224/1500], Training Loss: 0.8348, Validation Loss: 3.0701, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [225/1500], Training Loss: 0.7108, Validation Loss: 3.3390, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [226/1500], Training Loss: 0.6511, Validation Loss: 3.3110, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [227/1500], Training Loss: 0.6607, Validation Loss: 3.2696, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [228/1500], Training Loss: 0.6851, Validation Loss: 3.3736, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [229/1500], Training Loss: 0.7013, Validation Loss: 3.3387, Validation Accuracy: 0.3794, Percentage:37.9412%\n",
            "Epoch [230/1500], Training Loss: 0.6630, Validation Loss: 3.3937, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [231/1500], Training Loss: 0.6944, Validation Loss: 3.3842, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [232/1500], Training Loss: 0.7136, Validation Loss: 3.1054, Validation Accuracy: 0.4206, Percentage:42.0588%\n",
            "Epoch [233/1500], Training Loss: 0.7316, Validation Loss: 3.4080, Validation Accuracy: 0.3843, Percentage:38.4314%\n",
            "Epoch [234/1500], Training Loss: 0.6589, Validation Loss: 3.2867, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [235/1500], Training Loss: 0.6894, Validation Loss: 3.4032, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [236/1500], Training Loss: 0.7665, Validation Loss: 3.3348, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [237/1500], Training Loss: 0.6918, Validation Loss: 3.4286, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [238/1500], Training Loss: 0.6324, Validation Loss: 3.4294, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [239/1500], Training Loss: 0.7377, Validation Loss: 3.1790, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [240/1500], Training Loss: 0.7221, Validation Loss: 3.5372, Validation Accuracy: 0.3912, Percentage:39.1176%\n",
            "Epoch [241/1500], Training Loss: 0.7072, Validation Loss: 3.3702, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [242/1500], Training Loss: 0.7329, Validation Loss: 3.3511, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [243/1500], Training Loss: 0.6895, Validation Loss: 3.5726, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [244/1500], Training Loss: 0.6028, Validation Loss: 3.4018, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [245/1500], Training Loss: 0.5749, Validation Loss: 3.4758, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [246/1500], Training Loss: 0.5926, Validation Loss: 3.3290, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [247/1500], Training Loss: 0.5898, Validation Loss: 3.3604, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [248/1500], Training Loss: 0.6537, Validation Loss: 3.4390, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [249/1500], Training Loss: 0.6044, Validation Loss: 3.2903, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [250/1500], Training Loss: 0.6555, Validation Loss: 3.4131, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [251/1500], Training Loss: 0.7194, Validation Loss: 3.2386, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [252/1500], Training Loss: 0.5635, Validation Loss: 3.4318, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [253/1500], Training Loss: 0.6588, Validation Loss: 3.3567, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [254/1500], Training Loss: 0.5760, Validation Loss: 3.4693, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [255/1500], Training Loss: 0.6313, Validation Loss: 3.5227, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [256/1500], Training Loss: 0.6131, Validation Loss: 3.4552, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [257/1500], Training Loss: 0.5847, Validation Loss: 3.5116, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [258/1500], Training Loss: 0.6316, Validation Loss: 3.3345, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [259/1500], Training Loss: 0.6164, Validation Loss: 3.4712, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [260/1500], Training Loss: 0.6635, Validation Loss: 3.5132, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [261/1500], Training Loss: 0.5677, Validation Loss: 3.4074, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [262/1500], Training Loss: 0.6666, Validation Loss: 3.4058, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [263/1500], Training Loss: 0.6801, Validation Loss: 3.3454, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [264/1500], Training Loss: 0.5754, Validation Loss: 3.4678, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [265/1500], Training Loss: 0.6096, Validation Loss: 3.3736, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [266/1500], Training Loss: 0.6173, Validation Loss: 3.4722, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [267/1500], Training Loss: 0.6490, Validation Loss: 3.4188, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [268/1500], Training Loss: 0.6772, Validation Loss: 3.3345, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [269/1500], Training Loss: 0.6271, Validation Loss: 3.4341, Validation Accuracy: 0.4176, Percentage:41.7647%\n",
            "Epoch [270/1500], Training Loss: 0.6134, Validation Loss: 3.5117, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [271/1500], Training Loss: 0.6332, Validation Loss: 3.4756, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [272/1500], Training Loss: 0.6116, Validation Loss: 3.3890, Validation Accuracy: 0.4206, Percentage:42.0588%\n",
            "Epoch [273/1500], Training Loss: 0.5845, Validation Loss: 3.3853, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [274/1500], Training Loss: 0.5393, Validation Loss: 3.6493, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [275/1500], Training Loss: 0.5394, Validation Loss: 3.9377, Validation Accuracy: 0.3804, Percentage:38.0392%\n",
            "Epoch [276/1500], Training Loss: 0.5893, Validation Loss: 3.6292, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [277/1500], Training Loss: 0.6594, Validation Loss: 3.2903, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [278/1500], Training Loss: 0.5438, Validation Loss: 3.7472, Validation Accuracy: 0.3863, Percentage:38.6275%\n",
            "Epoch [279/1500], Training Loss: 0.5409, Validation Loss: 3.3134, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [280/1500], Training Loss: 0.5684, Validation Loss: 3.5971, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [281/1500], Training Loss: 0.5935, Validation Loss: 3.4831, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [282/1500], Training Loss: 0.5613, Validation Loss: 3.3347, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [283/1500], Training Loss: 0.5456, Validation Loss: 3.5081, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [284/1500], Training Loss: 0.5235, Validation Loss: 3.3172, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [285/1500], Training Loss: 0.5759, Validation Loss: 3.6647, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [286/1500], Training Loss: 0.5272, Validation Loss: 3.5354, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [287/1500], Training Loss: 0.5572, Validation Loss: 3.6351, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [288/1500], Training Loss: 0.5937, Validation Loss: 3.4321, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [289/1500], Training Loss: 0.5982, Validation Loss: 3.3232, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [290/1500], Training Loss: 0.4825, Validation Loss: 3.7239, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [291/1500], Training Loss: 0.5837, Validation Loss: 3.3335, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [292/1500], Training Loss: 0.5324, Validation Loss: 3.5734, Validation Accuracy: 0.3853, Percentage:38.5294%\n",
            "Epoch [293/1500], Training Loss: 0.5639, Validation Loss: 3.4630, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [294/1500], Training Loss: 0.5282, Validation Loss: 3.4463, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [295/1500], Training Loss: 0.5525, Validation Loss: 3.3659, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [296/1500], Training Loss: 0.4854, Validation Loss: 3.3758, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [297/1500], Training Loss: 0.6073, Validation Loss: 3.5096, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [298/1500], Training Loss: 0.5726, Validation Loss: 3.6641, Validation Accuracy: 0.3863, Percentage:38.6275%\n",
            "Epoch [299/1500], Training Loss: 0.5395, Validation Loss: 3.7100, Validation Accuracy: 0.3863, Percentage:38.6275%\n",
            "Epoch [300/1500], Training Loss: 0.5297, Validation Loss: 3.6510, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [301/1500], Training Loss: 0.5744, Validation Loss: 3.4527, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [302/1500], Training Loss: 0.5222, Validation Loss: 3.5115, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [303/1500], Training Loss: 0.5477, Validation Loss: 3.6395, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [304/1500], Training Loss: 0.5565, Validation Loss: 3.4450, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [305/1500], Training Loss: 0.5519, Validation Loss: 3.3255, Validation Accuracy: 0.4176, Percentage:41.7647%\n",
            "Epoch [306/1500], Training Loss: 0.5058, Validation Loss: 3.5734, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [307/1500], Training Loss: 0.5131, Validation Loss: 3.5868, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [308/1500], Training Loss: 0.5364, Validation Loss: 3.3625, Validation Accuracy: 0.4618, Percentage:46.1765%\n",
            "Epoch [309/1500], Training Loss: 0.5051, Validation Loss: 3.5575, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [310/1500], Training Loss: 0.5545, Validation Loss: 3.4383, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [311/1500], Training Loss: 0.5424, Validation Loss: 3.3663, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [312/1500], Training Loss: 0.5816, Validation Loss: 3.5113, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [313/1500], Training Loss: 0.4692, Validation Loss: 3.5361, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [314/1500], Training Loss: 0.5877, Validation Loss: 3.5813, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [315/1500], Training Loss: 0.4570, Validation Loss: 3.7464, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [316/1500], Training Loss: 0.5535, Validation Loss: 3.6347, Validation Accuracy: 0.4176, Percentage:41.7647%\n",
            "Epoch [317/1500], Training Loss: 0.5879, Validation Loss: 3.6247, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [318/1500], Training Loss: 0.5633, Validation Loss: 3.4789, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [319/1500], Training Loss: 0.5192, Validation Loss: 3.5106, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [320/1500], Training Loss: 0.5280, Validation Loss: 3.5938, Validation Accuracy: 0.4225, Percentage:42.2549%\n",
            "Epoch [321/1500], Training Loss: 0.5381, Validation Loss: 3.4513, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [322/1500], Training Loss: 0.4995, Validation Loss: 3.5559, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [323/1500], Training Loss: 0.5185, Validation Loss: 3.5018, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [324/1500], Training Loss: 0.4765, Validation Loss: 3.6271, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [325/1500], Training Loss: 0.4827, Validation Loss: 3.5522, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [326/1500], Training Loss: 0.4701, Validation Loss: 3.4459, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [327/1500], Training Loss: 0.4928, Validation Loss: 3.5176, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [328/1500], Training Loss: 0.4041, Validation Loss: 3.6383, Validation Accuracy: 0.4206, Percentage:42.0588%\n",
            "Epoch [329/1500], Training Loss: 0.4762, Validation Loss: 3.7249, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [330/1500], Training Loss: 0.4938, Validation Loss: 3.6546, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [331/1500], Training Loss: 0.4891, Validation Loss: 3.4732, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [332/1500], Training Loss: 0.4855, Validation Loss: 3.7932, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [333/1500], Training Loss: 0.5150, Validation Loss: 3.6972, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [334/1500], Training Loss: 0.5204, Validation Loss: 3.5689, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [335/1500], Training Loss: 0.5500, Validation Loss: 3.4438, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [336/1500], Training Loss: 0.4724, Validation Loss: 3.6296, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [337/1500], Training Loss: 0.4364, Validation Loss: 3.8766, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [338/1500], Training Loss: 0.4919, Validation Loss: 3.5771, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [339/1500], Training Loss: 0.4737, Validation Loss: 3.8068, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [340/1500], Training Loss: 0.5047, Validation Loss: 3.6312, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [341/1500], Training Loss: 0.4901, Validation Loss: 3.7174, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [342/1500], Training Loss: 0.5485, Validation Loss: 3.6557, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [343/1500], Training Loss: 0.5448, Validation Loss: 3.6202, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [344/1500], Training Loss: 0.4785, Validation Loss: 3.9259, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [345/1500], Training Loss: 0.4335, Validation Loss: 3.7700, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [346/1500], Training Loss: 0.4944, Validation Loss: 3.6383, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [347/1500], Training Loss: 0.4681, Validation Loss: 3.7345, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [348/1500], Training Loss: 0.4491, Validation Loss: 3.8308, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [349/1500], Training Loss: 0.4655, Validation Loss: 3.7987, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [350/1500], Training Loss: 0.4636, Validation Loss: 3.6546, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [351/1500], Training Loss: 0.4886, Validation Loss: 3.6664, Validation Accuracy: 0.4206, Percentage:42.0588%\n",
            "Epoch [352/1500], Training Loss: 0.5356, Validation Loss: 3.4430, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [353/1500], Training Loss: 0.5497, Validation Loss: 3.4820, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [354/1500], Training Loss: 0.4180, Validation Loss: 3.9045, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [355/1500], Training Loss: 0.4920, Validation Loss: 3.3855, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [356/1500], Training Loss: 0.4814, Validation Loss: 3.6713, Validation Accuracy: 0.4284, Percentage:42.8431%\n",
            "Epoch [357/1500], Training Loss: 0.4521, Validation Loss: 3.5853, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [358/1500], Training Loss: 0.4944, Validation Loss: 3.4806, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [359/1500], Training Loss: 0.5208, Validation Loss: 3.5303, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [360/1500], Training Loss: 0.4285, Validation Loss: 3.6655, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [361/1500], Training Loss: 0.4759, Validation Loss: 3.6800, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [362/1500], Training Loss: 0.5052, Validation Loss: 3.5006, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [363/1500], Training Loss: 0.4446, Validation Loss: 3.6257, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [364/1500], Training Loss: 0.4387, Validation Loss: 3.6018, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [365/1500], Training Loss: 0.4129, Validation Loss: 3.8354, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [366/1500], Training Loss: 0.4915, Validation Loss: 3.6706, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [367/1500], Training Loss: 0.4858, Validation Loss: 3.5054, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [368/1500], Training Loss: 0.3850, Validation Loss: 3.4889, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [369/1500], Training Loss: 0.4446, Validation Loss: 3.8235, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [370/1500], Training Loss: 0.4980, Validation Loss: 3.8151, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [371/1500], Training Loss: 0.4835, Validation Loss: 3.5679, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [372/1500], Training Loss: 0.5087, Validation Loss: 3.6425, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [373/1500], Training Loss: 0.4901, Validation Loss: 3.4843, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [374/1500], Training Loss: 0.3897, Validation Loss: 3.7934, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [375/1500], Training Loss: 0.4397, Validation Loss: 3.6058, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [376/1500], Training Loss: 0.4761, Validation Loss: 3.6409, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [377/1500], Training Loss: 0.4280, Validation Loss: 3.6678, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [378/1500], Training Loss: 0.4367, Validation Loss: 3.6343, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [379/1500], Training Loss: 0.4232, Validation Loss: 3.7135, Validation Accuracy: 0.4176, Percentage:41.7647%\n",
            "Epoch [380/1500], Training Loss: 0.5079, Validation Loss: 3.5912, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [381/1500], Training Loss: 0.4768, Validation Loss: 3.7303, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [382/1500], Training Loss: 0.4776, Validation Loss: 3.4889, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [383/1500], Training Loss: 0.4455, Validation Loss: 3.6874, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [384/1500], Training Loss: 0.4507, Validation Loss: 3.8598, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [385/1500], Training Loss: 0.4514, Validation Loss: 3.6958, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [386/1500], Training Loss: 0.4365, Validation Loss: 3.5220, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [387/1500], Training Loss: 0.3932, Validation Loss: 3.8958, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [388/1500], Training Loss: 0.3683, Validation Loss: 3.5348, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [389/1500], Training Loss: 0.3900, Validation Loss: 3.8780, Validation Accuracy: 0.4284, Percentage:42.8431%\n",
            "Epoch [390/1500], Training Loss: 0.4009, Validation Loss: 3.8962, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [391/1500], Training Loss: 0.4324, Validation Loss: 3.7059, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [392/1500], Training Loss: 0.5143, Validation Loss: 3.4931, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [393/1500], Training Loss: 0.4272, Validation Loss: 3.8723, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [394/1500], Training Loss: 0.3372, Validation Loss: 3.7005, Validation Accuracy: 0.4265, Percentage:42.6471%\n",
            "Epoch [395/1500], Training Loss: 0.4314, Validation Loss: 3.4427, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [396/1500], Training Loss: 0.4090, Validation Loss: 3.7111, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [397/1500], Training Loss: 0.4494, Validation Loss: 3.9364, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [398/1500], Training Loss: 0.3710, Validation Loss: 4.0079, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [399/1500], Training Loss: 0.4090, Validation Loss: 3.7569, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [400/1500], Training Loss: 0.3594, Validation Loss: 3.7752, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [401/1500], Training Loss: 0.3938, Validation Loss: 3.9803, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [402/1500], Training Loss: 0.4081, Validation Loss: 4.0653, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [403/1500], Training Loss: 0.3852, Validation Loss: 3.8768, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [404/1500], Training Loss: 0.4274, Validation Loss: 3.9694, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [405/1500], Training Loss: 0.5072, Validation Loss: 3.7656, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [406/1500], Training Loss: 0.4819, Validation Loss: 3.7487, Validation Accuracy: 0.4176, Percentage:41.7647%\n",
            "Epoch [407/1500], Training Loss: 0.4356, Validation Loss: 3.9378, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [408/1500], Training Loss: 0.4207, Validation Loss: 3.6851, Validation Accuracy: 0.4225, Percentage:42.2549%\n",
            "Epoch [409/1500], Training Loss: 0.4511, Validation Loss: 3.7875, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [410/1500], Training Loss: 0.4102, Validation Loss: 3.6635, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [411/1500], Training Loss: 0.3963, Validation Loss: 3.9010, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [412/1500], Training Loss: 0.4494, Validation Loss: 3.7020, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [413/1500], Training Loss: 0.3857, Validation Loss: 3.7330, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [414/1500], Training Loss: 0.3984, Validation Loss: 3.7108, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [415/1500], Training Loss: 0.4133, Validation Loss: 3.6597, Validation Accuracy: 0.4265, Percentage:42.6471%\n",
            "Epoch [416/1500], Training Loss: 0.3545, Validation Loss: 3.7099, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [417/1500], Training Loss: 0.3878, Validation Loss: 3.7989, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [418/1500], Training Loss: 0.4222, Validation Loss: 3.5871, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [419/1500], Training Loss: 0.3986, Validation Loss: 3.7736, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [420/1500], Training Loss: 0.3704, Validation Loss: 3.9510, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [421/1500], Training Loss: 0.4565, Validation Loss: 3.9886, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [422/1500], Training Loss: 0.4189, Validation Loss: 3.6100, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [423/1500], Training Loss: 0.4288, Validation Loss: 3.4885, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [424/1500], Training Loss: 0.3908, Validation Loss: 4.1500, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [425/1500], Training Loss: 0.3787, Validation Loss: 4.2556, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [426/1500], Training Loss: 0.4441, Validation Loss: 3.7252, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [427/1500], Training Loss: 0.3925, Validation Loss: 3.8952, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [428/1500], Training Loss: 0.4069, Validation Loss: 3.7211, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [429/1500], Training Loss: 0.4103, Validation Loss: 3.6720, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [430/1500], Training Loss: 0.3994, Validation Loss: 3.8723, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [431/1500], Training Loss: 0.3631, Validation Loss: 3.7709, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [432/1500], Training Loss: 0.4251, Validation Loss: 3.8963, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [433/1500], Training Loss: 0.4605, Validation Loss: 3.6989, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [434/1500], Training Loss: 0.3838, Validation Loss: 4.0275, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [435/1500], Training Loss: 0.4486, Validation Loss: 3.6542, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [436/1500], Training Loss: 0.3923, Validation Loss: 3.5831, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [437/1500], Training Loss: 0.3828, Validation Loss: 3.6560, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [438/1500], Training Loss: 0.3222, Validation Loss: 3.7646, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [439/1500], Training Loss: 0.3853, Validation Loss: 4.2174, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [440/1500], Training Loss: 0.3805, Validation Loss: 3.8474, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [441/1500], Training Loss: 0.3844, Validation Loss: 4.0161, Validation Accuracy: 0.4206, Percentage:42.0588%\n",
            "Epoch [442/1500], Training Loss: 0.3818, Validation Loss: 3.8158, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [443/1500], Training Loss: 0.3756, Validation Loss: 4.0331, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [444/1500], Training Loss: 0.4272, Validation Loss: 3.6107, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [445/1500], Training Loss: 0.3872, Validation Loss: 3.7467, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [446/1500], Training Loss: 0.3731, Validation Loss: 3.8064, Validation Accuracy: 0.4284, Percentage:42.8431%\n",
            "Epoch [447/1500], Training Loss: 0.3612, Validation Loss: 3.8613, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [448/1500], Training Loss: 0.3444, Validation Loss: 3.9439, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [449/1500], Training Loss: 0.3433, Validation Loss: 3.6683, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [450/1500], Training Loss: 0.4230, Validation Loss: 3.8726, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [451/1500], Training Loss: 0.4100, Validation Loss: 3.6101, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [452/1500], Training Loss: 0.4324, Validation Loss: 3.7069, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [453/1500], Training Loss: 0.4007, Validation Loss: 3.7791, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [454/1500], Training Loss: 0.3557, Validation Loss: 4.0655, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [455/1500], Training Loss: 0.3916, Validation Loss: 3.7514, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [456/1500], Training Loss: 0.4026, Validation Loss: 3.8295, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [457/1500], Training Loss: 0.4045, Validation Loss: 3.6936, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [458/1500], Training Loss: 0.4234, Validation Loss: 3.4980, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [459/1500], Training Loss: 0.4090, Validation Loss: 3.7629, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [460/1500], Training Loss: 0.3402, Validation Loss: 3.7045, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [461/1500], Training Loss: 0.3797, Validation Loss: 3.7118, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [462/1500], Training Loss: 0.4341, Validation Loss: 3.6273, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [463/1500], Training Loss: 0.3623, Validation Loss: 3.8651, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [464/1500], Training Loss: 0.3444, Validation Loss: 3.7898, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [465/1500], Training Loss: 0.3327, Validation Loss: 3.8478, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [466/1500], Training Loss: 0.3696, Validation Loss: 3.8443, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [467/1500], Training Loss: 0.3338, Validation Loss: 3.8403, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [468/1500], Training Loss: 0.3594, Validation Loss: 3.7521, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [469/1500], Training Loss: 0.3537, Validation Loss: 3.8943, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [470/1500], Training Loss: 0.3385, Validation Loss: 4.0836, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [471/1500], Training Loss: 0.2877, Validation Loss: 4.0188, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [472/1500], Training Loss: 0.4369, Validation Loss: 3.7494, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [473/1500], Training Loss: 0.3667, Validation Loss: 4.0263, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [474/1500], Training Loss: 0.3815, Validation Loss: 3.7193, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [475/1500], Training Loss: 0.3505, Validation Loss: 3.7692, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [476/1500], Training Loss: 0.3878, Validation Loss: 3.6539, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [477/1500], Training Loss: 0.3228, Validation Loss: 4.0225, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [478/1500], Training Loss: 0.4011, Validation Loss: 3.8579, Validation Accuracy: 0.4265, Percentage:42.6471%\n",
            "Epoch [479/1500], Training Loss: 0.3652, Validation Loss: 3.9240, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [480/1500], Training Loss: 0.3743, Validation Loss: 4.1723, Validation Accuracy: 0.4206, Percentage:42.0588%\n",
            "Epoch [481/1500], Training Loss: 0.3916, Validation Loss: 4.2027, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [482/1500], Training Loss: 0.3870, Validation Loss: 3.8860, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [483/1500], Training Loss: 0.4244, Validation Loss: 3.9336, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [484/1500], Training Loss: 0.4271, Validation Loss: 3.7649, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [485/1500], Training Loss: 0.3639, Validation Loss: 3.9365, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [486/1500], Training Loss: 0.3671, Validation Loss: 3.5856, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [487/1500], Training Loss: 0.3606, Validation Loss: 3.9740, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [488/1500], Training Loss: 0.3521, Validation Loss: 3.8300, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [489/1500], Training Loss: 0.2962, Validation Loss: 3.9810, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [490/1500], Training Loss: 0.3360, Validation Loss: 4.1914, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [491/1500], Training Loss: 0.3234, Validation Loss: 4.1673, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [492/1500], Training Loss: 0.3606, Validation Loss: 3.8951, Validation Accuracy: 0.4225, Percentage:42.2549%\n",
            "Epoch [493/1500], Training Loss: 0.4538, Validation Loss: 3.7955, Validation Accuracy: 0.4265, Percentage:42.6471%\n",
            "Epoch [494/1500], Training Loss: 0.3599, Validation Loss: 3.8811, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [495/1500], Training Loss: 0.3748, Validation Loss: 3.7199, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [496/1500], Training Loss: 0.3412, Validation Loss: 3.8348, Validation Accuracy: 0.4206, Percentage:42.0588%\n",
            "Epoch [497/1500], Training Loss: 0.3534, Validation Loss: 3.7558, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [498/1500], Training Loss: 0.3746, Validation Loss: 3.7958, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [499/1500], Training Loss: 0.3375, Validation Loss: 3.7632, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [500/1500], Training Loss: 0.3319, Validation Loss: 3.8142, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [501/1500], Training Loss: 0.3521, Validation Loss: 3.8258, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [502/1500], Training Loss: 0.3371, Validation Loss: 4.0458, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [503/1500], Training Loss: 0.2863, Validation Loss: 4.1914, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [504/1500], Training Loss: 0.3270, Validation Loss: 4.3514, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [505/1500], Training Loss: 0.3388, Validation Loss: 3.8829, Validation Accuracy: 0.4284, Percentage:42.8431%\n",
            "Epoch [506/1500], Training Loss: 0.3092, Validation Loss: 4.1112, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [507/1500], Training Loss: 0.3430, Validation Loss: 3.6337, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [508/1500], Training Loss: 0.3543, Validation Loss: 4.0277, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [509/1500], Training Loss: 0.2941, Validation Loss: 4.2080, Validation Accuracy: 0.4284, Percentage:42.8431%\n",
            "Epoch [510/1500], Training Loss: 0.3531, Validation Loss: 3.9487, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [511/1500], Training Loss: 0.3486, Validation Loss: 3.7840, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [512/1500], Training Loss: 0.3280, Validation Loss: 3.9256, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [513/1500], Training Loss: 0.3168, Validation Loss: 4.2067, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [514/1500], Training Loss: 0.3627, Validation Loss: 3.8630, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [515/1500], Training Loss: 0.4055, Validation Loss: 3.6212, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [516/1500], Training Loss: 0.3710, Validation Loss: 4.0660, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [517/1500], Training Loss: 0.3220, Validation Loss: 3.9498, Validation Accuracy: 0.4265, Percentage:42.6471%\n",
            "Epoch [518/1500], Training Loss: 0.3130, Validation Loss: 4.0195, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [519/1500], Training Loss: 0.3576, Validation Loss: 4.0610, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [520/1500], Training Loss: 0.3635, Validation Loss: 3.8351, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [521/1500], Training Loss: 0.3037, Validation Loss: 4.2200, Validation Accuracy: 0.4176, Percentage:41.7647%\n",
            "Epoch [522/1500], Training Loss: 0.3522, Validation Loss: 3.9221, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [523/1500], Training Loss: 0.3118, Validation Loss: 3.8704, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [524/1500], Training Loss: 0.3367, Validation Loss: 3.8029, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [525/1500], Training Loss: 0.3141, Validation Loss: 3.8990, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [526/1500], Training Loss: 0.3530, Validation Loss: 3.9849, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [527/1500], Training Loss: 0.3239, Validation Loss: 4.0719, Validation Accuracy: 0.4265, Percentage:42.6471%\n",
            "Epoch [528/1500], Training Loss: 0.3214, Validation Loss: 4.1258, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [529/1500], Training Loss: 0.3192, Validation Loss: 4.0644, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [530/1500], Training Loss: 0.3676, Validation Loss: 4.0573, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [531/1500], Training Loss: 0.3335, Validation Loss: 4.1046, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [532/1500], Training Loss: 0.3193, Validation Loss: 4.1235, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [533/1500], Training Loss: 0.3648, Validation Loss: 4.3983, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [534/1500], Training Loss: 0.2823, Validation Loss: 4.1684, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [535/1500], Training Loss: 0.3547, Validation Loss: 4.1358, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [536/1500], Training Loss: 0.3575, Validation Loss: 4.2078, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [537/1500], Training Loss: 0.3587, Validation Loss: 3.8555, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [538/1500], Training Loss: 0.3244, Validation Loss: 3.8978, Validation Accuracy: 0.4284, Percentage:42.8431%\n",
            "Epoch [539/1500], Training Loss: 0.3116, Validation Loss: 4.0521, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [540/1500], Training Loss: 0.3176, Validation Loss: 3.9871, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [541/1500], Training Loss: 0.2838, Validation Loss: 4.1311, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [542/1500], Training Loss: 0.3821, Validation Loss: 3.8161, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [543/1500], Training Loss: 0.3489, Validation Loss: 3.8503, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [544/1500], Training Loss: 0.3519, Validation Loss: 4.0476, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [545/1500], Training Loss: 0.3038, Validation Loss: 4.0246, Validation Accuracy: 0.4578, Percentage:45.7843%\n",
            "Epoch [546/1500], Training Loss: 0.2870, Validation Loss: 4.2079, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [547/1500], Training Loss: 0.2856, Validation Loss: 4.0444, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [548/1500], Training Loss: 0.3485, Validation Loss: 4.0799, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [549/1500], Training Loss: 0.3616, Validation Loss: 4.0562, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [550/1500], Training Loss: 0.3638, Validation Loss: 3.9175, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [551/1500], Training Loss: 0.3226, Validation Loss: 3.9511, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [552/1500], Training Loss: 0.3229, Validation Loss: 4.1107, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [553/1500], Training Loss: 0.3180, Validation Loss: 4.1028, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [554/1500], Training Loss: 0.3306, Validation Loss: 3.8615, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [555/1500], Training Loss: 0.3260, Validation Loss: 3.9693, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [556/1500], Training Loss: 0.2989, Validation Loss: 4.1301, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [557/1500], Training Loss: 0.3640, Validation Loss: 3.9113, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [558/1500], Training Loss: 0.3061, Validation Loss: 4.0658, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [559/1500], Training Loss: 0.2926, Validation Loss: 3.7309, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [560/1500], Training Loss: 0.3036, Validation Loss: 3.7782, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [561/1500], Training Loss: 0.3516, Validation Loss: 3.9742, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [562/1500], Training Loss: 0.3164, Validation Loss: 3.9626, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [563/1500], Training Loss: 0.2926, Validation Loss: 3.9226, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [564/1500], Training Loss: 0.2915, Validation Loss: 4.0869, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [565/1500], Training Loss: 0.3984, Validation Loss: 3.9851, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [566/1500], Training Loss: 0.3110, Validation Loss: 4.1957, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [567/1500], Training Loss: 0.3206, Validation Loss: 4.0322, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [568/1500], Training Loss: 0.3166, Validation Loss: 4.0315, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [569/1500], Training Loss: 0.2991, Validation Loss: 4.0403, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [570/1500], Training Loss: 0.3997, Validation Loss: 4.0741, Validation Accuracy: 0.4225, Percentage:42.2549%\n",
            "Epoch [571/1500], Training Loss: 0.2619, Validation Loss: 4.3150, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [572/1500], Training Loss: 0.3389, Validation Loss: 4.0301, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [573/1500], Training Loss: 0.3196, Validation Loss: 4.3224, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [574/1500], Training Loss: 0.3331, Validation Loss: 3.8939, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [575/1500], Training Loss: 0.3449, Validation Loss: 3.8881, Validation Accuracy: 0.4578, Percentage:45.7843%\n",
            "Epoch [576/1500], Training Loss: 0.3265, Validation Loss: 3.9321, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [577/1500], Training Loss: 0.2629, Validation Loss: 3.8959, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [578/1500], Training Loss: 0.2971, Validation Loss: 3.9050, Validation Accuracy: 0.4667, Percentage:46.6667%\n",
            "Epoch [579/1500], Training Loss: 0.3448, Validation Loss: 3.9803, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [580/1500], Training Loss: 0.2787, Validation Loss: 3.9568, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [581/1500], Training Loss: 0.3002, Validation Loss: 4.0162, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [582/1500], Training Loss: 0.2920, Validation Loss: 4.0324, Validation Accuracy: 0.4618, Percentage:46.1765%\n",
            "Epoch [583/1500], Training Loss: 0.2996, Validation Loss: 3.9054, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [584/1500], Training Loss: 0.3170, Validation Loss: 4.0040, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [585/1500], Training Loss: 0.2830, Validation Loss: 4.2930, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [586/1500], Training Loss: 0.3382, Validation Loss: 4.6230, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [587/1500], Training Loss: 0.2745, Validation Loss: 3.9709, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [588/1500], Training Loss: 0.2601, Validation Loss: 4.2462, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [589/1500], Training Loss: 0.3199, Validation Loss: 4.0347, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [590/1500], Training Loss: 0.3102, Validation Loss: 3.6768, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [591/1500], Training Loss: 0.3334, Validation Loss: 3.8854, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [592/1500], Training Loss: 0.3369, Validation Loss: 3.9664, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [593/1500], Training Loss: 0.3529, Validation Loss: 3.8246, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [594/1500], Training Loss: 0.2299, Validation Loss: 4.0397, Validation Accuracy: 0.4265, Percentage:42.6471%\n",
            "Epoch [595/1500], Training Loss: 0.2917, Validation Loss: 4.2108, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [596/1500], Training Loss: 0.3314, Validation Loss: 4.0649, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [597/1500], Training Loss: 0.2914, Validation Loss: 4.5073, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [598/1500], Training Loss: 0.2886, Validation Loss: 4.2910, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [599/1500], Training Loss: 0.2828, Validation Loss: 4.1139, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [600/1500], Training Loss: 0.3390, Validation Loss: 3.9258, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [601/1500], Training Loss: 0.3322, Validation Loss: 3.9161, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [602/1500], Training Loss: 0.2900, Validation Loss: 3.9643, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [603/1500], Training Loss: 0.3321, Validation Loss: 3.9801, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [604/1500], Training Loss: 0.2733, Validation Loss: 4.1566, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [605/1500], Training Loss: 0.3349, Validation Loss: 4.4574, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [606/1500], Training Loss: 0.2752, Validation Loss: 4.2379, Validation Accuracy: 0.4284, Percentage:42.8431%\n",
            "Epoch [607/1500], Training Loss: 0.3193, Validation Loss: 4.0300, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [608/1500], Training Loss: 0.2459, Validation Loss: 4.3407, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [609/1500], Training Loss: 0.2727, Validation Loss: 4.2218, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [610/1500], Training Loss: 0.3214, Validation Loss: 4.3068, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [611/1500], Training Loss: 0.2654, Validation Loss: 4.1926, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [612/1500], Training Loss: 0.3241, Validation Loss: 3.8332, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [613/1500], Training Loss: 0.2864, Validation Loss: 3.8532, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [614/1500], Training Loss: 0.3067, Validation Loss: 4.1548, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [615/1500], Training Loss: 0.3186, Validation Loss: 4.4473, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [616/1500], Training Loss: 0.3126, Validation Loss: 4.0972, Validation Accuracy: 0.4284, Percentage:42.8431%\n",
            "Epoch [617/1500], Training Loss: 0.3205, Validation Loss: 4.0607, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [618/1500], Training Loss: 0.2813, Validation Loss: 4.2271, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [619/1500], Training Loss: 0.3464, Validation Loss: 4.4789, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [620/1500], Training Loss: 0.2712, Validation Loss: 4.0595, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [621/1500], Training Loss: 0.3405, Validation Loss: 4.0798, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [622/1500], Training Loss: 0.3203, Validation Loss: 3.8773, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [623/1500], Training Loss: 0.3172, Validation Loss: 3.8179, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [624/1500], Training Loss: 0.3219, Validation Loss: 4.3646, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [625/1500], Training Loss: 0.2835, Validation Loss: 4.2633, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [626/1500], Training Loss: 0.2710, Validation Loss: 4.3093, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [627/1500], Training Loss: 0.3029, Validation Loss: 4.0640, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [628/1500], Training Loss: 0.2785, Validation Loss: 4.1523, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [629/1500], Training Loss: 0.3009, Validation Loss: 3.9802, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [630/1500], Training Loss: 0.2758, Validation Loss: 4.3451, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [631/1500], Training Loss: 0.3358, Validation Loss: 3.9894, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [632/1500], Training Loss: 0.3637, Validation Loss: 3.9316, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [633/1500], Training Loss: 0.2743, Validation Loss: 4.2806, Validation Accuracy: 0.4284, Percentage:42.8431%\n",
            "Epoch [634/1500], Training Loss: 0.2508, Validation Loss: 4.3831, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [635/1500], Training Loss: 0.2447, Validation Loss: 4.0750, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [636/1500], Training Loss: 0.2767, Validation Loss: 4.1985, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [637/1500], Training Loss: 0.2366, Validation Loss: 4.0782, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [638/1500], Training Loss: 0.2531, Validation Loss: 4.4185, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [639/1500], Training Loss: 0.3402, Validation Loss: 4.3446, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [640/1500], Training Loss: 0.2397, Validation Loss: 4.5202, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [641/1500], Training Loss: 0.3186, Validation Loss: 4.1135, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [642/1500], Training Loss: 0.3336, Validation Loss: 3.9810, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [643/1500], Training Loss: 0.2471, Validation Loss: 4.0536, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [644/1500], Training Loss: 0.2495, Validation Loss: 4.1751, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [645/1500], Training Loss: 0.2426, Validation Loss: 4.1004, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [646/1500], Training Loss: 0.2658, Validation Loss: 4.3895, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [647/1500], Training Loss: 0.2276, Validation Loss: 3.9702, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [648/1500], Training Loss: 0.2344, Validation Loss: 4.3374, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [649/1500], Training Loss: 0.2663, Validation Loss: 4.0244, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [650/1500], Training Loss: 0.2810, Validation Loss: 3.9883, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [651/1500], Training Loss: 0.3012, Validation Loss: 4.2134, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [652/1500], Training Loss: 0.2663, Validation Loss: 4.0543, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [653/1500], Training Loss: 0.2780, Validation Loss: 4.3143, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [654/1500], Training Loss: 0.2650, Validation Loss: 3.8969, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [655/1500], Training Loss: 0.3058, Validation Loss: 4.2879, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [656/1500], Training Loss: 0.2713, Validation Loss: 4.2614, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [657/1500], Training Loss: 0.2330, Validation Loss: 4.2519, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [658/1500], Training Loss: 0.2632, Validation Loss: 4.1163, Validation Accuracy: 0.4676, Percentage:46.7647%\n",
            "Epoch [659/1500], Training Loss: 0.3185, Validation Loss: 4.0091, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [660/1500], Training Loss: 0.3016, Validation Loss: 4.0437, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [661/1500], Training Loss: 0.2637, Validation Loss: 4.0362, Validation Accuracy: 0.4265, Percentage:42.6471%\n",
            "Epoch [662/1500], Training Loss: 0.3182, Validation Loss: 3.9795, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [663/1500], Training Loss: 0.2149, Validation Loss: 4.4918, Validation Accuracy: 0.4284, Percentage:42.8431%\n",
            "Epoch [664/1500], Training Loss: 0.2732, Validation Loss: 4.2031, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [665/1500], Training Loss: 0.3127, Validation Loss: 4.0705, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [666/1500], Training Loss: 0.2941, Validation Loss: 4.1566, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [667/1500], Training Loss: 0.2755, Validation Loss: 4.1992, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [668/1500], Training Loss: 0.2270, Validation Loss: 4.3703, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [669/1500], Training Loss: 0.2506, Validation Loss: 4.4365, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [670/1500], Training Loss: 0.2083, Validation Loss: 4.4850, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [671/1500], Training Loss: 0.2660, Validation Loss: 4.2517, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [672/1500], Training Loss: 0.2484, Validation Loss: 4.6424, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [673/1500], Training Loss: 0.3633, Validation Loss: 4.0783, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [674/1500], Training Loss: 0.2878, Validation Loss: 3.9180, Validation Accuracy: 0.4627, Percentage:46.2745%\n",
            "Epoch [675/1500], Training Loss: 0.2191, Validation Loss: 4.1759, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [676/1500], Training Loss: 0.2000, Validation Loss: 4.0849, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [677/1500], Training Loss: 0.2539, Validation Loss: 4.3119, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [678/1500], Training Loss: 0.2867, Validation Loss: 4.2179, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [679/1500], Training Loss: 0.2579, Validation Loss: 3.9838, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [680/1500], Training Loss: 0.3160, Validation Loss: 4.0739, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [681/1500], Training Loss: 0.2663, Validation Loss: 4.1363, Validation Accuracy: 0.4265, Percentage:42.6471%\n",
            "Epoch [682/1500], Training Loss: 0.2560, Validation Loss: 4.4038, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [683/1500], Training Loss: 0.2914, Validation Loss: 4.3025, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [684/1500], Training Loss: 0.2940, Validation Loss: 3.9468, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [685/1500], Training Loss: 0.2551, Validation Loss: 4.1057, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [686/1500], Training Loss: 0.2471, Validation Loss: 4.1684, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [687/1500], Training Loss: 0.2635, Validation Loss: 3.9787, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [688/1500], Training Loss: 0.2824, Validation Loss: 4.1854, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [689/1500], Training Loss: 0.2870, Validation Loss: 4.3836, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [690/1500], Training Loss: 0.2792, Validation Loss: 4.1851, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [691/1500], Training Loss: 0.2422, Validation Loss: 4.2313, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [692/1500], Training Loss: 0.2768, Validation Loss: 4.1634, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [693/1500], Training Loss: 0.2743, Validation Loss: 4.0478, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [694/1500], Training Loss: 0.3145, Validation Loss: 3.9465, Validation Accuracy: 0.4225, Percentage:42.2549%\n",
            "Epoch [695/1500], Training Loss: 0.2656, Validation Loss: 4.0298, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [696/1500], Training Loss: 0.2622, Validation Loss: 4.3491, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [697/1500], Training Loss: 0.3034, Validation Loss: 4.2144, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [698/1500], Training Loss: 0.3098, Validation Loss: 4.3136, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [699/1500], Training Loss: 0.2770, Validation Loss: 4.1950, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [700/1500], Training Loss: 0.2632, Validation Loss: 4.2642, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [701/1500], Training Loss: 0.2315, Validation Loss: 4.0610, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [702/1500], Training Loss: 0.2683, Validation Loss: 4.4411, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [703/1500], Training Loss: 0.3151, Validation Loss: 3.8893, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [704/1500], Training Loss: 0.2464, Validation Loss: 4.2249, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [705/1500], Training Loss: 0.2389, Validation Loss: 4.1548, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [706/1500], Training Loss: 0.3058, Validation Loss: 4.3185, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [707/1500], Training Loss: 0.2085, Validation Loss: 4.4213, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [708/1500], Training Loss: 0.2691, Validation Loss: 4.5269, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [709/1500], Training Loss: 0.2665, Validation Loss: 4.3121, Validation Accuracy: 0.4304, Percentage:43.0392%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1f4459f9886b>\u001b[0m in \u001b[0;36m<cell line: 104>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/flowers102.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    971\u001b[0m         \"\"\"\n\u001b[1;32m    972\u001b[0m         \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresized_crop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresized_crop\u001b[0;34m(img, top, left, height, width, size, interpolation, antialias)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresized_crop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Anti-alias option is always applied for PIL Image input. Argument antialias is ignored.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0mpil_interpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_modes_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpil_interpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_pil.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Got inappropriate size arg: {size}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2190\u001b[0m                 )\n\u001b[1;32m   2191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2192\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import Flowers102\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define transforms for data augmentation and normalization\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(500),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(500),\n",
        "    transforms.CenterCrop(500),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the dataset with train/val/test splits\n",
        "train_dataset = Flowers102(root='./data', split='train', transform=train_transform, download=True)\n",
        "val_dataset = Flowers102(root='./data', split='val', transform=val_transform, download=True)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Define data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "class CNN_NN(nn.Module):\n",
        "    def __init__(self, num_classes=102):\n",
        "        super(CNN_NN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv5= nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "        # Initialize the size of the fully connected layer based on the sample input\n",
        "        self._to_linear = None\n",
        "        self.convs = nn.Sequential(\n",
        "            self.conv1,\n",
        "            nn.ReLU(),\n",
        "            self.pool,\n",
        "            self.conv2,\n",
        "            nn.ReLU(),\n",
        "            self.pool,\n",
        "            self.conv3,\n",
        "            nn.ReLU(),\n",
        "            self.pool,\n",
        "            self.conv4,\n",
        "            nn.ReLU(),\n",
        "            self.pool,\n",
        "            self.conv5,\n",
        "            nn.ReLU(),\n",
        "            self.pool\n",
        "        )\n",
        "        self._initialize_linear_layer()\n",
        "\n",
        "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def _initialize_linear_layer(self):\n",
        "        # Create a dummy input tensor to calculate the output size after conv layers\n",
        "        x = torch.randn(1, 3, 500, 500)\n",
        "        x = self.convs(x)\n",
        "        self._to_linear = x.view(1, -1).shape[1]\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor while preserving the batch size\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Define the device (GPU or CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyperparameters\n",
        "num_classes = 102  # Number of output classes\n",
        "learning_rate = 0.0001\n",
        "num_epochs = 1500\n",
        "\n",
        "# Initialize the model\n",
        "model = CNN_NN(num_classes=num_classes).to(device)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "#Learning rate scheduler\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    # Calculate average loss for the epoch\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Calculate average validation loss and accuracy\n",
        "    val_loss = val_loss / len(val_loader.dataset)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "          f'Training Loss: {epoch_loss:.4f}, '\n",
        "          f'Validation Loss: {val_loss:.4f}, '\n",
        "          f'Validation Accuracy: {accuracy:.4f}, '\n",
        "          f'Percentage:{accuracy*100:.4f}%')\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "Q5b4VyuqPED_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1aec5209-b0de-4a4f-ee10-869e932db742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1500], Training Loss: 4.6240, Validation Loss: 4.5762, Validation Accuracy: 0.0324, Percentage:3.2353%\n",
            "Epoch [2/1500], Training Loss: 4.4547, Validation Loss: 4.2655, Validation Accuracy: 0.0490, Percentage:4.9020%\n",
            "Epoch [3/1500], Training Loss: 4.2319, Validation Loss: 4.0250, Validation Accuracy: 0.0735, Percentage:7.3529%\n",
            "Epoch [4/1500], Training Loss: 4.0818, Validation Loss: 3.8917, Validation Accuracy: 0.1020, Percentage:10.1961%\n",
            "Epoch [5/1500], Training Loss: 3.9599, Validation Loss: 3.7585, Validation Accuracy: 0.1167, Percentage:11.6667%\n",
            "Epoch [6/1500], Training Loss: 3.8068, Validation Loss: 3.6706, Validation Accuracy: 0.1471, Percentage:14.7059%\n",
            "Epoch [7/1500], Training Loss: 3.7219, Validation Loss: 3.5404, Validation Accuracy: 0.1500, Percentage:15.0000%\n",
            "Epoch [8/1500], Training Loss: 3.6188, Validation Loss: 3.4848, Validation Accuracy: 0.1745, Percentage:17.4510%\n",
            "Epoch [9/1500], Training Loss: 3.5848, Validation Loss: 3.4292, Validation Accuracy: 0.1951, Percentage:19.5098%\n",
            "Epoch [10/1500], Training Loss: 3.4942, Validation Loss: 3.3140, Validation Accuracy: 0.1961, Percentage:19.6078%\n",
            "Epoch [11/1500], Training Loss: 3.2929, Validation Loss: 3.2534, Validation Accuracy: 0.2127, Percentage:21.2745%\n",
            "Epoch [12/1500], Training Loss: 3.2444, Validation Loss: 3.2199, Validation Accuracy: 0.2098, Percentage:20.9804%\n",
            "Epoch [13/1500], Training Loss: 3.2746, Validation Loss: 3.1970, Validation Accuracy: 0.2147, Percentage:21.4706%\n",
            "Epoch [14/1500], Training Loss: 3.2256, Validation Loss: 3.1758, Validation Accuracy: 0.2265, Percentage:22.6471%\n",
            "Epoch [15/1500], Training Loss: 3.1731, Validation Loss: 3.1693, Validation Accuracy: 0.2225, Percentage:22.2549%\n",
            "Epoch [16/1500], Training Loss: 3.2058, Validation Loss: 3.1544, Validation Accuracy: 0.2363, Percentage:23.6275%\n",
            "Epoch [17/1500], Training Loss: 3.1797, Validation Loss: 3.1491, Validation Accuracy: 0.2392, Percentage:23.9216%\n",
            "Epoch [18/1500], Training Loss: 3.1756, Validation Loss: 3.1308, Validation Accuracy: 0.2431, Percentage:24.3137%\n",
            "Epoch [19/1500], Training Loss: 3.1858, Validation Loss: 3.1315, Validation Accuracy: 0.2392, Percentage:23.9216%\n",
            "Epoch [20/1500], Training Loss: 3.1230, Validation Loss: 3.1097, Validation Accuracy: 0.2559, Percentage:25.5882%\n",
            "Epoch [21/1500], Training Loss: 3.1335, Validation Loss: 3.1077, Validation Accuracy: 0.2578, Percentage:25.7843%\n",
            "Epoch [22/1500], Training Loss: 3.0447, Validation Loss: 3.1066, Validation Accuracy: 0.2559, Percentage:25.5882%\n",
            "Epoch [23/1500], Training Loss: 3.1342, Validation Loss: 3.1062, Validation Accuracy: 0.2539, Percentage:25.3922%\n",
            "Epoch [24/1500], Training Loss: 3.1219, Validation Loss: 3.1047, Validation Accuracy: 0.2539, Percentage:25.3922%\n",
            "Epoch [25/1500], Training Loss: 3.0621, Validation Loss: 3.1040, Validation Accuracy: 0.2510, Percentage:25.0980%\n",
            "Epoch [26/1500], Training Loss: 3.0703, Validation Loss: 3.1023, Validation Accuracy: 0.2510, Percentage:25.0980%\n",
            "Epoch [27/1500], Training Loss: 3.0891, Validation Loss: 3.1017, Validation Accuracy: 0.2490, Percentage:24.9020%\n",
            "Epoch [28/1500], Training Loss: 3.1650, Validation Loss: 3.1007, Validation Accuracy: 0.2471, Percentage:24.7059%\n",
            "Epoch [29/1500], Training Loss: 3.1083, Validation Loss: 3.0991, Validation Accuracy: 0.2490, Percentage:24.9020%\n",
            "Epoch [30/1500], Training Loss: 3.1213, Validation Loss: 3.1003, Validation Accuracy: 0.2490, Percentage:24.9020%\n",
            "Epoch [31/1500], Training Loss: 3.0169, Validation Loss: 3.1001, Validation Accuracy: 0.2490, Percentage:24.9020%\n",
            "Epoch [32/1500], Training Loss: 3.1241, Validation Loss: 3.1000, Validation Accuracy: 0.2490, Percentage:24.9020%\n",
            "Epoch [33/1500], Training Loss: 3.1349, Validation Loss: 3.0997, Validation Accuracy: 0.2490, Percentage:24.9020%\n",
            "Epoch [34/1500], Training Loss: 3.0967, Validation Loss: 3.0995, Validation Accuracy: 0.2490, Percentage:24.9020%\n",
            "Epoch [35/1500], Training Loss: 3.0251, Validation Loss: 3.0994, Validation Accuracy: 0.2490, Percentage:24.9020%\n",
            "Epoch [36/1500], Training Loss: 3.0833, Validation Loss: 3.0993, Validation Accuracy: 0.2490, Percentage:24.9020%\n",
            "Epoch [37/1500], Training Loss: 3.1022, Validation Loss: 3.0993, Validation Accuracy: 0.2490, Percentage:24.9020%\n",
            "Epoch [38/1500], Training Loss: 3.0976, Validation Loss: 3.0992, Validation Accuracy: 0.2490, Percentage:24.9020%\n",
            "Epoch [39/1500], Training Loss: 3.1386, Validation Loss: 3.0991, Validation Accuracy: 0.2490, Percentage:24.9020%\n",
            "Epoch [40/1500], Training Loss: 3.1242, Validation Loss: 3.0989, Validation Accuracy: 0.2490, Percentage:24.9020%\n",
            "Epoch [41/1500], Training Loss: 3.1643, Validation Loss: 3.0989, Validation Accuracy: 0.2490, Percentage:24.9020%\n",
            "Epoch [42/1500], Training Loss: 3.0983, Validation Loss: 3.0989, Validation Accuracy: 0.2490, Percentage:24.9020%\n",
            "Epoch [43/1500], Training Loss: 3.0803, Validation Loss: 3.0989, Validation Accuracy: 0.2490, Percentage:24.9020%\n",
            "Epoch [44/1500], Training Loss: 3.0694, Validation Loss: 3.0989, Validation Accuracy: 0.2490, Percentage:24.9020%\n",
            "Epoch [45/1500], Training Loss: 3.0849, Validation Loss: 3.0989, Validation Accuracy: 0.2490, Percentage:24.9020%\n",
            "Epoch [46/1500], Training Loss: 3.0683, Validation Loss: 3.0988, Validation Accuracy: 0.2490, Percentage:24.9020%\n",
            "Epoch [47/1500], Training Loss: 3.0900, Validation Loss: 3.0988, Validation Accuracy: 0.2500, Percentage:25.0000%\n",
            "Epoch [48/1500], Training Loss: 3.0387, Validation Loss: 3.0988, Validation Accuracy: 0.2500, Percentage:25.0000%\n",
            "Epoch [49/1500], Training Loss: 3.0636, Validation Loss: 3.0988, Validation Accuracy: 0.2500, Percentage:25.0000%\n",
            "Epoch [50/1500], Training Loss: 3.1180, Validation Loss: 3.0988, Validation Accuracy: 0.2500, Percentage:25.0000%\n",
            "Epoch [51/1500], Training Loss: 3.0840, Validation Loss: 3.0988, Validation Accuracy: 0.2500, Percentage:25.0000%\n",
            "Epoch [52/1500], Training Loss: 3.1072, Validation Loss: 3.0988, Validation Accuracy: 0.2500, Percentage:25.0000%\n",
            "Epoch [53/1500], Training Loss: 3.0724, Validation Loss: 3.0988, Validation Accuracy: 0.2500, Percentage:25.0000%\n",
            "Epoch [54/1500], Training Loss: 3.0881, Validation Loss: 3.0988, Validation Accuracy: 0.2500, Percentage:25.0000%\n",
            "Epoch [55/1500], Training Loss: 3.1085, Validation Loss: 3.0988, Validation Accuracy: 0.2500, Percentage:25.0000%\n",
            "Epoch [56/1500], Training Loss: 3.0464, Validation Loss: 3.0988, Validation Accuracy: 0.2500, Percentage:25.0000%\n",
            "Epoch [57/1500], Training Loss: 3.1052, Validation Loss: 3.0988, Validation Accuracy: 0.2500, Percentage:25.0000%\n",
            "Epoch [58/1500], Training Loss: 3.1061, Validation Loss: 3.0988, Validation Accuracy: 0.2500, Percentage:25.0000%\n",
            "Epoch [59/1500], Training Loss: 3.0608, Validation Loss: 3.0988, Validation Accuracy: 0.2500, Percentage:25.0000%\n",
            "Epoch [60/1500], Training Loss: 3.1175, Validation Loss: 3.0988, Validation Accuracy: 0.2500, Percentage:25.0000%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-b6ef7c1cf552>\u001b[0m in \u001b[0;36m<cell line: 108>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/flowers102.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mimage_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_image_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    947\u001b[0m                 \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"RGBA\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1204\u001b[0m         \"\"\"\n\u001b[1;32m   1205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m     \u001b[0m__copy__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import Flowers102\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define transforms for data augmentation and normalization\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(500),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(500),\n",
        "    transforms.CenterCrop(500),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the dataset with train/val/test splits\n",
        "train_dataset = Flowers102(root='./data', split='train', transform=train_transform, download=True)\n",
        "val_dataset = Flowers102(root='./data', split='val', transform=val_transform, download=True)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Define data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "class CNN_NN(nn.Module):\n",
        "    def __init__(self, num_classes=102):\n",
        "        super(CNN_NN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv5= nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "        # Initialize the size of the fully connected layer based on the sample input\n",
        "        self._to_linear = None\n",
        "        self.convs = nn.Sequential(\n",
        "            self.conv1,\n",
        "            nn.ReLU(),\n",
        "            self.pool,\n",
        "            self.conv2,\n",
        "            nn.ReLU(),\n",
        "            self.pool,\n",
        "            self.conv3,\n",
        "            nn.ReLU(),\n",
        "            self.pool,\n",
        "            self.conv4,\n",
        "            nn.ReLU(),\n",
        "            self.pool,\n",
        "            self.conv5,\n",
        "            nn.ReLU(),\n",
        "            self.pool\n",
        "        )\n",
        "        self._initialize_linear_layer()\n",
        "\n",
        "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def _initialize_linear_layer(self):\n",
        "        # Create a dummy input tensor to calculate the output size after conv layers\n",
        "        x = torch.randn(1, 3, 500, 500)\n",
        "        x = self.convs(x)\n",
        "        self._to_linear = x.view(1, -1).shape[1]\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor while preserving the batch size\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Define the device (GPU or CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyperparameters\n",
        "num_classes = 102  # Number of output classes\n",
        "learning_rate = 0.001\n",
        "num_epochs = 1500\n",
        "\n",
        "# Initialize the model\n",
        "model = CNN_NN(num_classes=num_classes).to(device)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "\n",
        "#Learning rate scheduler\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    # Calculate average loss for the epoch\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Calculate average validation loss and accuracy\n",
        "    val_loss = val_loss / len(val_loader.dataset)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "          f'Training Loss: {epoch_loss:.4f}, '\n",
        "          f'Validation Loss: {val_loss:.4f}, '\n",
        "          f'Validation Accuracy: {accuracy:.4f}, '\n",
        "          f'Percentage:{accuracy*100:.4f}%')\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pWTNyGwfZHK6",
        "outputId": "9a092677-a698-4274-cf90-a80e0fe0b8f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1500], Training Loss: 4.6970, Validation Loss: 4.6253, Validation Accuracy: 0.0118, Percentage:1.1765%\n",
            "Epoch [2/1500], Training Loss: 4.6113, Validation Loss: 4.5284, Validation Accuracy: 0.0245, Percentage:2.4510%\n",
            "Epoch [3/1500], Training Loss: 4.4929, Validation Loss: 4.4003, Validation Accuracy: 0.0245, Percentage:2.4510%\n",
            "Epoch [4/1500], Training Loss: 4.4269, Validation Loss: 4.3856, Validation Accuracy: 0.0206, Percentage:2.0588%\n",
            "Epoch [5/1500], Training Loss: 4.3971, Validation Loss: 4.3491, Validation Accuracy: 0.0245, Percentage:2.4510%\n",
            "Epoch [6/1500], Training Loss: 4.3292, Validation Loss: 4.1977, Validation Accuracy: 0.0294, Percentage:2.9412%\n",
            "Epoch [7/1500], Training Loss: 4.2297, Validation Loss: 4.1476, Validation Accuracy: 0.0255, Percentage:2.5490%\n",
            "Epoch [8/1500], Training Loss: 4.1903, Validation Loss: 4.0935, Validation Accuracy: 0.0363, Percentage:3.6275%\n",
            "Epoch [9/1500], Training Loss: 4.1389, Validation Loss: 4.1040, Validation Accuracy: 0.0608, Percentage:6.0784%\n",
            "Epoch [10/1500], Training Loss: 4.1236, Validation Loss: 4.0377, Validation Accuracy: 0.0578, Percentage:5.7843%\n",
            "Epoch [11/1500], Training Loss: 4.0793, Validation Loss: 3.9948, Validation Accuracy: 0.0539, Percentage:5.3922%\n",
            "Epoch [12/1500], Training Loss: 4.0318, Validation Loss: 3.9431, Validation Accuracy: 0.0618, Percentage:6.1765%\n",
            "Epoch [13/1500], Training Loss: 4.0426, Validation Loss: 3.9433, Validation Accuracy: 0.0657, Percentage:6.5686%\n",
            "Epoch [14/1500], Training Loss: 3.9808, Validation Loss: 3.8496, Validation Accuracy: 0.0882, Percentage:8.8235%\n",
            "Epoch [15/1500], Training Loss: 3.9397, Validation Loss: 3.8494, Validation Accuracy: 0.0971, Percentage:9.7059%\n",
            "Epoch [16/1500], Training Loss: 3.8942, Validation Loss: 3.7904, Validation Accuracy: 0.0892, Percentage:8.9216%\n",
            "Epoch [17/1500], Training Loss: 3.9084, Validation Loss: 3.7221, Validation Accuracy: 0.1147, Percentage:11.4706%\n",
            "Epoch [18/1500], Training Loss: 3.7887, Validation Loss: 3.6854, Validation Accuracy: 0.1137, Percentage:11.3725%\n",
            "Epoch [19/1500], Training Loss: 3.7550, Validation Loss: 3.5876, Validation Accuracy: 0.1284, Percentage:12.8431%\n",
            "Epoch [20/1500], Training Loss: 3.6757, Validation Loss: 3.5373, Validation Accuracy: 0.1529, Percentage:15.2941%\n",
            "Epoch [21/1500], Training Loss: 3.6042, Validation Loss: 3.5054, Validation Accuracy: 0.1402, Percentage:14.0196%\n",
            "Epoch [22/1500], Training Loss: 3.5508, Validation Loss: 3.4944, Validation Accuracy: 0.1500, Percentage:15.0000%\n",
            "Epoch [23/1500], Training Loss: 3.5755, Validation Loss: 3.4066, Validation Accuracy: 0.1667, Percentage:16.6667%\n",
            "Epoch [24/1500], Training Loss: 3.5609, Validation Loss: 3.5015, Validation Accuracy: 0.1588, Percentage:15.8824%\n",
            "Epoch [25/1500], Training Loss: 3.4844, Validation Loss: 3.3398, Validation Accuracy: 0.2059, Percentage:20.5882%\n",
            "Epoch [26/1500], Training Loss: 3.4036, Validation Loss: 3.3926, Validation Accuracy: 0.1784, Percentage:17.8431%\n",
            "Epoch [27/1500], Training Loss: 3.3846, Validation Loss: 3.2749, Validation Accuracy: 0.1951, Percentage:19.5098%\n",
            "Epoch [28/1500], Training Loss: 3.3727, Validation Loss: 3.3257, Validation Accuracy: 0.1961, Percentage:19.6078%\n",
            "Epoch [29/1500], Training Loss: 3.3204, Validation Loss: 3.2618, Validation Accuracy: 0.2098, Percentage:20.9804%\n",
            "Epoch [30/1500], Training Loss: 3.3311, Validation Loss: 3.3636, Validation Accuracy: 0.1892, Percentage:18.9216%\n",
            "Epoch [31/1500], Training Loss: 3.1452, Validation Loss: 3.1856, Validation Accuracy: 0.2186, Percentage:21.8627%\n",
            "Epoch [32/1500], Training Loss: 3.1453, Validation Loss: 3.1649, Validation Accuracy: 0.2275, Percentage:22.7451%\n",
            "Epoch [33/1500], Training Loss: 3.1789, Validation Loss: 3.1602, Validation Accuracy: 0.2275, Percentage:22.7451%\n",
            "Epoch [34/1500], Training Loss: 3.0701, Validation Loss: 3.1380, Validation Accuracy: 0.2402, Percentage:24.0196%\n",
            "Epoch [35/1500], Training Loss: 3.0370, Validation Loss: 3.1345, Validation Accuracy: 0.2471, Percentage:24.7059%\n",
            "Epoch [36/1500], Training Loss: 3.0693, Validation Loss: 3.1144, Validation Accuracy: 0.2500, Percentage:25.0000%\n",
            "Epoch [37/1500], Training Loss: 3.0256, Validation Loss: 3.1199, Validation Accuracy: 0.2569, Percentage:25.6863%\n",
            "Epoch [38/1500], Training Loss: 2.9971, Validation Loss: 3.1228, Validation Accuracy: 0.2461, Percentage:24.6078%\n",
            "Epoch [39/1500], Training Loss: 3.0307, Validation Loss: 3.0991, Validation Accuracy: 0.2657, Percentage:26.5686%\n",
            "Epoch [40/1500], Training Loss: 3.0162, Validation Loss: 3.1181, Validation Accuracy: 0.2471, Percentage:24.7059%\n",
            "Epoch [41/1500], Training Loss: 3.0897, Validation Loss: 3.0922, Validation Accuracy: 0.2510, Percentage:25.0980%\n",
            "Epoch [42/1500], Training Loss: 3.0152, Validation Loss: 3.0894, Validation Accuracy: 0.2510, Percentage:25.0980%\n",
            "Epoch [43/1500], Training Loss: 2.9742, Validation Loss: 3.0839, Validation Accuracy: 0.2578, Percentage:25.7843%\n",
            "Epoch [44/1500], Training Loss: 2.9793, Validation Loss: 3.0657, Validation Accuracy: 0.2588, Percentage:25.8824%\n",
            "Epoch [45/1500], Training Loss: 3.0054, Validation Loss: 3.0615, Validation Accuracy: 0.2608, Percentage:26.0784%\n",
            "Epoch [46/1500], Training Loss: 2.9252, Validation Loss: 3.0960, Validation Accuracy: 0.2559, Percentage:25.5882%\n",
            "Epoch [47/1500], Training Loss: 2.9336, Validation Loss: 3.0790, Validation Accuracy: 0.2676, Percentage:26.7647%\n",
            "Epoch [48/1500], Training Loss: 2.9113, Validation Loss: 3.0451, Validation Accuracy: 0.2637, Percentage:26.3725%\n",
            "Epoch [49/1500], Training Loss: 2.8618, Validation Loss: 3.0849, Validation Accuracy: 0.2608, Percentage:26.0784%\n",
            "Epoch [50/1500], Training Loss: 2.9824, Validation Loss: 3.0331, Validation Accuracy: 0.2667, Percentage:26.6667%\n",
            "Epoch [51/1500], Training Loss: 2.9317, Validation Loss: 3.0199, Validation Accuracy: 0.2735, Percentage:27.3529%\n",
            "Epoch [52/1500], Training Loss: 2.9062, Validation Loss: 3.0490, Validation Accuracy: 0.2627, Percentage:26.2745%\n",
            "Epoch [53/1500], Training Loss: 2.8964, Validation Loss: 3.0399, Validation Accuracy: 0.2686, Percentage:26.8627%\n",
            "Epoch [54/1500], Training Loss: 2.8848, Validation Loss: 3.0317, Validation Accuracy: 0.2765, Percentage:27.6471%\n",
            "Epoch [55/1500], Training Loss: 2.9097, Validation Loss: 3.0130, Validation Accuracy: 0.2775, Percentage:27.7451%\n",
            "Epoch [56/1500], Training Loss: 2.8612, Validation Loss: 3.0341, Validation Accuracy: 0.2706, Percentage:27.0588%\n",
            "Epoch [57/1500], Training Loss: 2.8524, Validation Loss: 2.9930, Validation Accuracy: 0.2941, Percentage:29.4118%\n",
            "Epoch [58/1500], Training Loss: 2.8653, Validation Loss: 3.0136, Validation Accuracy: 0.2745, Percentage:27.4510%\n",
            "Epoch [59/1500], Training Loss: 2.8681, Validation Loss: 3.0049, Validation Accuracy: 0.2794, Percentage:27.9412%\n",
            "Epoch [60/1500], Training Loss: 2.8590, Validation Loss: 2.9939, Validation Accuracy: 0.2833, Percentage:28.3333%\n",
            "Epoch [61/1500], Training Loss: 2.8087, Validation Loss: 2.9805, Validation Accuracy: 0.2902, Percentage:29.0196%\n",
            "Epoch [62/1500], Training Loss: 2.8019, Validation Loss: 2.9783, Validation Accuracy: 0.2853, Percentage:28.5294%\n",
            "Epoch [63/1500], Training Loss: 2.8143, Validation Loss: 2.9766, Validation Accuracy: 0.2833, Percentage:28.3333%\n",
            "Epoch [64/1500], Training Loss: 2.7948, Validation Loss: 2.9769, Validation Accuracy: 0.2833, Percentage:28.3333%\n",
            "Epoch [65/1500], Training Loss: 2.8332, Validation Loss: 2.9761, Validation Accuracy: 0.2814, Percentage:28.1373%\n",
            "Epoch [66/1500], Training Loss: 2.8656, Validation Loss: 2.9742, Validation Accuracy: 0.2833, Percentage:28.3333%\n",
            "Epoch [67/1500], Training Loss: 2.8242, Validation Loss: 2.9704, Validation Accuracy: 0.2824, Percentage:28.2353%\n",
            "Epoch [68/1500], Training Loss: 2.7810, Validation Loss: 2.9790, Validation Accuracy: 0.2794, Percentage:27.9412%\n",
            "Epoch [69/1500], Training Loss: 2.8346, Validation Loss: 2.9732, Validation Accuracy: 0.2804, Percentage:28.0392%\n",
            "Epoch [70/1500], Training Loss: 2.8036, Validation Loss: 2.9730, Validation Accuracy: 0.2853, Percentage:28.5294%\n",
            "Epoch [71/1500], Training Loss: 2.8518, Validation Loss: 2.9715, Validation Accuracy: 0.2853, Percentage:28.5294%\n",
            "Epoch [72/1500], Training Loss: 2.8362, Validation Loss: 2.9654, Validation Accuracy: 0.2882, Percentage:28.8235%\n",
            "Epoch [73/1500], Training Loss: 2.8567, Validation Loss: 2.9717, Validation Accuracy: 0.2882, Percentage:28.8235%\n",
            "Epoch [74/1500], Training Loss: 2.7725, Validation Loss: 2.9703, Validation Accuracy: 0.2892, Percentage:28.9216%\n",
            "Epoch [75/1500], Training Loss: 2.8202, Validation Loss: 2.9733, Validation Accuracy: 0.2873, Percentage:28.7255%\n",
            "Epoch [76/1500], Training Loss: 2.8167, Validation Loss: 2.9709, Validation Accuracy: 0.2882, Percentage:28.8235%\n",
            "Epoch [77/1500], Training Loss: 2.8154, Validation Loss: 2.9705, Validation Accuracy: 0.2863, Percentage:28.6275%\n",
            "Epoch [78/1500], Training Loss: 2.7587, Validation Loss: 2.9707, Validation Accuracy: 0.2853, Percentage:28.5294%\n",
            "Epoch [79/1500], Training Loss: 2.7883, Validation Loss: 2.9673, Validation Accuracy: 0.2892, Percentage:28.9216%\n",
            "Epoch [80/1500], Training Loss: 2.7870, Validation Loss: 2.9694, Validation Accuracy: 0.2892, Percentage:28.9216%\n",
            "Epoch [81/1500], Training Loss: 2.8331, Validation Loss: 2.9703, Validation Accuracy: 0.2941, Percentage:29.4118%\n",
            "Epoch [82/1500], Training Loss: 2.7973, Validation Loss: 2.9668, Validation Accuracy: 0.2971, Percentage:29.7059%\n",
            "Epoch [83/1500], Training Loss: 2.8043, Validation Loss: 2.9654, Validation Accuracy: 0.2941, Percentage:29.4118%\n",
            "Epoch [84/1500], Training Loss: 2.9178, Validation Loss: 2.9646, Validation Accuracy: 0.2980, Percentage:29.8039%\n",
            "Epoch [85/1500], Training Loss: 2.8798, Validation Loss: 2.9637, Validation Accuracy: 0.2980, Percentage:29.8039%\n",
            "Epoch [86/1500], Training Loss: 2.7141, Validation Loss: 2.9617, Validation Accuracy: 0.2990, Percentage:29.9020%\n",
            "Epoch [87/1500], Training Loss: 2.8399, Validation Loss: 2.9641, Validation Accuracy: 0.2971, Percentage:29.7059%\n",
            "Epoch [88/1500], Training Loss: 2.7896, Validation Loss: 2.9607, Validation Accuracy: 0.2961, Percentage:29.6078%\n",
            "Epoch [89/1500], Training Loss: 2.7543, Validation Loss: 2.9649, Validation Accuracy: 0.2951, Percentage:29.5098%\n",
            "Epoch [90/1500], Training Loss: 2.8005, Validation Loss: 2.9661, Validation Accuracy: 0.2951, Percentage:29.5098%\n",
            "Epoch [91/1500], Training Loss: 2.8344, Validation Loss: 2.9654, Validation Accuracy: 0.2961, Percentage:29.6078%\n",
            "Epoch [92/1500], Training Loss: 2.8199, Validation Loss: 2.9653, Validation Accuracy: 0.2961, Percentage:29.6078%\n",
            "Epoch [93/1500], Training Loss: 2.8852, Validation Loss: 2.9652, Validation Accuracy: 0.2971, Percentage:29.7059%\n",
            "Epoch [94/1500], Training Loss: 2.7799, Validation Loss: 2.9645, Validation Accuracy: 0.2971, Percentage:29.7059%\n",
            "Epoch [95/1500], Training Loss: 2.7874, Validation Loss: 2.9643, Validation Accuracy: 0.2961, Percentage:29.6078%\n",
            "Epoch [96/1500], Training Loss: 2.7671, Validation Loss: 2.9643, Validation Accuracy: 0.2961, Percentage:29.6078%\n",
            "Epoch [97/1500], Training Loss: 2.8181, Validation Loss: 2.9640, Validation Accuracy: 0.2961, Percentage:29.6078%\n",
            "Epoch [98/1500], Training Loss: 2.8023, Validation Loss: 2.9630, Validation Accuracy: 0.2971, Percentage:29.7059%\n",
            "Epoch [99/1500], Training Loss: 2.8583, Validation Loss: 2.9630, Validation Accuracy: 0.2961, Percentage:29.6078%\n",
            "Epoch [100/1500], Training Loss: 2.8097, Validation Loss: 2.9628, Validation Accuracy: 0.2971, Percentage:29.7059%\n",
            "Epoch [101/1500], Training Loss: 2.7441, Validation Loss: 2.9626, Validation Accuracy: 0.2980, Percentage:29.8039%\n",
            "Epoch [102/1500], Training Loss: 2.8141, Validation Loss: 2.9618, Validation Accuracy: 0.2990, Percentage:29.9020%\n",
            "Epoch [103/1500], Training Loss: 2.7898, Validation Loss: 2.9616, Validation Accuracy: 0.2990, Percentage:29.9020%\n",
            "Epoch [104/1500], Training Loss: 2.8005, Validation Loss: 2.9617, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [105/1500], Training Loss: 2.7927, Validation Loss: 2.9618, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [106/1500], Training Loss: 2.7850, Validation Loss: 2.9615, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [107/1500], Training Loss: 2.7801, Validation Loss: 2.9610, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [108/1500], Training Loss: 2.7262, Validation Loss: 2.9613, Validation Accuracy: 0.2990, Percentage:29.9020%\n",
            "Epoch [109/1500], Training Loss: 2.8307, Validation Loss: 2.9618, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [110/1500], Training Loss: 2.8515, Validation Loss: 2.9621, Validation Accuracy: 0.2980, Percentage:29.8039%\n",
            "Epoch [111/1500], Training Loss: 2.7408, Validation Loss: 2.9621, Validation Accuracy: 0.3000, Percentage:30.0000%\n",
            "Epoch [112/1500], Training Loss: 2.8123, Validation Loss: 2.9617, Validation Accuracy: 0.3000, Percentage:30.0000%\n",
            "Epoch [113/1500], Training Loss: 2.7505, Validation Loss: 2.9618, Validation Accuracy: 0.3000, Percentage:30.0000%\n",
            "Epoch [114/1500], Training Loss: 2.8484, Validation Loss: 2.9619, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [115/1500], Training Loss: 2.8080, Validation Loss: 2.9620, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [116/1500], Training Loss: 2.7972, Validation Loss: 2.9612, Validation Accuracy: 0.3000, Percentage:30.0000%\n",
            "Epoch [117/1500], Training Loss: 2.8029, Validation Loss: 2.9611, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [118/1500], Training Loss: 2.7696, Validation Loss: 2.9611, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [119/1500], Training Loss: 2.7399, Validation Loss: 2.9616, Validation Accuracy: 0.3000, Percentage:30.0000%\n",
            "Epoch [120/1500], Training Loss: 2.7993, Validation Loss: 2.9610, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [121/1500], Training Loss: 2.7533, Validation Loss: 2.9610, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [122/1500], Training Loss: 2.7504, Validation Loss: 2.9610, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [123/1500], Training Loss: 2.7665, Validation Loss: 2.9610, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [124/1500], Training Loss: 2.7842, Validation Loss: 2.9609, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [125/1500], Training Loss: 2.7774, Validation Loss: 2.9609, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [126/1500], Training Loss: 2.8331, Validation Loss: 2.9609, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [127/1500], Training Loss: 2.7636, Validation Loss: 2.9609, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [128/1500], Training Loss: 2.7617, Validation Loss: 2.9609, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [129/1500], Training Loss: 2.7659, Validation Loss: 2.9608, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [130/1500], Training Loss: 2.7681, Validation Loss: 2.9609, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [131/1500], Training Loss: 2.7248, Validation Loss: 2.9608, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [132/1500], Training Loss: 2.8336, Validation Loss: 2.9607, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [133/1500], Training Loss: 2.8231, Validation Loss: 2.9607, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [134/1500], Training Loss: 2.7986, Validation Loss: 2.9606, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [135/1500], Training Loss: 2.7825, Validation Loss: 2.9606, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [136/1500], Training Loss: 2.8498, Validation Loss: 2.9606, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [137/1500], Training Loss: 2.7898, Validation Loss: 2.9606, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [138/1500], Training Loss: 2.8271, Validation Loss: 2.9605, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [139/1500], Training Loss: 2.7415, Validation Loss: 2.9605, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [140/1500], Training Loss: 2.7366, Validation Loss: 2.9604, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [141/1500], Training Loss: 2.8095, Validation Loss: 2.9603, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [142/1500], Training Loss: 2.7673, Validation Loss: 2.9603, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [143/1500], Training Loss: 2.7889, Validation Loss: 2.9603, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [144/1500], Training Loss: 2.8470, Validation Loss: 2.9602, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [145/1500], Training Loss: 2.7665, Validation Loss: 2.9603, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [146/1500], Training Loss: 2.8116, Validation Loss: 2.9604, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [147/1500], Training Loss: 2.7650, Validation Loss: 2.9603, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [148/1500], Training Loss: 2.7598, Validation Loss: 2.9604, Validation Accuracy: 0.3000, Percentage:30.0000%\n",
            "Epoch [149/1500], Training Loss: 2.7856, Validation Loss: 2.9603, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [150/1500], Training Loss: 2.8155, Validation Loss: 2.9604, Validation Accuracy: 0.3000, Percentage:30.0000%\n",
            "Epoch [151/1500], Training Loss: 2.7597, Validation Loss: 2.9604, Validation Accuracy: 0.3000, Percentage:30.0000%\n",
            "Epoch [152/1500], Training Loss: 2.8319, Validation Loss: 2.9604, Validation Accuracy: 0.3000, Percentage:30.0000%\n",
            "Epoch [153/1500], Training Loss: 2.7434, Validation Loss: 2.9604, Validation Accuracy: 0.3000, Percentage:30.0000%\n",
            "Epoch [154/1500], Training Loss: 2.8107, Validation Loss: 2.9604, Validation Accuracy: 0.3000, Percentage:30.0000%\n",
            "Epoch [155/1500], Training Loss: 2.7756, Validation Loss: 2.9604, Validation Accuracy: 0.3000, Percentage:30.0000%\n",
            "Epoch [156/1500], Training Loss: 2.7453, Validation Loss: 2.9604, Validation Accuracy: 0.3000, Percentage:30.0000%\n",
            "Epoch [157/1500], Training Loss: 2.7670, Validation Loss: 2.9604, Validation Accuracy: 0.3000, Percentage:30.0000%\n",
            "Epoch [158/1500], Training Loss: 2.7733, Validation Loss: 2.9604, Validation Accuracy: 0.3000, Percentage:30.0000%\n",
            "Epoch [159/1500], Training Loss: 2.8364, Validation Loss: 2.9604, Validation Accuracy: 0.3000, Percentage:30.0000%\n",
            "Epoch [160/1500], Training Loss: 2.7745, Validation Loss: 2.9604, Validation Accuracy: 0.3000, Percentage:30.0000%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-c456dea31c97>\u001b[0m in \u001b[0;36m<cell line: 108>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;31m# Calculate average loss for the epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import Flowers102\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "# Define transforms for data augmentation and normalization\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the dataset with train/val/test splits\n",
        "train_dataset = Flowers102(root='./data', split='train', transform=train_transform, download=True)\n",
        "val_dataset = Flowers102(root='./data', split='val', transform=val_transform, download=True)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Define data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Using a pre-trained model (ResNet18) and fine-tuning it\n",
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 102)\n",
        "\n",
        "# Define the device (GPU or CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "# Hyperparameters\n",
        "num_classes = 102  # Number of output classes\n",
        "learning_rate = 0.001\n",
        "num_epochs = 100\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    # Calculate average loss for the epoch\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Calculate average validation loss and accuracy\n",
        "    val_loss = val_loss / len(val_loader.dataset)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "          f'Training Loss: {epoch_loss:.4f}, '\n",
        "          f'Validation Loss: {val_loss:.4f}, '\n",
        "          f'Validation Accuracy: {accuracy:.4f}, '\n",
        "          f'Percentage: {accuracy*100:.4f}%')\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "print('Finished Training')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "Ayuc7GzXk5DK",
        "outputId": "c062a003-548f-4607-864e-d7f4abe1b3f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Training Loss: 4.1096, Validation Loss: 4.7784, Validation Accuracy: 0.1324, Percentage: 13.2353%\n",
            "Epoch [2/100], Training Loss: 2.7636, Validation Loss: 2.7753, Validation Accuracy: 0.3196, Percentage: 31.9608%\n",
            "Epoch [3/100], Training Loss: 2.1088, Validation Loss: 2.1022, Validation Accuracy: 0.4529, Percentage: 45.2941%\n",
            "Epoch [4/100], Training Loss: 1.7337, Validation Loss: 1.9631, Validation Accuracy: 0.4912, Percentage: 49.1176%\n",
            "Epoch [5/100], Training Loss: 1.4534, Validation Loss: 1.4563, Validation Accuracy: 0.6167, Percentage: 61.6667%\n",
            "Epoch [6/100], Training Loss: 1.2252, Validation Loss: 1.7552, Validation Accuracy: 0.5696, Percentage: 56.9608%\n",
            "Epoch [7/100], Training Loss: 1.1055, Validation Loss: 1.3404, Validation Accuracy: 0.6490, Percentage: 64.9020%\n",
            "Epoch [8/100], Training Loss: 1.0164, Validation Loss: 1.4485, Validation Accuracy: 0.6314, Percentage: 63.1373%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-3dd95ef79cbe>\u001b[0m in \u001b[0;36m<cell line: 63>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/flowers102.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mimage_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_image_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    935\u001b[0m         \"\"\"\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0mhas_transparency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"transparency\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import Flowers102\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define transforms for data augmentation and normalization\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),  # Additional data augmentation\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the dataset with train/val/test splits\n",
        "train_dataset = Flowers102(root='./data', split='train', transform=train_transform, download=True)\n",
        "val_dataset = Flowers102(root='./data', split='val', transform=val_transform, download=True)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Define data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "class CNN_NN(nn.Module):\n",
        "    def __init__(self, num_classes=102):\n",
        "        super(CNN_NN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv5 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv6 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv7 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv8 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Initialize the size of the fully connected layer based on the sample input\n",
        "        self._to_linear = None\n",
        "        self.convs = nn.Sequential(\n",
        "            self.conv1,\n",
        "            nn.ReLU(inplace=True),\n",
        "            self.conv2,\n",
        "            nn.ReLU(inplace=True),\n",
        "            self.pool,\n",
        "            self.conv3,\n",
        "            nn.ReLU(inplace=True),\n",
        "            self.conv4,\n",
        "            nn.ReLU(inplace=True),\n",
        "            self.pool,\n",
        "            self.conv5,\n",
        "            nn.ReLU(inplace=True),\n",
        "            self.conv6,\n",
        "            nn.ReLU(inplace=True),\n",
        "            self.pool,\n",
        "            self.conv7,\n",
        "            nn.ReLU(inplace=True),\n",
        "            self.conv8,\n",
        "            nn.ReLU(inplace=True),\n",
        "            self.pool\n",
        "        )\n",
        "        self._initialize_linear_layer()\n",
        "\n",
        "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def _initialize_linear_layer(self):\n",
        "        # Create a dummy input tensor to calculate the output size after conv layers\n",
        "        x = torch.randn(1, 3, 224, 224)\n",
        "        x = self.convs(x)\n",
        "        self._to_linear = x.view(1, -1).shape[1]\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor while preserving the batch size\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Define the device (GPU or CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyperparameters\n",
        "num_classes = 102  # Number of output classes\n",
        "learning_rate = 0.001\n",
        "num_epochs = 1000\n",
        "\n",
        "# Initialize the model\n",
        "model = CNN_NN(num_classes=num_classes).to(device)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    # Calculate average loss for the epoch\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Calculate average validation loss and accuracy\n",
        "    val_loss = val_loss / len(val_loader.dataset)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "          f'Training Loss: {epoch_loss:.4f}, '\n",
        "          f'Validation Loss: {val_loss:.4f}, '\n",
        "          f'Validation Accuracy: {accuracy:.4f}, '\n",
        "          f'Percentage:{accuracy*100:.4f}%')\n",
        "\n",
        "    # Update learning rate scheduler\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # Early stopping condition\n",
        "    if val_loss < 0.1:  # Adjust the threshold based on your validation loss\n",
        "        print(\"Validation loss is below threshold. Stopping training.\")\n",
        "        break\n",
        "\n",
        "print('Finished Training')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "Olb048TOD68I",
        "outputId": "60287701-6c2e-4252-e831-5c9147c7afc2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1000], Training Loss: 4.6606, Validation Loss: 4.6256, Validation Accuracy: 0.0098, Percentage:0.9804%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/1000], Training Loss: 4.6285, Validation Loss: 4.6253, Validation Accuracy: 0.0098, Percentage:0.9804%\n",
            "Epoch [3/1000], Training Loss: 4.6258, Validation Loss: 4.6253, Validation Accuracy: 0.0098, Percentage:0.9804%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-9c529293486b>\u001b[0m in \u001b[0;36m<cell line: 117>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Set the model to training mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/flowers102.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m   1278\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_saturation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaturation_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mfn_id\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhue_factor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1280\u001b[0;31m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_hue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36madjust_hue\u001b[0;34m(img, hue_factor)\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjust_hue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_hue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_hue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_pil.py\u001b[0m in \u001b[0;36madjust_hue\u001b[0;34m(img, hue_factor)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"L\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"HSV\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(mode, bands)\u001b[0m\n\u001b[1;32m   3383\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mband\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbands\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3384\u001b[0m         \u001b[0mband\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3385\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbands\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbands\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import Flowers102\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define transforms for data augmentation and normalization\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the dataset with train/val/test splits\n",
        "train_dataset = Flowers102(root='./data', split='train', transform=train_transform, download=True)\n",
        "val_dataset = Flowers102(root='./data', split='val', transform=val_transform, download=True)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Define data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "class CNN_NN(nn.Module):\n",
        "    def __init__(self, num_classes=102):\n",
        "        super(CNN_NN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv5= nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv6= nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
        "        #self.conv7= nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
        "        #self.conv8= nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation =1, ceil_mode=False)\n",
        "\n",
        "        # Initialize the size of the fully connected layer based on the sample input\n",
        "        self._to_linear = None\n",
        "        self.convs = nn.Sequential(\n",
        "            self.conv1,\n",
        "            nn.ReLU(inplace=True),\n",
        "            #self.pool,\n",
        "            self.conv2,\n",
        "            nn.ReLU(inplace=True),\n",
        "            self.pool,\n",
        "            self.conv3,\n",
        "            nn.ReLU(inplace=True),\n",
        "            #self.pool,\n",
        "            self.conv4,\n",
        "            nn.ReLU(inplace=True),\n",
        "            self.pool,\n",
        "            self.conv5,\n",
        "            nn.ReLU(inplace=True),\n",
        "            #self.pool\n",
        "            #self.conv6,\n",
        "            #nn.ReLU(inplace=True),\n",
        "            self.conv6,\n",
        "            nn.ReLU(inplace=True),\n",
        "            self.pool,\n",
        "           # self.conv7,\n",
        "            #nn.ReLU(inplace=True),\n",
        "            #self.conv8,\n",
        "            #nn.ReLU(inplace=True),\n",
        "            #self.conv8,\n",
        "           # nn.ReLU(inplace=True),\n",
        "           # self.pool,\n",
        "            #self.conv8,\n",
        "           # nn.ReLU(inplace=True),\n",
        "           # self.conv8,\n",
        "           # nn.ReLU(inplace=True),\n",
        "           # self.conv8,\n",
        "           # nn.ReLU(inplace=True),\n",
        "           # self.pool,\n",
        "\n",
        "        )\n",
        "        self._initialize_linear_layer()\n",
        "\n",
        "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def _initialize_linear_layer(self):\n",
        "        # Create a dummy input tensor to calculate the output size after conv layers\n",
        "        x = torch.randn(1, 3, 224, 224)\n",
        "        x = self.convs(x)\n",
        "        self._to_linear = x.view(1, -1).shape[1]\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor while preserving the batch size\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Define the device (GPU or CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyperparameters\n",
        "num_classes = 102  # Number of output classes\n",
        "learning_rate = 0.001\n",
        "num_epochs = 1500\n",
        "\n",
        "# Initialize the model\n",
        "model = CNN_NN(num_classes=num_classes).to(device)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    # Calculate average loss for the epoch\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Calculate average validation loss and accuracy\n",
        "    val_loss = val_loss / len(val_loader.dataset)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "          f'Training Loss: {epoch_loss:.4f}, '\n",
        "          f'Validation Loss: {val_loss:.4f}, '\n",
        "          f'Validation Accuracy: {accuracy:.4f}, '\n",
        "          f'Percentage:{accuracy*100:.4f}%')\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSQOSzYsHHpw",
        "outputId": "b42a3998-e862-4f8d-d909-80ba210eedea"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1500], Training Loss: 4.6453, Validation Loss: 4.5989, Validation Accuracy: 0.0127, Percentage:1.2745%\n",
            "Epoch [2/1500], Training Loss: 4.5949, Validation Loss: 4.4818, Validation Accuracy: 0.0157, Percentage:1.5686%\n",
            "Epoch [3/1500], Training Loss: 4.5061, Validation Loss: 4.4816, Validation Accuracy: 0.0176, Percentage:1.7647%\n",
            "Epoch [4/1500], Training Loss: 4.4482, Validation Loss: 4.3469, Validation Accuracy: 0.0186, Percentage:1.8627%\n",
            "Epoch [5/1500], Training Loss: 4.3793, Validation Loss: 4.3162, Validation Accuracy: 0.0176, Percentage:1.7647%\n",
            "Epoch [6/1500], Training Loss: 4.3159, Validation Loss: 4.2561, Validation Accuracy: 0.0402, Percentage:4.0196%\n",
            "Epoch [7/1500], Training Loss: 4.2623, Validation Loss: 4.2407, Validation Accuracy: 0.0402, Percentage:4.0196%\n",
            "Epoch [8/1500], Training Loss: 4.2517, Validation Loss: 4.1788, Validation Accuracy: 0.0363, Percentage:3.6275%\n",
            "Epoch [9/1500], Training Loss: 4.2213, Validation Loss: 4.1766, Validation Accuracy: 0.0373, Percentage:3.7255%\n",
            "Epoch [10/1500], Training Loss: 4.2444, Validation Loss: 4.1751, Validation Accuracy: 0.0353, Percentage:3.5294%\n",
            "Epoch [11/1500], Training Loss: 4.1714, Validation Loss: 4.1726, Validation Accuracy: 0.0304, Percentage:3.0392%\n",
            "Epoch [12/1500], Training Loss: 4.1402, Validation Loss: 4.0929, Validation Accuracy: 0.0510, Percentage:5.0980%\n",
            "Epoch [13/1500], Training Loss: 4.1356, Validation Loss: 4.0300, Validation Accuracy: 0.0618, Percentage:6.1765%\n",
            "Epoch [14/1500], Training Loss: 4.1337, Validation Loss: 4.0642, Validation Accuracy: 0.0569, Percentage:5.6863%\n",
            "Epoch [15/1500], Training Loss: 4.0469, Validation Loss: 4.0282, Validation Accuracy: 0.0618, Percentage:6.1765%\n",
            "Epoch [16/1500], Training Loss: 4.0704, Validation Loss: 4.0367, Validation Accuracy: 0.0588, Percentage:5.8824%\n",
            "Epoch [17/1500], Training Loss: 3.9819, Validation Loss: 3.9990, Validation Accuracy: 0.0725, Percentage:7.2549%\n",
            "Epoch [18/1500], Training Loss: 3.9838, Validation Loss: 3.9824, Validation Accuracy: 0.0725, Percentage:7.2549%\n",
            "Epoch [19/1500], Training Loss: 3.9874, Validation Loss: 4.0014, Validation Accuracy: 0.0784, Percentage:7.8431%\n",
            "Epoch [20/1500], Training Loss: 4.0071, Validation Loss: 4.0242, Validation Accuracy: 0.0824, Percentage:8.2353%\n",
            "Epoch [21/1500], Training Loss: 3.9253, Validation Loss: 3.9411, Validation Accuracy: 0.0961, Percentage:9.6078%\n",
            "Epoch [22/1500], Training Loss: 3.9044, Validation Loss: 3.9161, Validation Accuracy: 0.0784, Percentage:7.8431%\n",
            "Epoch [23/1500], Training Loss: 3.8797, Validation Loss: 3.9505, Validation Accuracy: 0.0824, Percentage:8.2353%\n",
            "Epoch [24/1500], Training Loss: 3.8606, Validation Loss: 3.8761, Validation Accuracy: 0.1049, Percentage:10.4902%\n",
            "Epoch [25/1500], Training Loss: 3.8169, Validation Loss: 3.8617, Validation Accuracy: 0.0882, Percentage:8.8235%\n",
            "Epoch [26/1500], Training Loss: 3.7684, Validation Loss: 4.0100, Validation Accuracy: 0.0843, Percentage:8.4314%\n",
            "Epoch [27/1500], Training Loss: 3.8171, Validation Loss: 3.8625, Validation Accuracy: 0.0990, Percentage:9.9020%\n",
            "Epoch [28/1500], Training Loss: 3.7990, Validation Loss: 3.8370, Validation Accuracy: 0.1049, Percentage:10.4902%\n",
            "Epoch [29/1500], Training Loss: 3.7319, Validation Loss: 3.9496, Validation Accuracy: 0.0980, Percentage:9.8039%\n",
            "Epoch [30/1500], Training Loss: 3.7702, Validation Loss: 3.7868, Validation Accuracy: 0.1039, Percentage:10.3922%\n",
            "Epoch [31/1500], Training Loss: 3.6382, Validation Loss: 3.7941, Validation Accuracy: 0.1039, Percentage:10.3922%\n",
            "Epoch [32/1500], Training Loss: 3.6542, Validation Loss: 3.7807, Validation Accuracy: 0.1206, Percentage:12.0588%\n",
            "Epoch [33/1500], Training Loss: 3.6275, Validation Loss: 3.7933, Validation Accuracy: 0.0931, Percentage:9.3137%\n",
            "Epoch [34/1500], Training Loss: 3.5942, Validation Loss: 3.8085, Validation Accuracy: 0.1049, Percentage:10.4902%\n",
            "Epoch [35/1500], Training Loss: 3.6061, Validation Loss: 3.8134, Validation Accuracy: 0.1088, Percentage:10.8824%\n",
            "Epoch [36/1500], Training Loss: 3.5489, Validation Loss: 3.7142, Validation Accuracy: 0.1186, Percentage:11.8627%\n",
            "Epoch [37/1500], Training Loss: 3.5748, Validation Loss: 3.7968, Validation Accuracy: 0.1098, Percentage:10.9804%\n",
            "Epoch [38/1500], Training Loss: 3.5115, Validation Loss: 3.6654, Validation Accuracy: 0.1500, Percentage:15.0000%\n",
            "Epoch [39/1500], Training Loss: 3.4746, Validation Loss: 3.7138, Validation Accuracy: 0.1225, Percentage:12.2549%\n",
            "Epoch [40/1500], Training Loss: 3.4881, Validation Loss: 3.6653, Validation Accuracy: 0.1353, Percentage:13.5294%\n",
            "Epoch [41/1500], Training Loss: 3.4915, Validation Loss: 3.7012, Validation Accuracy: 0.1314, Percentage:13.1373%\n",
            "Epoch [42/1500], Training Loss: 3.4568, Validation Loss: 3.6625, Validation Accuracy: 0.1431, Percentage:14.3137%\n",
            "Epoch [43/1500], Training Loss: 3.4990, Validation Loss: 3.6151, Validation Accuracy: 0.1608, Percentage:16.0784%\n",
            "Epoch [44/1500], Training Loss: 3.4740, Validation Loss: 3.6384, Validation Accuracy: 0.1510, Percentage:15.0980%\n",
            "Epoch [45/1500], Training Loss: 3.4230, Validation Loss: 3.6849, Validation Accuracy: 0.1441, Percentage:14.4118%\n",
            "Epoch [46/1500], Training Loss: 3.4054, Validation Loss: 3.6366, Validation Accuracy: 0.1373, Percentage:13.7255%\n",
            "Epoch [47/1500], Training Loss: 3.3682, Validation Loss: 3.6472, Validation Accuracy: 0.1402, Percentage:14.0196%\n",
            "Epoch [48/1500], Training Loss: 3.4158, Validation Loss: 3.6098, Validation Accuracy: 0.1441, Percentage:14.4118%\n",
            "Epoch [49/1500], Training Loss: 3.4213, Validation Loss: 3.5665, Validation Accuracy: 0.1706, Percentage:17.0588%\n",
            "Epoch [50/1500], Training Loss: 3.3306, Validation Loss: 3.5906, Validation Accuracy: 0.1539, Percentage:15.3922%\n",
            "Epoch [51/1500], Training Loss: 3.3804, Validation Loss: 3.5933, Validation Accuracy: 0.1461, Percentage:14.6078%\n",
            "Epoch [52/1500], Training Loss: 3.2313, Validation Loss: 3.6183, Validation Accuracy: 0.1627, Percentage:16.2745%\n",
            "Epoch [53/1500], Training Loss: 3.3467, Validation Loss: 3.4840, Validation Accuracy: 0.1676, Percentage:16.7647%\n",
            "Epoch [54/1500], Training Loss: 3.2374, Validation Loss: 3.6052, Validation Accuracy: 0.1480, Percentage:14.8039%\n",
            "Epoch [55/1500], Training Loss: 3.2806, Validation Loss: 3.5201, Validation Accuracy: 0.1647, Percentage:16.4706%\n",
            "Epoch [56/1500], Training Loss: 3.2302, Validation Loss: 3.5262, Validation Accuracy: 0.1618, Percentage:16.1765%\n",
            "Epoch [57/1500], Training Loss: 3.2605, Validation Loss: 3.5219, Validation Accuracy: 0.1618, Percentage:16.1765%\n",
            "Epoch [58/1500], Training Loss: 3.2163, Validation Loss: 3.4785, Validation Accuracy: 0.1706, Percentage:17.0588%\n",
            "Epoch [59/1500], Training Loss: 3.1918, Validation Loss: 3.4630, Validation Accuracy: 0.1804, Percentage:18.0392%\n",
            "Epoch [60/1500], Training Loss: 3.1374, Validation Loss: 3.5248, Validation Accuracy: 0.1667, Percentage:16.6667%\n",
            "Epoch [61/1500], Training Loss: 3.2308, Validation Loss: 3.5007, Validation Accuracy: 0.1735, Percentage:17.3529%\n",
            "Epoch [62/1500], Training Loss: 3.2927, Validation Loss: 3.4631, Validation Accuracy: 0.1667, Percentage:16.6667%\n",
            "Epoch [63/1500], Training Loss: 3.1100, Validation Loss: 3.4822, Validation Accuracy: 0.1725, Percentage:17.2549%\n",
            "Epoch [64/1500], Training Loss: 3.2106, Validation Loss: 3.4649, Validation Accuracy: 0.1882, Percentage:18.8235%\n",
            "Epoch [65/1500], Training Loss: 3.1630, Validation Loss: 3.3917, Validation Accuracy: 0.1735, Percentage:17.3529%\n",
            "Epoch [66/1500], Training Loss: 3.0670, Validation Loss: 3.4147, Validation Accuracy: 0.2000, Percentage:20.0000%\n",
            "Epoch [67/1500], Training Loss: 3.1277, Validation Loss: 3.3933, Validation Accuracy: 0.1794, Percentage:17.9412%\n",
            "Epoch [68/1500], Training Loss: 3.0658, Validation Loss: 3.4797, Validation Accuracy: 0.1755, Percentage:17.5490%\n",
            "Epoch [69/1500], Training Loss: 3.0075, Validation Loss: 3.5356, Validation Accuracy: 0.1804, Percentage:18.0392%\n",
            "Epoch [70/1500], Training Loss: 3.0309, Validation Loss: 3.4581, Validation Accuracy: 0.1804, Percentage:18.0392%\n",
            "Epoch [71/1500], Training Loss: 3.0569, Validation Loss: 3.4967, Validation Accuracy: 0.1833, Percentage:18.3333%\n",
            "Epoch [72/1500], Training Loss: 3.0776, Validation Loss: 3.4145, Validation Accuracy: 0.1873, Percentage:18.7255%\n",
            "Epoch [73/1500], Training Loss: 3.1020, Validation Loss: 3.4944, Validation Accuracy: 0.1951, Percentage:19.5098%\n",
            "Epoch [74/1500], Training Loss: 3.0009, Validation Loss: 3.5632, Validation Accuracy: 0.1971, Percentage:19.7059%\n",
            "Epoch [75/1500], Training Loss: 3.0159, Validation Loss: 3.3498, Validation Accuracy: 0.2059, Percentage:20.5882%\n",
            "Epoch [76/1500], Training Loss: 3.0105, Validation Loss: 3.3495, Validation Accuracy: 0.2186, Percentage:21.8627%\n",
            "Epoch [77/1500], Training Loss: 2.9231, Validation Loss: 3.4987, Validation Accuracy: 0.2000, Percentage:20.0000%\n",
            "Epoch [78/1500], Training Loss: 2.9822, Validation Loss: 3.5153, Validation Accuracy: 0.1912, Percentage:19.1176%\n",
            "Epoch [79/1500], Training Loss: 2.9201, Validation Loss: 3.3943, Validation Accuracy: 0.2020, Percentage:20.1961%\n",
            "Epoch [80/1500], Training Loss: 2.9663, Validation Loss: 3.3503, Validation Accuracy: 0.2088, Percentage:20.8824%\n",
            "Epoch [81/1500], Training Loss: 2.8920, Validation Loss: 3.3518, Validation Accuracy: 0.1951, Percentage:19.5098%\n",
            "Epoch [82/1500], Training Loss: 3.0281, Validation Loss: 3.3562, Validation Accuracy: 0.2108, Percentage:21.0784%\n",
            "Epoch [83/1500], Training Loss: 2.8344, Validation Loss: 3.3783, Validation Accuracy: 0.2127, Percentage:21.2745%\n",
            "Epoch [84/1500], Training Loss: 2.9130, Validation Loss: 3.3756, Validation Accuracy: 0.2020, Percentage:20.1961%\n",
            "Epoch [85/1500], Training Loss: 2.9287, Validation Loss: 3.4244, Validation Accuracy: 0.2000, Percentage:20.0000%\n",
            "Epoch [86/1500], Training Loss: 2.8712, Validation Loss: 3.3008, Validation Accuracy: 0.2225, Percentage:22.2549%\n",
            "Epoch [87/1500], Training Loss: 2.8267, Validation Loss: 3.3411, Validation Accuracy: 0.2255, Percentage:22.5490%\n",
            "Epoch [88/1500], Training Loss: 2.8496, Validation Loss: 3.3401, Validation Accuracy: 0.2235, Percentage:22.3529%\n",
            "Epoch [89/1500], Training Loss: 2.7615, Validation Loss: 3.3771, Validation Accuracy: 0.1961, Percentage:19.6078%\n",
            "Epoch [90/1500], Training Loss: 2.7842, Validation Loss: 3.3780, Validation Accuracy: 0.2000, Percentage:20.0000%\n",
            "Epoch [91/1500], Training Loss: 2.8187, Validation Loss: 3.4223, Validation Accuracy: 0.2078, Percentage:20.7843%\n",
            "Epoch [92/1500], Training Loss: 2.8414, Validation Loss: 3.3692, Validation Accuracy: 0.2176, Percentage:21.7647%\n",
            "Epoch [93/1500], Training Loss: 2.7772, Validation Loss: 3.2983, Validation Accuracy: 0.2324, Percentage:23.2353%\n",
            "Epoch [94/1500], Training Loss: 2.6994, Validation Loss: 3.3648, Validation Accuracy: 0.2353, Percentage:23.5294%\n",
            "Epoch [95/1500], Training Loss: 2.8709, Validation Loss: 3.2842, Validation Accuracy: 0.2108, Percentage:21.0784%\n",
            "Epoch [96/1500], Training Loss: 2.7635, Validation Loss: 3.3153, Validation Accuracy: 0.2275, Percentage:22.7451%\n",
            "Epoch [97/1500], Training Loss: 2.7773, Validation Loss: 3.3588, Validation Accuracy: 0.2108, Percentage:21.0784%\n",
            "Epoch [98/1500], Training Loss: 2.6916, Validation Loss: 3.2512, Validation Accuracy: 0.2314, Percentage:23.1373%\n",
            "Epoch [99/1500], Training Loss: 2.6787, Validation Loss: 3.6385, Validation Accuracy: 0.1794, Percentage:17.9412%\n",
            "Epoch [100/1500], Training Loss: 2.6993, Validation Loss: 3.3045, Validation Accuracy: 0.2275, Percentage:22.7451%\n",
            "Epoch [101/1500], Training Loss: 2.7426, Validation Loss: 3.3516, Validation Accuracy: 0.2167, Percentage:21.6667%\n",
            "Epoch [102/1500], Training Loss: 2.7084, Validation Loss: 3.2929, Validation Accuracy: 0.2216, Percentage:22.1569%\n",
            "Epoch [103/1500], Training Loss: 2.6664, Validation Loss: 3.3932, Validation Accuracy: 0.2373, Percentage:23.7255%\n",
            "Epoch [104/1500], Training Loss: 2.7334, Validation Loss: 3.2758, Validation Accuracy: 0.2225, Percentage:22.2549%\n",
            "Epoch [105/1500], Training Loss: 2.6154, Validation Loss: 3.2152, Validation Accuracy: 0.2549, Percentage:25.4902%\n",
            "Epoch [106/1500], Training Loss: 2.6361, Validation Loss: 3.2361, Validation Accuracy: 0.2353, Percentage:23.5294%\n",
            "Epoch [107/1500], Training Loss: 2.5639, Validation Loss: 3.3054, Validation Accuracy: 0.2382, Percentage:23.8235%\n",
            "Epoch [108/1500], Training Loss: 2.6394, Validation Loss: 3.3472, Validation Accuracy: 0.2255, Percentage:22.5490%\n",
            "Epoch [109/1500], Training Loss: 2.6354, Validation Loss: 3.2959, Validation Accuracy: 0.2451, Percentage:24.5098%\n",
            "Epoch [110/1500], Training Loss: 2.5703, Validation Loss: 3.1856, Validation Accuracy: 0.2588, Percentage:25.8824%\n",
            "Epoch [111/1500], Training Loss: 2.5782, Validation Loss: 3.3495, Validation Accuracy: 0.2402, Percentage:24.0196%\n",
            "Epoch [112/1500], Training Loss: 2.4667, Validation Loss: 3.2956, Validation Accuracy: 0.2608, Percentage:26.0784%\n",
            "Epoch [113/1500], Training Loss: 2.5083, Validation Loss: 3.2982, Validation Accuracy: 0.2500, Percentage:25.0000%\n",
            "Epoch [114/1500], Training Loss: 2.6169, Validation Loss: 3.3774, Validation Accuracy: 0.2265, Percentage:22.6471%\n",
            "Epoch [115/1500], Training Loss: 2.4644, Validation Loss: 3.2761, Validation Accuracy: 0.2441, Percentage:24.4118%\n",
            "Epoch [116/1500], Training Loss: 2.5017, Validation Loss: 3.2453, Validation Accuracy: 0.2461, Percentage:24.6078%\n",
            "Epoch [117/1500], Training Loss: 2.5951, Validation Loss: 3.1080, Validation Accuracy: 0.2618, Percentage:26.1765%\n",
            "Epoch [118/1500], Training Loss: 2.5184, Validation Loss: 3.1412, Validation Accuracy: 0.2706, Percentage:27.0588%\n",
            "Epoch [119/1500], Training Loss: 2.5457, Validation Loss: 3.1725, Validation Accuracy: 0.2480, Percentage:24.8039%\n",
            "Epoch [120/1500], Training Loss: 2.4317, Validation Loss: 3.2199, Validation Accuracy: 0.2608, Percentage:26.0784%\n",
            "Epoch [121/1500], Training Loss: 2.4065, Validation Loss: 3.1786, Validation Accuracy: 0.2833, Percentage:28.3333%\n",
            "Epoch [122/1500], Training Loss: 2.4667, Validation Loss: 3.1379, Validation Accuracy: 0.2706, Percentage:27.0588%\n",
            "Epoch [123/1500], Training Loss: 2.4983, Validation Loss: 3.1070, Validation Accuracy: 0.2500, Percentage:25.0000%\n",
            "Epoch [124/1500], Training Loss: 2.4410, Validation Loss: 3.1597, Validation Accuracy: 0.2598, Percentage:25.9804%\n",
            "Epoch [125/1500], Training Loss: 2.4762, Validation Loss: 3.1021, Validation Accuracy: 0.2520, Percentage:25.1961%\n",
            "Epoch [126/1500], Training Loss: 2.5167, Validation Loss: 3.1734, Validation Accuracy: 0.2441, Percentage:24.4118%\n",
            "Epoch [127/1500], Training Loss: 2.4311, Validation Loss: 3.0549, Validation Accuracy: 0.2843, Percentage:28.4314%\n",
            "Epoch [128/1500], Training Loss: 2.3338, Validation Loss: 3.2814, Validation Accuracy: 0.2529, Percentage:25.2941%\n",
            "Epoch [129/1500], Training Loss: 2.4125, Validation Loss: 3.0933, Validation Accuracy: 0.2686, Percentage:26.8627%\n",
            "Epoch [130/1500], Training Loss: 2.4297, Validation Loss: 3.1942, Validation Accuracy: 0.2657, Percentage:26.5686%\n",
            "Epoch [131/1500], Training Loss: 2.3703, Validation Loss: 3.2409, Validation Accuracy: 0.2676, Percentage:26.7647%\n",
            "Epoch [132/1500], Training Loss: 2.4900, Validation Loss: 3.1663, Validation Accuracy: 0.2765, Percentage:27.6471%\n",
            "Epoch [133/1500], Training Loss: 2.3564, Validation Loss: 3.2461, Validation Accuracy: 0.2706, Percentage:27.0588%\n",
            "Epoch [134/1500], Training Loss: 2.4429, Validation Loss: 3.2810, Validation Accuracy: 0.2559, Percentage:25.5882%\n",
            "Epoch [135/1500], Training Loss: 2.3683, Validation Loss: 3.2854, Validation Accuracy: 0.2431, Percentage:24.3137%\n",
            "Epoch [136/1500], Training Loss: 2.2292, Validation Loss: 3.1139, Validation Accuracy: 0.2853, Percentage:28.5294%\n",
            "Epoch [137/1500], Training Loss: 2.3532, Validation Loss: 3.1615, Validation Accuracy: 0.2853, Percentage:28.5294%\n",
            "Epoch [138/1500], Training Loss: 2.2992, Validation Loss: 3.0670, Validation Accuracy: 0.2824, Percentage:28.2353%\n",
            "Epoch [139/1500], Training Loss: 2.2500, Validation Loss: 3.1718, Validation Accuracy: 0.2804, Percentage:28.0392%\n",
            "Epoch [140/1500], Training Loss: 2.3092, Validation Loss: 3.0282, Validation Accuracy: 0.2912, Percentage:29.1176%\n",
            "Epoch [141/1500], Training Loss: 2.2585, Validation Loss: 3.1965, Validation Accuracy: 0.2667, Percentage:26.6667%\n",
            "Epoch [142/1500], Training Loss: 2.2770, Validation Loss: 3.1817, Validation Accuracy: 0.2912, Percentage:29.1176%\n",
            "Epoch [143/1500], Training Loss: 2.3052, Validation Loss: 3.2341, Validation Accuracy: 0.2696, Percentage:26.9608%\n",
            "Epoch [144/1500], Training Loss: 2.2790, Validation Loss: 3.0666, Validation Accuracy: 0.2922, Percentage:29.2157%\n",
            "Epoch [145/1500], Training Loss: 2.1960, Validation Loss: 2.9554, Validation Accuracy: 0.2873, Percentage:28.7255%\n",
            "Epoch [146/1500], Training Loss: 2.2799, Validation Loss: 3.0765, Validation Accuracy: 0.2843, Percentage:28.4314%\n",
            "Epoch [147/1500], Training Loss: 2.2444, Validation Loss: 3.1474, Validation Accuracy: 0.2873, Percentage:28.7255%\n",
            "Epoch [148/1500], Training Loss: 2.2715, Validation Loss: 3.0798, Validation Accuracy: 0.2853, Percentage:28.5294%\n",
            "Epoch [149/1500], Training Loss: 2.2748, Validation Loss: 3.0726, Validation Accuracy: 0.2912, Percentage:29.1176%\n",
            "Epoch [150/1500], Training Loss: 2.2290, Validation Loss: 3.0576, Validation Accuracy: 0.2775, Percentage:27.7451%\n",
            "Epoch [151/1500], Training Loss: 2.1995, Validation Loss: 3.2412, Validation Accuracy: 0.2784, Percentage:27.8431%\n",
            "Epoch [152/1500], Training Loss: 2.1478, Validation Loss: 3.0745, Validation Accuracy: 0.2902, Percentage:29.0196%\n",
            "Epoch [153/1500], Training Loss: 2.2787, Validation Loss: 3.1127, Validation Accuracy: 0.3020, Percentage:30.1961%\n",
            "Epoch [154/1500], Training Loss: 2.1726, Validation Loss: 3.1735, Validation Accuracy: 0.2990, Percentage:29.9020%\n",
            "Epoch [155/1500], Training Loss: 2.0843, Validation Loss: 3.1448, Validation Accuracy: 0.2922, Percentage:29.2157%\n",
            "Epoch [156/1500], Training Loss: 2.1143, Validation Loss: 3.0065, Validation Accuracy: 0.2990, Percentage:29.9020%\n",
            "Epoch [157/1500], Training Loss: 2.2525, Validation Loss: 3.1638, Validation Accuracy: 0.3029, Percentage:30.2941%\n",
            "Epoch [158/1500], Training Loss: 2.1727, Validation Loss: 3.1225, Validation Accuracy: 0.2814, Percentage:28.1373%\n",
            "Epoch [159/1500], Training Loss: 2.1938, Validation Loss: 2.9921, Validation Accuracy: 0.3098, Percentage:30.9804%\n",
            "Epoch [160/1500], Training Loss: 2.1207, Validation Loss: 3.1612, Validation Accuracy: 0.2765, Percentage:27.6471%\n",
            "Epoch [161/1500], Training Loss: 2.0732, Validation Loss: 3.0637, Validation Accuracy: 0.2990, Percentage:29.9020%\n",
            "Epoch [162/1500], Training Loss: 2.1532, Validation Loss: 3.0801, Validation Accuracy: 0.2755, Percentage:27.5490%\n",
            "Epoch [163/1500], Training Loss: 2.1486, Validation Loss: 3.1008, Validation Accuracy: 0.2863, Percentage:28.6275%\n",
            "Epoch [164/1500], Training Loss: 2.1485, Validation Loss: 3.0103, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [165/1500], Training Loss: 2.1616, Validation Loss: 3.1256, Validation Accuracy: 0.2951, Percentage:29.5098%\n",
            "Epoch [166/1500], Training Loss: 2.1151, Validation Loss: 3.0444, Validation Accuracy: 0.2892, Percentage:28.9216%\n",
            "Epoch [167/1500], Training Loss: 2.0145, Validation Loss: 3.3129, Validation Accuracy: 0.2735, Percentage:27.3529%\n",
            "Epoch [168/1500], Training Loss: 2.0657, Validation Loss: 3.0476, Validation Accuracy: 0.2971, Percentage:29.7059%\n",
            "Epoch [169/1500], Training Loss: 2.2050, Validation Loss: 3.0973, Validation Accuracy: 0.3069, Percentage:30.6863%\n",
            "Epoch [170/1500], Training Loss: 2.1644, Validation Loss: 2.9613, Validation Accuracy: 0.3088, Percentage:30.8824%\n",
            "Epoch [171/1500], Training Loss: 2.0080, Validation Loss: 3.1232, Validation Accuracy: 0.3010, Percentage:30.0980%\n",
            "Epoch [172/1500], Training Loss: 2.0431, Validation Loss: 3.0698, Validation Accuracy: 0.3098, Percentage:30.9804%\n",
            "Epoch [173/1500], Training Loss: 2.1229, Validation Loss: 3.0148, Validation Accuracy: 0.2971, Percentage:29.7059%\n",
            "Epoch [174/1500], Training Loss: 2.0804, Validation Loss: 3.1117, Validation Accuracy: 0.2980, Percentage:29.8039%\n",
            "Epoch [175/1500], Training Loss: 2.1451, Validation Loss: 2.9289, Validation Accuracy: 0.3137, Percentage:31.3725%\n",
            "Epoch [176/1500], Training Loss: 2.0234, Validation Loss: 3.2043, Validation Accuracy: 0.2931, Percentage:29.3137%\n",
            "Epoch [177/1500], Training Loss: 2.0323, Validation Loss: 3.0540, Validation Accuracy: 0.3039, Percentage:30.3922%\n",
            "Epoch [178/1500], Training Loss: 2.0004, Validation Loss: 3.1402, Validation Accuracy: 0.3098, Percentage:30.9804%\n",
            "Epoch [179/1500], Training Loss: 1.9616, Validation Loss: 3.0274, Validation Accuracy: 0.3088, Percentage:30.8824%\n",
            "Epoch [180/1500], Training Loss: 2.0396, Validation Loss: 3.0585, Validation Accuracy: 0.3069, Percentage:30.6863%\n",
            "Epoch [181/1500], Training Loss: 2.0900, Validation Loss: 3.0023, Validation Accuracy: 0.3039, Percentage:30.3922%\n",
            "Epoch [182/1500], Training Loss: 2.1291, Validation Loss: 3.0109, Validation Accuracy: 0.3039, Percentage:30.3922%\n",
            "Epoch [183/1500], Training Loss: 1.9973, Validation Loss: 3.1065, Validation Accuracy: 0.3108, Percentage:31.0784%\n",
            "Epoch [184/1500], Training Loss: 2.0337, Validation Loss: 3.1446, Validation Accuracy: 0.3078, Percentage:30.7843%\n",
            "Epoch [185/1500], Training Loss: 1.9438, Validation Loss: 3.0862, Validation Accuracy: 0.3127, Percentage:31.2745%\n",
            "Epoch [186/1500], Training Loss: 1.9543, Validation Loss: 3.2772, Validation Accuracy: 0.2863, Percentage:28.6275%\n",
            "Epoch [187/1500], Training Loss: 2.0701, Validation Loss: 3.2358, Validation Accuracy: 0.2892, Percentage:28.9216%\n",
            "Epoch [188/1500], Training Loss: 2.0413, Validation Loss: 3.0009, Validation Accuracy: 0.3098, Percentage:30.9804%\n",
            "Epoch [189/1500], Training Loss: 1.9582, Validation Loss: 2.9746, Validation Accuracy: 0.3147, Percentage:31.4706%\n",
            "Epoch [190/1500], Training Loss: 1.9951, Validation Loss: 3.0617, Validation Accuracy: 0.3049, Percentage:30.4902%\n",
            "Epoch [191/1500], Training Loss: 1.9651, Validation Loss: 3.1102, Validation Accuracy: 0.3157, Percentage:31.5686%\n",
            "Epoch [192/1500], Training Loss: 1.9226, Validation Loss: 3.1502, Validation Accuracy: 0.3059, Percentage:30.5882%\n",
            "Epoch [193/1500], Training Loss: 1.9131, Validation Loss: 3.0939, Validation Accuracy: 0.3137, Percentage:31.3725%\n",
            "Epoch [194/1500], Training Loss: 1.9819, Validation Loss: 2.9914, Validation Accuracy: 0.3127, Percentage:31.2745%\n",
            "Epoch [195/1500], Training Loss: 2.0792, Validation Loss: 3.0635, Validation Accuracy: 0.3186, Percentage:31.8627%\n",
            "Epoch [196/1500], Training Loss: 1.8945, Validation Loss: 3.0217, Validation Accuracy: 0.3000, Percentage:30.0000%\n",
            "Epoch [197/1500], Training Loss: 2.0124, Validation Loss: 3.0191, Validation Accuracy: 0.3118, Percentage:31.1765%\n",
            "Epoch [198/1500], Training Loss: 1.9615, Validation Loss: 3.1084, Validation Accuracy: 0.3186, Percentage:31.8627%\n",
            "Epoch [199/1500], Training Loss: 1.9346, Validation Loss: 2.9703, Validation Accuracy: 0.3098, Percentage:30.9804%\n",
            "Epoch [200/1500], Training Loss: 1.9350, Validation Loss: 3.0777, Validation Accuracy: 0.3000, Percentage:30.0000%\n",
            "Epoch [201/1500], Training Loss: 1.9610, Validation Loss: 2.8975, Validation Accuracy: 0.3373, Percentage:33.7255%\n",
            "Epoch [202/1500], Training Loss: 1.9423, Validation Loss: 3.0060, Validation Accuracy: 0.3255, Percentage:32.5490%\n",
            "Epoch [203/1500], Training Loss: 1.9054, Validation Loss: 3.1402, Validation Accuracy: 0.3235, Percentage:32.3529%\n",
            "Epoch [204/1500], Training Loss: 1.8475, Validation Loss: 3.0289, Validation Accuracy: 0.3245, Percentage:32.4510%\n",
            "Epoch [205/1500], Training Loss: 1.9407, Validation Loss: 3.0566, Validation Accuracy: 0.3147, Percentage:31.4706%\n",
            "Epoch [206/1500], Training Loss: 1.8124, Validation Loss: 2.9066, Validation Accuracy: 0.3225, Percentage:32.2549%\n",
            "Epoch [207/1500], Training Loss: 1.9067, Validation Loss: 2.9991, Validation Accuracy: 0.3363, Percentage:33.6275%\n",
            "Epoch [208/1500], Training Loss: 1.9322, Validation Loss: 2.9316, Validation Accuracy: 0.3127, Percentage:31.2745%\n",
            "Epoch [209/1500], Training Loss: 1.8051, Validation Loss: 3.1728, Validation Accuracy: 0.3088, Percentage:30.8824%\n",
            "Epoch [210/1500], Training Loss: 1.8550, Validation Loss: 2.9720, Validation Accuracy: 0.3275, Percentage:32.7451%\n",
            "Epoch [211/1500], Training Loss: 1.8934, Validation Loss: 3.0896, Validation Accuracy: 0.3255, Percentage:32.5490%\n",
            "Epoch [212/1500], Training Loss: 1.8076, Validation Loss: 3.1737, Validation Accuracy: 0.3088, Percentage:30.8824%\n",
            "Epoch [213/1500], Training Loss: 2.0243, Validation Loss: 3.1508, Validation Accuracy: 0.3157, Percentage:31.5686%\n",
            "Epoch [214/1500], Training Loss: 1.9479, Validation Loss: 2.9410, Validation Accuracy: 0.3382, Percentage:33.8235%\n",
            "Epoch [215/1500], Training Loss: 1.8501, Validation Loss: 3.0356, Validation Accuracy: 0.3304, Percentage:33.0392%\n",
            "Epoch [216/1500], Training Loss: 1.7677, Validation Loss: 3.0122, Validation Accuracy: 0.3157, Percentage:31.5686%\n",
            "Epoch [217/1500], Training Loss: 1.6675, Validation Loss: 3.2120, Validation Accuracy: 0.3245, Percentage:32.4510%\n",
            "Epoch [218/1500], Training Loss: 1.8878, Validation Loss: 2.9904, Validation Accuracy: 0.3206, Percentage:32.0588%\n",
            "Epoch [219/1500], Training Loss: 1.8629, Validation Loss: 3.0820, Validation Accuracy: 0.3373, Percentage:33.7255%\n",
            "Epoch [220/1500], Training Loss: 1.8069, Validation Loss: 2.8786, Validation Accuracy: 0.3294, Percentage:32.9412%\n",
            "Epoch [221/1500], Training Loss: 1.8860, Validation Loss: 2.9582, Validation Accuracy: 0.3039, Percentage:30.3922%\n",
            "Epoch [222/1500], Training Loss: 1.8398, Validation Loss: 3.2230, Validation Accuracy: 0.3353, Percentage:33.5294%\n",
            "Epoch [223/1500], Training Loss: 1.8568, Validation Loss: 2.9643, Validation Accuracy: 0.3353, Percentage:33.5294%\n",
            "Epoch [224/1500], Training Loss: 1.8087, Validation Loss: 3.0928, Validation Accuracy: 0.3284, Percentage:32.8431%\n",
            "Epoch [225/1500], Training Loss: 1.7941, Validation Loss: 3.0904, Validation Accuracy: 0.2990, Percentage:29.9020%\n",
            "Epoch [226/1500], Training Loss: 1.8194, Validation Loss: 3.0430, Validation Accuracy: 0.3098, Percentage:30.9804%\n",
            "Epoch [227/1500], Training Loss: 1.8954, Validation Loss: 3.1972, Validation Accuracy: 0.2971, Percentage:29.7059%\n",
            "Epoch [228/1500], Training Loss: 1.8580, Validation Loss: 3.0643, Validation Accuracy: 0.3294, Percentage:32.9412%\n",
            "Epoch [229/1500], Training Loss: 1.7646, Validation Loss: 3.0463, Validation Accuracy: 0.3471, Percentage:34.7059%\n",
            "Epoch [230/1500], Training Loss: 1.7389, Validation Loss: 2.8744, Validation Accuracy: 0.3422, Percentage:34.2157%\n",
            "Epoch [231/1500], Training Loss: 1.8363, Validation Loss: 3.1244, Validation Accuracy: 0.3216, Percentage:32.1569%\n",
            "Epoch [232/1500], Training Loss: 1.7107, Validation Loss: 2.9766, Validation Accuracy: 0.3392, Percentage:33.9216%\n",
            "Epoch [233/1500], Training Loss: 1.7557, Validation Loss: 3.0045, Validation Accuracy: 0.3333, Percentage:33.3333%\n",
            "Epoch [234/1500], Training Loss: 1.7763, Validation Loss: 3.0826, Validation Accuracy: 0.3529, Percentage:35.2941%\n",
            "Epoch [235/1500], Training Loss: 1.6392, Validation Loss: 2.9383, Validation Accuracy: 0.3431, Percentage:34.3137%\n",
            "Epoch [236/1500], Training Loss: 1.7027, Validation Loss: 3.2884, Validation Accuracy: 0.3127, Percentage:31.2745%\n",
            "Epoch [237/1500], Training Loss: 1.7795, Validation Loss: 2.9554, Validation Accuracy: 0.3343, Percentage:33.4314%\n",
            "Epoch [238/1500], Training Loss: 1.7046, Validation Loss: 3.0665, Validation Accuracy: 0.3402, Percentage:34.0196%\n",
            "Epoch [239/1500], Training Loss: 1.6960, Validation Loss: 2.9329, Validation Accuracy: 0.3618, Percentage:36.1765%\n",
            "Epoch [240/1500], Training Loss: 1.7656, Validation Loss: 2.9795, Validation Accuracy: 0.3392, Percentage:33.9216%\n",
            "Epoch [241/1500], Training Loss: 1.7910, Validation Loss: 3.0116, Validation Accuracy: 0.3431, Percentage:34.3137%\n",
            "Epoch [242/1500], Training Loss: 1.7980, Validation Loss: 3.1121, Validation Accuracy: 0.3147, Percentage:31.4706%\n",
            "Epoch [243/1500], Training Loss: 1.7730, Validation Loss: 3.1223, Validation Accuracy: 0.3412, Percentage:34.1176%\n",
            "Epoch [244/1500], Training Loss: 1.6845, Validation Loss: 3.0741, Validation Accuracy: 0.3069, Percentage:30.6863%\n",
            "Epoch [245/1500], Training Loss: 1.6812, Validation Loss: 3.0070, Validation Accuracy: 0.3451, Percentage:34.5098%\n",
            "Epoch [246/1500], Training Loss: 1.7870, Validation Loss: 3.0820, Validation Accuracy: 0.3167, Percentage:31.6667%\n",
            "Epoch [247/1500], Training Loss: 1.7254, Validation Loss: 3.1153, Validation Accuracy: 0.3196, Percentage:31.9608%\n",
            "Epoch [248/1500], Training Loss: 1.6720, Validation Loss: 3.0054, Validation Accuracy: 0.3382, Percentage:33.8235%\n",
            "Epoch [249/1500], Training Loss: 1.6051, Validation Loss: 3.1932, Validation Accuracy: 0.3275, Percentage:32.7451%\n",
            "Epoch [250/1500], Training Loss: 1.7142, Validation Loss: 3.0795, Validation Accuracy: 0.3490, Percentage:34.9020%\n",
            "Epoch [251/1500], Training Loss: 1.7640, Validation Loss: 2.9845, Validation Accuracy: 0.3343, Percentage:33.4314%\n",
            "Epoch [252/1500], Training Loss: 1.6441, Validation Loss: 3.1122, Validation Accuracy: 0.3412, Percentage:34.1176%\n",
            "Epoch [253/1500], Training Loss: 1.7567, Validation Loss: 2.9822, Validation Accuracy: 0.3333, Percentage:33.3333%\n",
            "Epoch [254/1500], Training Loss: 1.8243, Validation Loss: 3.1644, Validation Accuracy: 0.3353, Percentage:33.5294%\n",
            "Epoch [255/1500], Training Loss: 1.7419, Validation Loss: 2.9741, Validation Accuracy: 0.3363, Percentage:33.6275%\n",
            "Epoch [256/1500], Training Loss: 1.7042, Validation Loss: 3.0002, Validation Accuracy: 0.3294, Percentage:32.9412%\n",
            "Epoch [257/1500], Training Loss: 1.6941, Validation Loss: 2.9886, Validation Accuracy: 0.3294, Percentage:32.9412%\n",
            "Epoch [258/1500], Training Loss: 1.6495, Validation Loss: 3.0542, Validation Accuracy: 0.3363, Percentage:33.6275%\n",
            "Epoch [259/1500], Training Loss: 1.7184, Validation Loss: 3.0525, Validation Accuracy: 0.3294, Percentage:32.9412%\n",
            "Epoch [260/1500], Training Loss: 1.6371, Validation Loss: 2.9654, Validation Accuracy: 0.3422, Percentage:34.2157%\n",
            "Epoch [261/1500], Training Loss: 1.6820, Validation Loss: 3.0283, Validation Accuracy: 0.3461, Percentage:34.6078%\n",
            "Epoch [262/1500], Training Loss: 1.6594, Validation Loss: 3.0327, Validation Accuracy: 0.3431, Percentage:34.3137%\n",
            "Epoch [263/1500], Training Loss: 1.7146, Validation Loss: 3.0433, Validation Accuracy: 0.3539, Percentage:35.3922%\n",
            "Epoch [264/1500], Training Loss: 1.6609, Validation Loss: 3.0344, Validation Accuracy: 0.3412, Percentage:34.1176%\n",
            "Epoch [265/1500], Training Loss: 1.7875, Validation Loss: 3.0082, Validation Accuracy: 0.3402, Percentage:34.0196%\n",
            "Epoch [266/1500], Training Loss: 1.6911, Validation Loss: 3.1107, Validation Accuracy: 0.3402, Percentage:34.0196%\n",
            "Epoch [267/1500], Training Loss: 1.6338, Validation Loss: 3.1050, Validation Accuracy: 0.3363, Percentage:33.6275%\n",
            "Epoch [268/1500], Training Loss: 1.6096, Validation Loss: 2.9708, Validation Accuracy: 0.3520, Percentage:35.1961%\n",
            "Epoch [269/1500], Training Loss: 1.6439, Validation Loss: 2.9606, Validation Accuracy: 0.3529, Percentage:35.2941%\n",
            "Epoch [270/1500], Training Loss: 1.6592, Validation Loss: 3.1333, Validation Accuracy: 0.3235, Percentage:32.3529%\n",
            "Epoch [271/1500], Training Loss: 1.7385, Validation Loss: 2.9688, Validation Accuracy: 0.3490, Percentage:34.9020%\n",
            "Epoch [272/1500], Training Loss: 1.6898, Validation Loss: 2.9361, Validation Accuracy: 0.3549, Percentage:35.4902%\n",
            "Epoch [273/1500], Training Loss: 1.6020, Validation Loss: 2.9378, Validation Accuracy: 0.3382, Percentage:33.8235%\n",
            "Epoch [274/1500], Training Loss: 1.6209, Validation Loss: 3.0563, Validation Accuracy: 0.3392, Percentage:33.9216%\n",
            "Epoch [275/1500], Training Loss: 1.5793, Validation Loss: 2.9522, Validation Accuracy: 0.3784, Percentage:37.8431%\n",
            "Epoch [276/1500], Training Loss: 1.5372, Validation Loss: 3.0555, Validation Accuracy: 0.3441, Percentage:34.4118%\n",
            "Epoch [277/1500], Training Loss: 1.4529, Validation Loss: 3.1846, Validation Accuracy: 0.3480, Percentage:34.8039%\n",
            "Epoch [278/1500], Training Loss: 1.5995, Validation Loss: 2.9528, Validation Accuracy: 0.3667, Percentage:36.6667%\n",
            "Epoch [279/1500], Training Loss: 1.6319, Validation Loss: 2.9196, Validation Accuracy: 0.3627, Percentage:36.2745%\n",
            "Epoch [280/1500], Training Loss: 1.4880, Validation Loss: 3.0424, Validation Accuracy: 0.3588, Percentage:35.8824%\n",
            "Epoch [281/1500], Training Loss: 1.5605, Validation Loss: 3.0048, Validation Accuracy: 0.3490, Percentage:34.9020%\n",
            "Epoch [282/1500], Training Loss: 1.6311, Validation Loss: 2.9076, Validation Accuracy: 0.3657, Percentage:36.5686%\n",
            "Epoch [283/1500], Training Loss: 1.5206, Validation Loss: 3.0780, Validation Accuracy: 0.3539, Percentage:35.3922%\n",
            "Epoch [284/1500], Training Loss: 1.7093, Validation Loss: 2.9966, Validation Accuracy: 0.3490, Percentage:34.9020%\n",
            "Epoch [285/1500], Training Loss: 1.5253, Validation Loss: 2.9752, Validation Accuracy: 0.3471, Percentage:34.7059%\n",
            "Epoch [286/1500], Training Loss: 1.6510, Validation Loss: 2.9722, Validation Accuracy: 0.3520, Percentage:35.1961%\n",
            "Epoch [287/1500], Training Loss: 1.6238, Validation Loss: 3.0357, Validation Accuracy: 0.3500, Percentage:35.0000%\n",
            "Epoch [288/1500], Training Loss: 1.5371, Validation Loss: 2.9369, Validation Accuracy: 0.3735, Percentage:37.3529%\n",
            "Epoch [289/1500], Training Loss: 1.6507, Validation Loss: 2.9309, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [290/1500], Training Loss: 1.6551, Validation Loss: 2.8688, Validation Accuracy: 0.3471, Percentage:34.7059%\n",
            "Epoch [291/1500], Training Loss: 1.6513, Validation Loss: 2.8534, Validation Accuracy: 0.3510, Percentage:35.0980%\n",
            "Epoch [292/1500], Training Loss: 1.6195, Validation Loss: 2.9259, Validation Accuracy: 0.3451, Percentage:34.5098%\n",
            "Epoch [293/1500], Training Loss: 1.5199, Validation Loss: 3.1040, Validation Accuracy: 0.3559, Percentage:35.5882%\n",
            "Epoch [294/1500], Training Loss: 1.7138, Validation Loss: 2.9160, Validation Accuracy: 0.3343, Percentage:33.4314%\n",
            "Epoch [295/1500], Training Loss: 1.6364, Validation Loss: 3.0519, Validation Accuracy: 0.3500, Percentage:35.0000%\n",
            "Epoch [296/1500], Training Loss: 1.5894, Validation Loss: 2.9270, Validation Accuracy: 0.3775, Percentage:37.7451%\n",
            "Epoch [297/1500], Training Loss: 1.5979, Validation Loss: 2.8982, Validation Accuracy: 0.3637, Percentage:36.3725%\n",
            "Epoch [298/1500], Training Loss: 1.5888, Validation Loss: 2.9758, Validation Accuracy: 0.3618, Percentage:36.1765%\n",
            "Epoch [299/1500], Training Loss: 1.4637, Validation Loss: 3.1822, Validation Accuracy: 0.3412, Percentage:34.1176%\n",
            "Epoch [300/1500], Training Loss: 1.5867, Validation Loss: 2.8778, Validation Accuracy: 0.3549, Percentage:35.4902%\n",
            "Epoch [301/1500], Training Loss: 1.5437, Validation Loss: 3.0812, Validation Accuracy: 0.3382, Percentage:33.8235%\n",
            "Epoch [302/1500], Training Loss: 1.5198, Validation Loss: 3.0467, Validation Accuracy: 0.3431, Percentage:34.3137%\n",
            "Epoch [303/1500], Training Loss: 1.6251, Validation Loss: 2.8841, Validation Accuracy: 0.3598, Percentage:35.9804%\n",
            "Epoch [304/1500], Training Loss: 1.5606, Validation Loss: 2.8710, Validation Accuracy: 0.3824, Percentage:38.2353%\n",
            "Epoch [305/1500], Training Loss: 1.5002, Validation Loss: 2.9880, Validation Accuracy: 0.3520, Percentage:35.1961%\n",
            "Epoch [306/1500], Training Loss: 1.5203, Validation Loss: 2.9054, Validation Accuracy: 0.3490, Percentage:34.9020%\n",
            "Epoch [307/1500], Training Loss: 1.4793, Validation Loss: 3.0279, Validation Accuracy: 0.3392, Percentage:33.9216%\n",
            "Epoch [308/1500], Training Loss: 1.6474, Validation Loss: 2.9261, Validation Accuracy: 0.3657, Percentage:36.5686%\n",
            "Epoch [309/1500], Training Loss: 1.5517, Validation Loss: 2.9066, Validation Accuracy: 0.3539, Percentage:35.3922%\n",
            "Epoch [310/1500], Training Loss: 1.5707, Validation Loss: 3.0233, Validation Accuracy: 0.3490, Percentage:34.9020%\n",
            "Epoch [311/1500], Training Loss: 1.4427, Validation Loss: 3.1472, Validation Accuracy: 0.3686, Percentage:36.8627%\n",
            "Epoch [312/1500], Training Loss: 1.6275, Validation Loss: 3.1864, Validation Accuracy: 0.3647, Percentage:36.4706%\n",
            "Epoch [313/1500], Training Loss: 1.5045, Validation Loss: 3.0914, Validation Accuracy: 0.3735, Percentage:37.3529%\n",
            "Epoch [314/1500], Training Loss: 1.5624, Validation Loss: 2.9612, Validation Accuracy: 0.3431, Percentage:34.3137%\n",
            "Epoch [315/1500], Training Loss: 1.5031, Validation Loss: 3.0948, Validation Accuracy: 0.3667, Percentage:36.6667%\n",
            "Epoch [316/1500], Training Loss: 1.5048, Validation Loss: 3.0715, Validation Accuracy: 0.3706, Percentage:37.0588%\n",
            "Epoch [317/1500], Training Loss: 1.4898, Validation Loss: 3.1492, Validation Accuracy: 0.3520, Percentage:35.1961%\n",
            "Epoch [318/1500], Training Loss: 1.4507, Validation Loss: 3.1326, Validation Accuracy: 0.3608, Percentage:36.0784%\n",
            "Epoch [319/1500], Training Loss: 1.5382, Validation Loss: 3.0009, Validation Accuracy: 0.3716, Percentage:37.1569%\n",
            "Epoch [320/1500], Training Loss: 1.4521, Validation Loss: 2.9606, Validation Accuracy: 0.3569, Percentage:35.6863%\n",
            "Epoch [321/1500], Training Loss: 1.4909, Validation Loss: 3.0561, Validation Accuracy: 0.3529, Percentage:35.2941%\n",
            "Epoch [322/1500], Training Loss: 1.4253, Validation Loss: 2.9110, Validation Accuracy: 0.3716, Percentage:37.1569%\n",
            "Epoch [323/1500], Training Loss: 1.4654, Validation Loss: 2.9295, Validation Accuracy: 0.3637, Percentage:36.3725%\n",
            "Epoch [324/1500], Training Loss: 1.5828, Validation Loss: 2.8995, Validation Accuracy: 0.3637, Percentage:36.3725%\n",
            "Epoch [325/1500], Training Loss: 1.5154, Validation Loss: 3.1058, Validation Accuracy: 0.3716, Percentage:37.1569%\n",
            "Epoch [326/1500], Training Loss: 1.5063, Validation Loss: 3.0561, Validation Accuracy: 0.3706, Percentage:37.0588%\n",
            "Epoch [327/1500], Training Loss: 1.4995, Validation Loss: 2.8727, Validation Accuracy: 0.3706, Percentage:37.0588%\n",
            "Epoch [328/1500], Training Loss: 1.4959, Validation Loss: 2.8445, Validation Accuracy: 0.3794, Percentage:37.9412%\n",
            "Epoch [329/1500], Training Loss: 1.5785, Validation Loss: 3.0067, Validation Accuracy: 0.3657, Percentage:36.5686%\n",
            "Epoch [330/1500], Training Loss: 1.4839, Validation Loss: 2.9804, Validation Accuracy: 0.3627, Percentage:36.2745%\n",
            "Epoch [331/1500], Training Loss: 1.3883, Validation Loss: 3.2297, Validation Accuracy: 0.3431, Percentage:34.3137%\n",
            "Epoch [332/1500], Training Loss: 1.4302, Validation Loss: 3.1902, Validation Accuracy: 0.3598, Percentage:35.9804%\n",
            "Epoch [333/1500], Training Loss: 1.4769, Validation Loss: 3.0263, Validation Accuracy: 0.3716, Percentage:37.1569%\n",
            "Epoch [334/1500], Training Loss: 1.4517, Validation Loss: 3.1120, Validation Accuracy: 0.3735, Percentage:37.3529%\n",
            "Epoch [335/1500], Training Loss: 1.5288, Validation Loss: 3.0522, Validation Accuracy: 0.3833, Percentage:38.3333%\n",
            "Epoch [336/1500], Training Loss: 1.4935, Validation Loss: 3.1204, Validation Accuracy: 0.3784, Percentage:37.8431%\n",
            "Epoch [337/1500], Training Loss: 1.4123, Validation Loss: 2.9141, Validation Accuracy: 0.3745, Percentage:37.4510%\n",
            "Epoch [338/1500], Training Loss: 1.4775, Validation Loss: 3.0105, Validation Accuracy: 0.3765, Percentage:37.6471%\n",
            "Epoch [339/1500], Training Loss: 1.5102, Validation Loss: 2.9763, Validation Accuracy: 0.3735, Percentage:37.3529%\n",
            "Epoch [340/1500], Training Loss: 1.5037, Validation Loss: 2.8833, Validation Accuracy: 0.3637, Percentage:36.3725%\n",
            "Epoch [341/1500], Training Loss: 1.3059, Validation Loss: 2.9424, Validation Accuracy: 0.3647, Percentage:36.4706%\n",
            "Epoch [342/1500], Training Loss: 1.4665, Validation Loss: 2.9995, Validation Accuracy: 0.3618, Percentage:36.1765%\n",
            "Epoch [343/1500], Training Loss: 1.3995, Validation Loss: 2.8964, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [344/1500], Training Loss: 1.4961, Validation Loss: 2.9418, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [345/1500], Training Loss: 1.4547, Validation Loss: 3.0196, Validation Accuracy: 0.3784, Percentage:37.8431%\n",
            "Epoch [346/1500], Training Loss: 1.3828, Validation Loss: 3.0666, Validation Accuracy: 0.3745, Percentage:37.4510%\n",
            "Epoch [347/1500], Training Loss: 1.3695, Validation Loss: 3.1044, Validation Accuracy: 0.3784, Percentage:37.8431%\n",
            "Epoch [348/1500], Training Loss: 1.3597, Validation Loss: 3.0152, Validation Accuracy: 0.3627, Percentage:36.2745%\n",
            "Epoch [349/1500], Training Loss: 1.5213, Validation Loss: 2.9356, Validation Accuracy: 0.3627, Percentage:36.2745%\n",
            "Epoch [350/1500], Training Loss: 1.3568, Validation Loss: 3.0532, Validation Accuracy: 0.3549, Percentage:35.4902%\n",
            "Epoch [351/1500], Training Loss: 1.4071, Validation Loss: 3.0120, Validation Accuracy: 0.3667, Percentage:36.6667%\n",
            "Epoch [352/1500], Training Loss: 1.4950, Validation Loss: 2.7740, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [353/1500], Training Loss: 1.4117, Validation Loss: 2.9243, Validation Accuracy: 0.3686, Percentage:36.8627%\n",
            "Epoch [354/1500], Training Loss: 1.4565, Validation Loss: 2.8313, Validation Accuracy: 0.3667, Percentage:36.6667%\n",
            "Epoch [355/1500], Training Loss: 1.4736, Validation Loss: 3.0161, Validation Accuracy: 0.3569, Percentage:35.6863%\n",
            "Epoch [356/1500], Training Loss: 1.4274, Validation Loss: 2.8779, Validation Accuracy: 0.3686, Percentage:36.8627%\n",
            "Epoch [357/1500], Training Loss: 1.4767, Validation Loss: 3.0209, Validation Accuracy: 0.3735, Percentage:37.3529%\n",
            "Epoch [358/1500], Training Loss: 1.3731, Validation Loss: 2.8155, Validation Accuracy: 0.3833, Percentage:38.3333%\n",
            "Epoch [359/1500], Training Loss: 1.3550, Validation Loss: 2.9671, Validation Accuracy: 0.3775, Percentage:37.7451%\n",
            "Epoch [360/1500], Training Loss: 1.4104, Validation Loss: 2.9406, Validation Accuracy: 0.3529, Percentage:35.2941%\n",
            "Epoch [361/1500], Training Loss: 1.4921, Validation Loss: 2.9306, Validation Accuracy: 0.3490, Percentage:34.9020%\n",
            "Epoch [362/1500], Training Loss: 1.4266, Validation Loss: 2.9631, Validation Accuracy: 0.3461, Percentage:34.6078%\n",
            "Epoch [363/1500], Training Loss: 1.5039, Validation Loss: 2.7999, Validation Accuracy: 0.3549, Percentage:35.4902%\n",
            "Epoch [364/1500], Training Loss: 1.4416, Validation Loss: 2.9069, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [365/1500], Training Loss: 1.4545, Validation Loss: 2.8693, Validation Accuracy: 0.3706, Percentage:37.0588%\n",
            "Epoch [366/1500], Training Loss: 1.4765, Validation Loss: 3.1441, Validation Accuracy: 0.3706, Percentage:37.0588%\n",
            "Epoch [367/1500], Training Loss: 1.4894, Validation Loss: 2.9306, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [368/1500], Training Loss: 1.5000, Validation Loss: 2.9571, Validation Accuracy: 0.3578, Percentage:35.7843%\n",
            "Epoch [369/1500], Training Loss: 1.4825, Validation Loss: 2.9531, Validation Accuracy: 0.3725, Percentage:37.2549%\n",
            "Epoch [370/1500], Training Loss: 1.2577, Validation Loss: 2.9438, Validation Accuracy: 0.3853, Percentage:38.5294%\n",
            "Epoch [371/1500], Training Loss: 1.4655, Validation Loss: 2.9963, Validation Accuracy: 0.3539, Percentage:35.3922%\n",
            "Epoch [372/1500], Training Loss: 1.3653, Validation Loss: 2.9075, Validation Accuracy: 0.3657, Percentage:36.5686%\n",
            "Epoch [373/1500], Training Loss: 1.4392, Validation Loss: 2.8164, Validation Accuracy: 0.3765, Percentage:37.6471%\n",
            "Epoch [374/1500], Training Loss: 1.2841, Validation Loss: 2.9090, Validation Accuracy: 0.3882, Percentage:38.8235%\n",
            "Epoch [375/1500], Training Loss: 1.3824, Validation Loss: 2.9986, Validation Accuracy: 0.3882, Percentage:38.8235%\n",
            "Epoch [376/1500], Training Loss: 1.3828, Validation Loss: 2.9453, Validation Accuracy: 0.3745, Percentage:37.4510%\n",
            "Epoch [377/1500], Training Loss: 1.3539, Validation Loss: 3.0896, Validation Accuracy: 0.3578, Percentage:35.7843%\n",
            "Epoch [378/1500], Training Loss: 1.3879, Validation Loss: 3.0143, Validation Accuracy: 0.3412, Percentage:34.1176%\n",
            "Epoch [379/1500], Training Loss: 1.3002, Validation Loss: 3.0685, Validation Accuracy: 0.3637, Percentage:36.3725%\n",
            "Epoch [380/1500], Training Loss: 1.4448, Validation Loss: 2.9036, Validation Accuracy: 0.3853, Percentage:38.5294%\n",
            "Epoch [381/1500], Training Loss: 1.3526, Validation Loss: 3.0354, Validation Accuracy: 0.3765, Percentage:37.6471%\n",
            "Epoch [382/1500], Training Loss: 1.3534, Validation Loss: 3.1112, Validation Accuracy: 0.3569, Percentage:35.6863%\n",
            "Epoch [383/1500], Training Loss: 1.3894, Validation Loss: 2.9910, Validation Accuracy: 0.3765, Percentage:37.6471%\n",
            "Epoch [384/1500], Training Loss: 1.4575, Validation Loss: 2.9306, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [385/1500], Training Loss: 1.4085, Validation Loss: 2.9183, Validation Accuracy: 0.3706, Percentage:37.0588%\n",
            "Epoch [386/1500], Training Loss: 1.3751, Validation Loss: 2.9283, Validation Accuracy: 0.3716, Percentage:37.1569%\n",
            "Epoch [387/1500], Training Loss: 1.3681, Validation Loss: 3.1546, Validation Accuracy: 0.3549, Percentage:35.4902%\n",
            "Epoch [388/1500], Training Loss: 1.4220, Validation Loss: 2.9116, Validation Accuracy: 0.3637, Percentage:36.3725%\n",
            "Epoch [389/1500], Training Loss: 1.5656, Validation Loss: 2.9754, Validation Accuracy: 0.3598, Percentage:35.9804%\n",
            "Epoch [390/1500], Training Loss: 1.3780, Validation Loss: 2.9732, Validation Accuracy: 0.3745, Percentage:37.4510%\n",
            "Epoch [391/1500], Training Loss: 1.3090, Validation Loss: 3.0324, Validation Accuracy: 0.3657, Percentage:36.5686%\n",
            "Epoch [392/1500], Training Loss: 1.2807, Validation Loss: 3.0413, Validation Accuracy: 0.3843, Percentage:38.4314%\n",
            "Epoch [393/1500], Training Loss: 1.3412, Validation Loss: 2.8230, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [394/1500], Training Loss: 1.3042, Validation Loss: 2.9003, Validation Accuracy: 0.3804, Percentage:38.0392%\n",
            "Epoch [395/1500], Training Loss: 1.4894, Validation Loss: 2.8581, Validation Accuracy: 0.3814, Percentage:38.1373%\n",
            "Epoch [396/1500], Training Loss: 1.4663, Validation Loss: 2.9851, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [397/1500], Training Loss: 1.3193, Validation Loss: 2.8817, Validation Accuracy: 0.3843, Percentage:38.4314%\n",
            "Epoch [398/1500], Training Loss: 1.3297, Validation Loss: 2.9353, Validation Accuracy: 0.3794, Percentage:37.9412%\n",
            "Epoch [399/1500], Training Loss: 1.4114, Validation Loss: 2.9054, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [400/1500], Training Loss: 1.3851, Validation Loss: 2.9469, Validation Accuracy: 0.3755, Percentage:37.5490%\n",
            "Epoch [401/1500], Training Loss: 1.4193, Validation Loss: 2.8918, Validation Accuracy: 0.3549, Percentage:35.4902%\n",
            "Epoch [402/1500], Training Loss: 1.3144, Validation Loss: 3.0729, Validation Accuracy: 0.3520, Percentage:35.1961%\n",
            "Epoch [403/1500], Training Loss: 1.3577, Validation Loss: 2.9645, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [404/1500], Training Loss: 1.3784, Validation Loss: 2.8603, Validation Accuracy: 0.3794, Percentage:37.9412%\n",
            "Epoch [405/1500], Training Loss: 1.3143, Validation Loss: 2.9680, Validation Accuracy: 0.3657, Percentage:36.5686%\n",
            "Epoch [406/1500], Training Loss: 1.3489, Validation Loss: 2.9898, Validation Accuracy: 0.3667, Percentage:36.6667%\n",
            "Epoch [407/1500], Training Loss: 1.3368, Validation Loss: 2.7937, Validation Accuracy: 0.3853, Percentage:38.5294%\n",
            "Epoch [408/1500], Training Loss: 1.3150, Validation Loss: 2.9619, Validation Accuracy: 0.3765, Percentage:37.6471%\n",
            "Epoch [409/1500], Training Loss: 1.3477, Validation Loss: 2.8705, Validation Accuracy: 0.3735, Percentage:37.3529%\n",
            "Epoch [410/1500], Training Loss: 1.3187, Validation Loss: 2.8753, Validation Accuracy: 0.3676, Percentage:36.7647%\n",
            "Epoch [411/1500], Training Loss: 1.4280, Validation Loss: 3.0229, Validation Accuracy: 0.3745, Percentage:37.4510%\n",
            "Epoch [412/1500], Training Loss: 1.3768, Validation Loss: 2.9086, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [413/1500], Training Loss: 1.1818, Validation Loss: 3.0842, Validation Accuracy: 0.3745, Percentage:37.4510%\n",
            "Epoch [414/1500], Training Loss: 1.4359, Validation Loss: 2.7591, Validation Accuracy: 0.3912, Percentage:39.1176%\n",
            "Epoch [415/1500], Training Loss: 1.2940, Validation Loss: 2.8471, Validation Accuracy: 0.3912, Percentage:39.1176%\n",
            "Epoch [416/1500], Training Loss: 1.2159, Validation Loss: 3.0592, Validation Accuracy: 0.3912, Percentage:39.1176%\n",
            "Epoch [417/1500], Training Loss: 1.3290, Validation Loss: 3.0796, Validation Accuracy: 0.3775, Percentage:37.7451%\n",
            "Epoch [418/1500], Training Loss: 1.2406, Validation Loss: 2.8910, Validation Accuracy: 0.3902, Percentage:39.0196%\n",
            "Epoch [419/1500], Training Loss: 1.4279, Validation Loss: 2.7757, Validation Accuracy: 0.3784, Percentage:37.8431%\n",
            "Epoch [420/1500], Training Loss: 1.3171, Validation Loss: 2.8970, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [421/1500], Training Loss: 1.3716, Validation Loss: 2.8170, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [422/1500], Training Loss: 1.4071, Validation Loss: 2.7990, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [423/1500], Training Loss: 1.2907, Validation Loss: 2.9755, Validation Accuracy: 0.3667, Percentage:36.6667%\n",
            "Epoch [424/1500], Training Loss: 1.2342, Validation Loss: 2.9396, Validation Accuracy: 0.3745, Percentage:37.4510%\n",
            "Epoch [425/1500], Training Loss: 1.2833, Validation Loss: 2.9171, Validation Accuracy: 0.3853, Percentage:38.5294%\n",
            "Epoch [426/1500], Training Loss: 1.4094, Validation Loss: 2.8135, Validation Accuracy: 0.3892, Percentage:38.9216%\n",
            "Epoch [427/1500], Training Loss: 1.2731, Validation Loss: 2.9648, Validation Accuracy: 0.3794, Percentage:37.9412%\n",
            "Epoch [428/1500], Training Loss: 1.3613, Validation Loss: 2.9224, Validation Accuracy: 0.3745, Percentage:37.4510%\n",
            "Epoch [429/1500], Training Loss: 1.2740, Validation Loss: 3.0223, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [430/1500], Training Loss: 1.3857, Validation Loss: 3.1428, Validation Accuracy: 0.3520, Percentage:35.1961%\n",
            "Epoch [431/1500], Training Loss: 1.2490, Validation Loss: 2.9534, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [432/1500], Training Loss: 1.3880, Validation Loss: 2.9397, Validation Accuracy: 0.3510, Percentage:35.0980%\n",
            "Epoch [433/1500], Training Loss: 1.3604, Validation Loss: 3.0370, Validation Accuracy: 0.3794, Percentage:37.9412%\n",
            "Epoch [434/1500], Training Loss: 1.2190, Validation Loss: 3.0327, Validation Accuracy: 0.3696, Percentage:36.9608%\n",
            "Epoch [435/1500], Training Loss: 1.3047, Validation Loss: 3.0422, Validation Accuracy: 0.3696, Percentage:36.9608%\n",
            "Epoch [436/1500], Training Loss: 1.3307, Validation Loss: 3.1659, Validation Accuracy: 0.3510, Percentage:35.0980%\n",
            "Epoch [437/1500], Training Loss: 1.3393, Validation Loss: 2.8792, Validation Accuracy: 0.3608, Percentage:36.0784%\n",
            "Epoch [438/1500], Training Loss: 1.2749, Validation Loss: 2.9523, Validation Accuracy: 0.3892, Percentage:38.9216%\n",
            "Epoch [439/1500], Training Loss: 1.2393, Validation Loss: 2.9901, Validation Accuracy: 0.3843, Percentage:38.4314%\n",
            "Epoch [440/1500], Training Loss: 1.2924, Validation Loss: 2.9458, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [441/1500], Training Loss: 1.3230, Validation Loss: 2.9878, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [442/1500], Training Loss: 1.3792, Validation Loss: 2.8144, Validation Accuracy: 0.3725, Percentage:37.2549%\n",
            "Epoch [443/1500], Training Loss: 1.3071, Validation Loss: 2.8886, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [444/1500], Training Loss: 1.2005, Validation Loss: 2.9078, Validation Accuracy: 0.3912, Percentage:39.1176%\n",
            "Epoch [445/1500], Training Loss: 1.3560, Validation Loss: 2.9440, Validation Accuracy: 0.3775, Percentage:37.7451%\n",
            "Epoch [446/1500], Training Loss: 1.2603, Validation Loss: 2.8680, Validation Accuracy: 0.3824, Percentage:38.2353%\n",
            "Epoch [447/1500], Training Loss: 1.2239, Validation Loss: 2.9409, Validation Accuracy: 0.3794, Percentage:37.9412%\n",
            "Epoch [448/1500], Training Loss: 1.2813, Validation Loss: 2.7881, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [449/1500], Training Loss: 1.2329, Validation Loss: 2.9502, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [450/1500], Training Loss: 1.1999, Validation Loss: 2.9876, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [451/1500], Training Loss: 1.2909, Validation Loss: 3.0111, Validation Accuracy: 0.3706, Percentage:37.0588%\n",
            "Epoch [452/1500], Training Loss: 1.3175, Validation Loss: 2.7694, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [453/1500], Training Loss: 1.1582, Validation Loss: 2.8534, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [454/1500], Training Loss: 1.1636, Validation Loss: 3.1046, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [455/1500], Training Loss: 1.2223, Validation Loss: 2.9552, Validation Accuracy: 0.3735, Percentage:37.3529%\n",
            "Epoch [456/1500], Training Loss: 1.2813, Validation Loss: 3.0103, Validation Accuracy: 0.3794, Percentage:37.9412%\n",
            "Epoch [457/1500], Training Loss: 1.2934, Validation Loss: 2.8850, Validation Accuracy: 0.3794, Percentage:37.9412%\n",
            "Epoch [458/1500], Training Loss: 1.3143, Validation Loss: 2.9937, Validation Accuracy: 0.3863, Percentage:38.6275%\n",
            "Epoch [459/1500], Training Loss: 1.3771, Validation Loss: 2.7852, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [460/1500], Training Loss: 1.2352, Validation Loss: 2.9689, Validation Accuracy: 0.3735, Percentage:37.3529%\n",
            "Epoch [461/1500], Training Loss: 1.1819, Validation Loss: 3.1390, Validation Accuracy: 0.3608, Percentage:36.0784%\n",
            "Epoch [462/1500], Training Loss: 1.1744, Validation Loss: 2.9666, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [463/1500], Training Loss: 1.2405, Validation Loss: 3.1016, Validation Accuracy: 0.3676, Percentage:36.7647%\n",
            "Epoch [464/1500], Training Loss: 1.2276, Validation Loss: 2.9941, Validation Accuracy: 0.3824, Percentage:38.2353%\n",
            "Epoch [465/1500], Training Loss: 1.2773, Validation Loss: 3.0467, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [466/1500], Training Loss: 1.2834, Validation Loss: 2.9772, Validation Accuracy: 0.3657, Percentage:36.5686%\n",
            "Epoch [467/1500], Training Loss: 1.2561, Validation Loss: 3.1345, Validation Accuracy: 0.3765, Percentage:37.6471%\n",
            "Epoch [468/1500], Training Loss: 1.2733, Validation Loss: 3.0714, Validation Accuracy: 0.3814, Percentage:38.1373%\n",
            "Epoch [469/1500], Training Loss: 1.3479, Validation Loss: 2.8227, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [470/1500], Training Loss: 1.2687, Validation Loss: 2.9769, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [471/1500], Training Loss: 1.2964, Validation Loss: 2.9569, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [472/1500], Training Loss: 1.2137, Validation Loss: 3.0076, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [473/1500], Training Loss: 1.2846, Validation Loss: 2.8757, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [474/1500], Training Loss: 1.2547, Validation Loss: 2.8530, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [475/1500], Training Loss: 1.2165, Validation Loss: 2.8768, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [476/1500], Training Loss: 1.2488, Validation Loss: 2.9030, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [477/1500], Training Loss: 1.2294, Validation Loss: 2.8909, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [478/1500], Training Loss: 1.1898, Validation Loss: 2.8732, Validation Accuracy: 0.3706, Percentage:37.0588%\n",
            "Epoch [479/1500], Training Loss: 1.1998, Validation Loss: 2.8411, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [480/1500], Training Loss: 1.1690, Validation Loss: 2.8918, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [481/1500], Training Loss: 1.1898, Validation Loss: 2.9020, Validation Accuracy: 0.3892, Percentage:38.9216%\n",
            "Epoch [482/1500], Training Loss: 1.2452, Validation Loss: 2.8397, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [483/1500], Training Loss: 1.2390, Validation Loss: 2.7434, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [484/1500], Training Loss: 1.1818, Validation Loss: 2.9345, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [485/1500], Training Loss: 1.2601, Validation Loss: 2.9660, Validation Accuracy: 0.3755, Percentage:37.5490%\n",
            "Epoch [486/1500], Training Loss: 1.2493, Validation Loss: 2.9659, Validation Accuracy: 0.3873, Percentage:38.7255%\n",
            "Epoch [487/1500], Training Loss: 1.2465, Validation Loss: 2.8957, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [488/1500], Training Loss: 1.2446, Validation Loss: 2.9595, Validation Accuracy: 0.3833, Percentage:38.3333%\n",
            "Epoch [489/1500], Training Loss: 1.2611, Validation Loss: 3.0383, Validation Accuracy: 0.3784, Percentage:37.8431%\n",
            "Epoch [490/1500], Training Loss: 1.1335, Validation Loss: 3.0612, Validation Accuracy: 0.3775, Percentage:37.7451%\n",
            "Epoch [491/1500], Training Loss: 1.1967, Validation Loss: 2.8361, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [492/1500], Training Loss: 1.2331, Validation Loss: 3.0972, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [493/1500], Training Loss: 1.1622, Validation Loss: 2.8497, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [494/1500], Training Loss: 1.2095, Validation Loss: 3.0809, Validation Accuracy: 0.3814, Percentage:38.1373%\n",
            "Epoch [495/1500], Training Loss: 1.2119, Validation Loss: 3.0154, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [496/1500], Training Loss: 1.1210, Validation Loss: 2.9725, Validation Accuracy: 0.4176, Percentage:41.7647%\n",
            "Epoch [497/1500], Training Loss: 1.1829, Validation Loss: 2.8249, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [498/1500], Training Loss: 1.2449, Validation Loss: 2.8731, Validation Accuracy: 0.4225, Percentage:42.2549%\n",
            "Epoch [499/1500], Training Loss: 1.2246, Validation Loss: 2.9982, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [500/1500], Training Loss: 1.2824, Validation Loss: 2.9953, Validation Accuracy: 0.3843, Percentage:38.4314%\n",
            "Epoch [501/1500], Training Loss: 1.2831, Validation Loss: 2.8797, Validation Accuracy: 0.3902, Percentage:39.0196%\n",
            "Epoch [502/1500], Training Loss: 1.1801, Validation Loss: 3.0197, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [503/1500], Training Loss: 1.2442, Validation Loss: 2.8168, Validation Accuracy: 0.3843, Percentage:38.4314%\n",
            "Epoch [504/1500], Training Loss: 1.2610, Validation Loss: 2.9464, Validation Accuracy: 0.3765, Percentage:37.6471%\n",
            "Epoch [505/1500], Training Loss: 1.2573, Validation Loss: 2.8939, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [506/1500], Training Loss: 1.1399, Validation Loss: 2.8569, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [507/1500], Training Loss: 1.2462, Validation Loss: 2.9411, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [508/1500], Training Loss: 1.1958, Validation Loss: 2.9176, Validation Accuracy: 0.3735, Percentage:37.3529%\n",
            "Epoch [509/1500], Training Loss: 1.2052, Validation Loss: 2.8706, Validation Accuracy: 0.3853, Percentage:38.5294%\n",
            "Epoch [510/1500], Training Loss: 1.2315, Validation Loss: 2.9813, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [511/1500], Training Loss: 1.1440, Validation Loss: 3.0941, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [512/1500], Training Loss: 1.1796, Validation Loss: 3.0068, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [513/1500], Training Loss: 1.2192, Validation Loss: 3.0436, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [514/1500], Training Loss: 1.1669, Validation Loss: 2.9415, Validation Accuracy: 0.3824, Percentage:38.2353%\n",
            "Epoch [515/1500], Training Loss: 1.1609, Validation Loss: 3.1225, Validation Accuracy: 0.3912, Percentage:39.1176%\n",
            "Epoch [516/1500], Training Loss: 1.2068, Validation Loss: 2.8031, Validation Accuracy: 0.3912, Percentage:39.1176%\n",
            "Epoch [517/1500], Training Loss: 1.1537, Validation Loss: 2.9855, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [518/1500], Training Loss: 1.1475, Validation Loss: 2.8896, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [519/1500], Training Loss: 1.2643, Validation Loss: 3.0272, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [520/1500], Training Loss: 1.1193, Validation Loss: 2.9943, Validation Accuracy: 0.3902, Percentage:39.0196%\n",
            "Epoch [521/1500], Training Loss: 1.1423, Validation Loss: 3.0542, Validation Accuracy: 0.3902, Percentage:39.0196%\n",
            "Epoch [522/1500], Training Loss: 1.3172, Validation Loss: 2.8947, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [523/1500], Training Loss: 1.1751, Validation Loss: 3.0684, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [524/1500], Training Loss: 1.1044, Validation Loss: 2.9929, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [525/1500], Training Loss: 1.1900, Validation Loss: 3.0807, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [526/1500], Training Loss: 1.1624, Validation Loss: 2.9890, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [527/1500], Training Loss: 1.1224, Validation Loss: 3.0557, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [528/1500], Training Loss: 1.1607, Validation Loss: 2.9735, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [529/1500], Training Loss: 1.1377, Validation Loss: 2.9489, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [530/1500], Training Loss: 1.1659, Validation Loss: 3.0720, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [531/1500], Training Loss: 1.1626, Validation Loss: 2.9154, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [532/1500], Training Loss: 1.1827, Validation Loss: 3.1117, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [533/1500], Training Loss: 1.2675, Validation Loss: 2.7541, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [534/1500], Training Loss: 1.1838, Validation Loss: 3.0317, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [535/1500], Training Loss: 1.2432, Validation Loss: 2.8771, Validation Accuracy: 0.4176, Percentage:41.7647%\n",
            "Epoch [536/1500], Training Loss: 1.2731, Validation Loss: 2.8161, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [537/1500], Training Loss: 1.1226, Validation Loss: 3.2288, Validation Accuracy: 0.3824, Percentage:38.2353%\n",
            "Epoch [538/1500], Training Loss: 1.1489, Validation Loss: 3.1204, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [539/1500], Training Loss: 1.1712, Validation Loss: 3.1027, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [540/1500], Training Loss: 1.1773, Validation Loss: 2.9355, Validation Accuracy: 0.3686, Percentage:36.8627%\n",
            "Epoch [541/1500], Training Loss: 1.1780, Validation Loss: 2.8562, Validation Accuracy: 0.3892, Percentage:38.9216%\n",
            "Epoch [542/1500], Training Loss: 1.2375, Validation Loss: 2.8321, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [543/1500], Training Loss: 1.1967, Validation Loss: 2.9043, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [544/1500], Training Loss: 1.1531, Validation Loss: 3.0569, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [545/1500], Training Loss: 1.1517, Validation Loss: 2.9782, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [546/1500], Training Loss: 1.2448, Validation Loss: 2.9729, Validation Accuracy: 0.3784, Percentage:37.8431%\n",
            "Epoch [547/1500], Training Loss: 1.2271, Validation Loss: 3.0986, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [548/1500], Training Loss: 1.1087, Validation Loss: 3.0797, Validation Accuracy: 0.3882, Percentage:38.8235%\n",
            "Epoch [549/1500], Training Loss: 1.2438, Validation Loss: 2.7835, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [550/1500], Training Loss: 1.1723, Validation Loss: 2.9096, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [551/1500], Training Loss: 1.0765, Validation Loss: 2.9417, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [552/1500], Training Loss: 1.1897, Validation Loss: 3.0088, Validation Accuracy: 0.3902, Percentage:39.0196%\n",
            "Epoch [553/1500], Training Loss: 1.1459, Validation Loss: 2.8718, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [554/1500], Training Loss: 1.1296, Validation Loss: 2.8623, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [555/1500], Training Loss: 1.1482, Validation Loss: 2.8627, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [556/1500], Training Loss: 1.1327, Validation Loss: 3.0144, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [557/1500], Training Loss: 1.1500, Validation Loss: 3.0246, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [558/1500], Training Loss: 1.1050, Validation Loss: 2.8385, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [559/1500], Training Loss: 1.1871, Validation Loss: 2.9898, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [560/1500], Training Loss: 1.2200, Validation Loss: 2.9418, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [561/1500], Training Loss: 1.0430, Validation Loss: 3.0212, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [562/1500], Training Loss: 1.2282, Validation Loss: 3.0577, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [563/1500], Training Loss: 1.1159, Validation Loss: 3.0459, Validation Accuracy: 0.3814, Percentage:38.1373%\n",
            "Epoch [564/1500], Training Loss: 1.1810, Validation Loss: 3.0390, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [565/1500], Training Loss: 1.2105, Validation Loss: 3.0032, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [566/1500], Training Loss: 1.1425, Validation Loss: 3.1497, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [567/1500], Training Loss: 1.1255, Validation Loss: 3.0866, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [568/1500], Training Loss: 1.1460, Validation Loss: 2.9884, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [569/1500], Training Loss: 1.1428, Validation Loss: 2.9118, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [570/1500], Training Loss: 1.1276, Validation Loss: 3.0436, Validation Accuracy: 0.3902, Percentage:39.0196%\n",
            "Epoch [571/1500], Training Loss: 1.1214, Validation Loss: 2.8650, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [572/1500], Training Loss: 1.1343, Validation Loss: 2.9542, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [573/1500], Training Loss: 1.0961, Validation Loss: 2.7599, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [574/1500], Training Loss: 1.0358, Validation Loss: 3.1885, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [575/1500], Training Loss: 1.2033, Validation Loss: 3.1054, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [576/1500], Training Loss: 1.1402, Validation Loss: 2.9366, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [577/1500], Training Loss: 1.1577, Validation Loss: 2.9289, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [578/1500], Training Loss: 1.1622, Validation Loss: 2.9681, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [579/1500], Training Loss: 1.1980, Validation Loss: 2.8922, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [580/1500], Training Loss: 1.0529, Validation Loss: 2.9718, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [581/1500], Training Loss: 1.0556, Validation Loss: 3.0039, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [582/1500], Training Loss: 1.1623, Validation Loss: 2.8815, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [583/1500], Training Loss: 1.1510, Validation Loss: 3.0315, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [584/1500], Training Loss: 1.0571, Validation Loss: 2.7820, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [585/1500], Training Loss: 1.0973, Validation Loss: 3.1509, Validation Accuracy: 0.3892, Percentage:38.9216%\n",
            "Epoch [586/1500], Training Loss: 1.1318, Validation Loss: 2.8558, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [587/1500], Training Loss: 1.0380, Validation Loss: 2.9585, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [588/1500], Training Loss: 1.2246, Validation Loss: 2.8829, Validation Accuracy: 0.4176, Percentage:41.7647%\n",
            "Epoch [589/1500], Training Loss: 1.2028, Validation Loss: 3.1181, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [590/1500], Training Loss: 1.1324, Validation Loss: 2.7629, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [591/1500], Training Loss: 1.1461, Validation Loss: 3.0856, Validation Accuracy: 0.4176, Percentage:41.7647%\n",
            "Epoch [592/1500], Training Loss: 1.2064, Validation Loss: 2.8890, Validation Accuracy: 0.3804, Percentage:38.0392%\n",
            "Epoch [593/1500], Training Loss: 1.1481, Validation Loss: 2.9152, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [594/1500], Training Loss: 1.0851, Validation Loss: 3.1771, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [595/1500], Training Loss: 1.1045, Validation Loss: 3.0881, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [596/1500], Training Loss: 1.1140, Validation Loss: 3.0404, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [597/1500], Training Loss: 1.2513, Validation Loss: 2.9242, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [598/1500], Training Loss: 1.2014, Validation Loss: 2.9380, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [599/1500], Training Loss: 1.0442, Validation Loss: 2.8631, Validation Accuracy: 0.4225, Percentage:42.2549%\n",
            "Epoch [600/1500], Training Loss: 1.0885, Validation Loss: 2.7541, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [601/1500], Training Loss: 1.1175, Validation Loss: 2.9886, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [602/1500], Training Loss: 1.0854, Validation Loss: 3.0692, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [603/1500], Training Loss: 1.1317, Validation Loss: 3.0257, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [604/1500], Training Loss: 1.0585, Validation Loss: 2.8930, Validation Accuracy: 0.3843, Percentage:38.4314%\n",
            "Epoch [605/1500], Training Loss: 1.1598, Validation Loss: 2.8171, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [606/1500], Training Loss: 1.0542, Validation Loss: 2.9853, Validation Accuracy: 0.3912, Percentage:39.1176%\n",
            "Epoch [607/1500], Training Loss: 1.2182, Validation Loss: 3.0861, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [608/1500], Training Loss: 1.1572, Validation Loss: 3.0530, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [609/1500], Training Loss: 1.0930, Validation Loss: 3.0644, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [610/1500], Training Loss: 1.0809, Validation Loss: 2.9760, Validation Accuracy: 0.3833, Percentage:38.3333%\n",
            "Epoch [611/1500], Training Loss: 1.1899, Validation Loss: 3.0045, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [612/1500], Training Loss: 1.0500, Validation Loss: 3.3497, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [613/1500], Training Loss: 1.2125, Validation Loss: 2.9981, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [614/1500], Training Loss: 1.1524, Validation Loss: 3.2984, Validation Accuracy: 0.3882, Percentage:38.8235%\n",
            "Epoch [615/1500], Training Loss: 1.1093, Validation Loss: 2.9635, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [616/1500], Training Loss: 1.1067, Validation Loss: 3.1278, Validation Accuracy: 0.3882, Percentage:38.8235%\n",
            "Epoch [617/1500], Training Loss: 1.0736, Validation Loss: 2.9592, Validation Accuracy: 0.3912, Percentage:39.1176%\n",
            "Epoch [618/1500], Training Loss: 1.0426, Validation Loss: 3.0852, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [619/1500], Training Loss: 1.1203, Validation Loss: 2.9873, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [620/1500], Training Loss: 1.2039, Validation Loss: 3.0480, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [621/1500], Training Loss: 1.1041, Validation Loss: 2.9494, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [622/1500], Training Loss: 1.0851, Validation Loss: 3.0648, Validation Accuracy: 0.3922, Percentage:39.2157%\n",
            "Epoch [623/1500], Training Loss: 1.0921, Validation Loss: 2.9851, Validation Accuracy: 0.4206, Percentage:42.0588%\n",
            "Epoch [624/1500], Training Loss: 1.0857, Validation Loss: 2.9720, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [625/1500], Training Loss: 1.0633, Validation Loss: 2.9026, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [626/1500], Training Loss: 1.1270, Validation Loss: 2.9436, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [627/1500], Training Loss: 1.0868, Validation Loss: 2.9800, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [628/1500], Training Loss: 1.0486, Validation Loss: 3.0426, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [629/1500], Training Loss: 1.0557, Validation Loss: 2.8876, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [630/1500], Training Loss: 1.0560, Validation Loss: 2.9647, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [631/1500], Training Loss: 1.1273, Validation Loss: 2.9966, Validation Accuracy: 0.3912, Percentage:39.1176%\n",
            "Epoch [632/1500], Training Loss: 1.1602, Validation Loss: 3.0587, Validation Accuracy: 0.3843, Percentage:38.4314%\n",
            "Epoch [633/1500], Training Loss: 1.3576, Validation Loss: 2.7885, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [634/1500], Training Loss: 1.0498, Validation Loss: 3.1551, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [635/1500], Training Loss: 1.0298, Validation Loss: 2.9267, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [636/1500], Training Loss: 1.0867, Validation Loss: 3.0908, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [637/1500], Training Loss: 1.2387, Validation Loss: 2.7922, Validation Accuracy: 0.4284, Percentage:42.8431%\n",
            "Epoch [638/1500], Training Loss: 1.2247, Validation Loss: 3.0231, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [639/1500], Training Loss: 1.0723, Validation Loss: 3.0921, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [640/1500], Training Loss: 1.0809, Validation Loss: 2.9607, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [641/1500], Training Loss: 1.0881, Validation Loss: 3.0974, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [642/1500], Training Loss: 1.1681, Validation Loss: 3.1973, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [643/1500], Training Loss: 1.0778, Validation Loss: 3.1148, Validation Accuracy: 0.3931, Percentage:39.3137%\n",
            "Epoch [644/1500], Training Loss: 1.1778, Validation Loss: 2.9964, Validation Accuracy: 0.3892, Percentage:38.9216%\n",
            "Epoch [645/1500], Training Loss: 1.1265, Validation Loss: 2.7947, Validation Accuracy: 0.4225, Percentage:42.2549%\n",
            "Epoch [646/1500], Training Loss: 1.1683, Validation Loss: 2.7742, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [647/1500], Training Loss: 1.0158, Validation Loss: 2.9339, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [648/1500], Training Loss: 0.9925, Validation Loss: 2.7769, Validation Accuracy: 0.4176, Percentage:41.7647%\n",
            "Epoch [649/1500], Training Loss: 0.9805, Validation Loss: 3.0969, Validation Accuracy: 0.4225, Percentage:42.2549%\n",
            "Epoch [650/1500], Training Loss: 1.0465, Validation Loss: 3.1821, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [651/1500], Training Loss: 1.0487, Validation Loss: 2.8560, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [652/1500], Training Loss: 1.1025, Validation Loss: 3.0762, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [653/1500], Training Loss: 1.0378, Validation Loss: 2.9110, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [654/1500], Training Loss: 1.0700, Validation Loss: 3.1346, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [655/1500], Training Loss: 1.0743, Validation Loss: 2.8878, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [656/1500], Training Loss: 1.0823, Validation Loss: 2.9872, Validation Accuracy: 0.4206, Percentage:42.0588%\n",
            "Epoch [657/1500], Training Loss: 0.9845, Validation Loss: 2.9684, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [658/1500], Training Loss: 1.1701, Validation Loss: 3.2000, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [659/1500], Training Loss: 1.0622, Validation Loss: 3.0791, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [660/1500], Training Loss: 1.0251, Validation Loss: 3.1104, Validation Accuracy: 0.3863, Percentage:38.6275%\n",
            "Epoch [661/1500], Training Loss: 1.0383, Validation Loss: 3.0257, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [662/1500], Training Loss: 1.0731, Validation Loss: 3.0432, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [663/1500], Training Loss: 1.0143, Validation Loss: 2.9888, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [664/1500], Training Loss: 1.0290, Validation Loss: 3.0128, Validation Accuracy: 0.4225, Percentage:42.2549%\n",
            "Epoch [665/1500], Training Loss: 1.0710, Validation Loss: 2.9141, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [666/1500], Training Loss: 1.0016, Validation Loss: 2.8992, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [667/1500], Training Loss: 1.1412, Validation Loss: 3.1005, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [668/1500], Training Loss: 1.0694, Validation Loss: 2.9426, Validation Accuracy: 0.4206, Percentage:42.0588%\n",
            "Epoch [669/1500], Training Loss: 1.2003, Validation Loss: 3.0227, Validation Accuracy: 0.3882, Percentage:38.8235%\n",
            "Epoch [670/1500], Training Loss: 1.0276, Validation Loss: 2.9077, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [671/1500], Training Loss: 1.0311, Validation Loss: 3.1239, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [672/1500], Training Loss: 1.1139, Validation Loss: 3.1450, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [673/1500], Training Loss: 1.0447, Validation Loss: 2.8796, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [674/1500], Training Loss: 1.0714, Validation Loss: 2.8648, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [675/1500], Training Loss: 1.0237, Validation Loss: 3.0609, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [676/1500], Training Loss: 1.1632, Validation Loss: 3.0430, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [677/1500], Training Loss: 0.9016, Validation Loss: 3.0330, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [678/1500], Training Loss: 1.0421, Validation Loss: 2.9985, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [679/1500], Training Loss: 1.0947, Validation Loss: 3.0599, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [680/1500], Training Loss: 1.0810, Validation Loss: 3.0460, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [681/1500], Training Loss: 1.0965, Validation Loss: 2.9713, Validation Accuracy: 0.4284, Percentage:42.8431%\n",
            "Epoch [682/1500], Training Loss: 1.1505, Validation Loss: 3.0764, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [683/1500], Training Loss: 1.0510, Validation Loss: 3.1085, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [684/1500], Training Loss: 1.0508, Validation Loss: 3.0716, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [685/1500], Training Loss: 1.0449, Validation Loss: 2.6776, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [686/1500], Training Loss: 1.0687, Validation Loss: 2.8286, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [687/1500], Training Loss: 0.9210, Validation Loss: 3.3873, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [688/1500], Training Loss: 1.1235, Validation Loss: 3.0664, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [689/1500], Training Loss: 1.1419, Validation Loss: 2.9413, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [690/1500], Training Loss: 1.0452, Validation Loss: 3.1078, Validation Accuracy: 0.3961, Percentage:39.6078%\n",
            "Epoch [691/1500], Training Loss: 1.0133, Validation Loss: 2.9519, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [692/1500], Training Loss: 1.0255, Validation Loss: 2.9864, Validation Accuracy: 0.4176, Percentage:41.7647%\n",
            "Epoch [693/1500], Training Loss: 1.0460, Validation Loss: 3.0254, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [694/1500], Training Loss: 0.9923, Validation Loss: 3.0620, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [695/1500], Training Loss: 1.0721, Validation Loss: 3.1805, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [696/1500], Training Loss: 1.0389, Validation Loss: 2.8369, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [697/1500], Training Loss: 1.0114, Validation Loss: 3.0593, Validation Accuracy: 0.3941, Percentage:39.4118%\n",
            "Epoch [698/1500], Training Loss: 1.0183, Validation Loss: 2.8849, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [699/1500], Training Loss: 1.1163, Validation Loss: 2.8319, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [700/1500], Training Loss: 1.0468, Validation Loss: 3.1928, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [701/1500], Training Loss: 1.0588, Validation Loss: 3.2269, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [702/1500], Training Loss: 1.1024, Validation Loss: 2.9463, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [703/1500], Training Loss: 1.0655, Validation Loss: 3.2623, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [704/1500], Training Loss: 1.1799, Validation Loss: 2.9930, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [705/1500], Training Loss: 1.0253, Validation Loss: 3.1215, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [706/1500], Training Loss: 1.0941, Validation Loss: 3.5957, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [707/1500], Training Loss: 1.0014, Validation Loss: 3.0342, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [708/1500], Training Loss: 1.0491, Validation Loss: 3.0123, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [709/1500], Training Loss: 1.0840, Validation Loss: 3.0289, Validation Accuracy: 0.3882, Percentage:38.8235%\n",
            "Epoch [710/1500], Training Loss: 0.9995, Validation Loss: 2.8820, Validation Accuracy: 0.4284, Percentage:42.8431%\n",
            "Epoch [711/1500], Training Loss: 0.9702, Validation Loss: 2.9890, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [712/1500], Training Loss: 1.0852, Validation Loss: 2.9361, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [713/1500], Training Loss: 1.0139, Validation Loss: 3.0079, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [714/1500], Training Loss: 1.1302, Validation Loss: 2.7066, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [715/1500], Training Loss: 0.9964, Validation Loss: 2.9426, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [716/1500], Training Loss: 1.1293, Validation Loss: 2.9421, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [717/1500], Training Loss: 1.0049, Validation Loss: 3.0740, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [718/1500], Training Loss: 1.1013, Validation Loss: 2.9412, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [719/1500], Training Loss: 0.9894, Validation Loss: 3.1183, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [720/1500], Training Loss: 1.1021, Validation Loss: 2.9043, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [721/1500], Training Loss: 0.9251, Validation Loss: 2.8676, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [722/1500], Training Loss: 1.0146, Validation Loss: 3.0888, Validation Accuracy: 0.4265, Percentage:42.6471%\n",
            "Epoch [723/1500], Training Loss: 1.0788, Validation Loss: 3.2382, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [724/1500], Training Loss: 0.9780, Validation Loss: 3.2426, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [725/1500], Training Loss: 0.9955, Validation Loss: 3.2025, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [726/1500], Training Loss: 1.1727, Validation Loss: 3.2892, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [727/1500], Training Loss: 1.0896, Validation Loss: 2.9841, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [728/1500], Training Loss: 1.0446, Validation Loss: 2.7462, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [729/1500], Training Loss: 1.0168, Validation Loss: 3.0400, Validation Accuracy: 0.4176, Percentage:41.7647%\n",
            "Epoch [730/1500], Training Loss: 1.0530, Validation Loss: 3.2498, Validation Accuracy: 0.4265, Percentage:42.6471%\n",
            "Epoch [731/1500], Training Loss: 0.9083, Validation Loss: 3.0128, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [732/1500], Training Loss: 1.0862, Validation Loss: 2.8945, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [733/1500], Training Loss: 0.9273, Validation Loss: 3.2135, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [734/1500], Training Loss: 1.0082, Validation Loss: 3.2840, Validation Accuracy: 0.3725, Percentage:37.2549%\n",
            "Epoch [735/1500], Training Loss: 1.0317, Validation Loss: 2.9964, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [736/1500], Training Loss: 0.9833, Validation Loss: 2.9627, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [737/1500], Training Loss: 0.9805, Validation Loss: 3.1621, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [738/1500], Training Loss: 0.9725, Validation Loss: 2.9909, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [739/1500], Training Loss: 0.9749, Validation Loss: 3.0011, Validation Accuracy: 0.4284, Percentage:42.8431%\n",
            "Epoch [740/1500], Training Loss: 1.0070, Validation Loss: 2.8614, Validation Accuracy: 0.4284, Percentage:42.8431%\n",
            "Epoch [741/1500], Training Loss: 1.0313, Validation Loss: 3.0343, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [742/1500], Training Loss: 1.0220, Validation Loss: 2.7552, Validation Accuracy: 0.4284, Percentage:42.8431%\n",
            "Epoch [743/1500], Training Loss: 1.0506, Validation Loss: 2.9696, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [744/1500], Training Loss: 0.9240, Validation Loss: 3.2894, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [745/1500], Training Loss: 0.9955, Validation Loss: 3.6596, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [746/1500], Training Loss: 1.0417, Validation Loss: 3.0510, Validation Accuracy: 0.4225, Percentage:42.2549%\n",
            "Epoch [747/1500], Training Loss: 1.0202, Validation Loss: 2.9347, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [748/1500], Training Loss: 0.9887, Validation Loss: 2.9100, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [749/1500], Training Loss: 1.0479, Validation Loss: 2.7861, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [750/1500], Training Loss: 0.9578, Validation Loss: 2.9346, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [751/1500], Training Loss: 1.0110, Validation Loss: 3.0007, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [752/1500], Training Loss: 0.9749, Validation Loss: 3.0671, Validation Accuracy: 0.4284, Percentage:42.8431%\n",
            "Epoch [753/1500], Training Loss: 1.0206, Validation Loss: 2.9336, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [754/1500], Training Loss: 1.0129, Validation Loss: 3.0533, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [755/1500], Training Loss: 0.9387, Validation Loss: 3.1019, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [756/1500], Training Loss: 0.9023, Validation Loss: 3.1026, Validation Accuracy: 0.4176, Percentage:41.7647%\n",
            "Epoch [757/1500], Training Loss: 1.0189, Validation Loss: 2.9221, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [758/1500], Training Loss: 0.9989, Validation Loss: 3.2645, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [759/1500], Training Loss: 1.0302, Validation Loss: 3.1552, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [760/1500], Training Loss: 1.0622, Validation Loss: 2.9015, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [761/1500], Training Loss: 1.0608, Validation Loss: 3.0211, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [762/1500], Training Loss: 1.0081, Validation Loss: 3.0586, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [763/1500], Training Loss: 0.8767, Validation Loss: 2.9030, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [764/1500], Training Loss: 1.0325, Validation Loss: 3.0483, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [765/1500], Training Loss: 0.9728, Validation Loss: 3.0054, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [766/1500], Training Loss: 1.2376, Validation Loss: 2.9444, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [767/1500], Training Loss: 0.9895, Validation Loss: 2.9642, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [768/1500], Training Loss: 1.0459, Validation Loss: 3.1851, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [769/1500], Training Loss: 1.1312, Validation Loss: 3.0470, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [770/1500], Training Loss: 0.9926, Validation Loss: 3.0515, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [771/1500], Training Loss: 1.0367, Validation Loss: 2.8216, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [772/1500], Training Loss: 1.0698, Validation Loss: 2.8757, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [773/1500], Training Loss: 1.0788, Validation Loss: 3.1785, Validation Accuracy: 0.3990, Percentage:39.9020%\n",
            "Epoch [774/1500], Training Loss: 0.9312, Validation Loss: 3.3125, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [775/1500], Training Loss: 1.0321, Validation Loss: 3.1472, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [776/1500], Training Loss: 0.9645, Validation Loss: 3.0631, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [777/1500], Training Loss: 1.0082, Validation Loss: 3.1067, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [778/1500], Training Loss: 0.9852, Validation Loss: 2.9050, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [779/1500], Training Loss: 1.0222, Validation Loss: 2.8752, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [780/1500], Training Loss: 0.9323, Validation Loss: 3.1334, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [781/1500], Training Loss: 1.0801, Validation Loss: 2.9076, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [782/1500], Training Loss: 1.1332, Validation Loss: 2.8642, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [783/1500], Training Loss: 0.9665, Validation Loss: 3.1291, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [784/1500], Training Loss: 0.9588, Validation Loss: 2.9348, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [785/1500], Training Loss: 1.0360, Validation Loss: 2.8162, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [786/1500], Training Loss: 1.0864, Validation Loss: 3.0367, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [787/1500], Training Loss: 1.0615, Validation Loss: 3.1286, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [788/1500], Training Loss: 1.0182, Validation Loss: 3.1237, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [789/1500], Training Loss: 0.9822, Validation Loss: 3.2729, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [790/1500], Training Loss: 1.0153, Validation Loss: 2.9598, Validation Accuracy: 0.4265, Percentage:42.6471%\n",
            "Epoch [791/1500], Training Loss: 1.0002, Validation Loss: 2.9340, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [792/1500], Training Loss: 0.9907, Validation Loss: 2.9381, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [793/1500], Training Loss: 0.9907, Validation Loss: 2.9979, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [794/1500], Training Loss: 0.9631, Validation Loss: 3.0718, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [795/1500], Training Loss: 0.9928, Validation Loss: 3.1952, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [796/1500], Training Loss: 1.0514, Validation Loss: 3.1458, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [797/1500], Training Loss: 0.9334, Validation Loss: 3.1315, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [798/1500], Training Loss: 0.9582, Validation Loss: 3.1367, Validation Accuracy: 0.3912, Percentage:39.1176%\n",
            "Epoch [799/1500], Training Loss: 1.0519, Validation Loss: 2.9994, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [800/1500], Training Loss: 1.0097, Validation Loss: 3.0826, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [801/1500], Training Loss: 1.0162, Validation Loss: 3.0599, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [802/1500], Training Loss: 1.1257, Validation Loss: 2.9799, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [803/1500], Training Loss: 1.0511, Validation Loss: 3.1273, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [804/1500], Training Loss: 0.9764, Validation Loss: 3.0598, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [805/1500], Training Loss: 1.0359, Validation Loss: 3.3180, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [806/1500], Training Loss: 1.0912, Validation Loss: 2.8471, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [807/1500], Training Loss: 0.9657, Validation Loss: 3.0953, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [808/1500], Training Loss: 0.9096, Validation Loss: 2.8344, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [809/1500], Training Loss: 1.0171, Validation Loss: 3.2220, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [810/1500], Training Loss: 1.0157, Validation Loss: 3.1461, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [811/1500], Training Loss: 1.0337, Validation Loss: 2.9204, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [812/1500], Training Loss: 0.9639, Validation Loss: 3.1757, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [813/1500], Training Loss: 1.0594, Validation Loss: 2.7519, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [814/1500], Training Loss: 1.0580, Validation Loss: 2.8904, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [815/1500], Training Loss: 1.0068, Validation Loss: 3.1523, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [816/1500], Training Loss: 1.0452, Validation Loss: 3.0635, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [817/1500], Training Loss: 0.9402, Validation Loss: 2.9056, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [818/1500], Training Loss: 1.0739, Validation Loss: 2.9433, Validation Accuracy: 0.4284, Percentage:42.8431%\n",
            "Epoch [819/1500], Training Loss: 1.0883, Validation Loss: 2.9849, Validation Accuracy: 0.4225, Percentage:42.2549%\n",
            "Epoch [820/1500], Training Loss: 0.9044, Validation Loss: 3.0412, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [821/1500], Training Loss: 1.0927, Validation Loss: 2.9810, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [822/1500], Training Loss: 1.0893, Validation Loss: 3.0937, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [823/1500], Training Loss: 0.9535, Validation Loss: 3.0209, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [824/1500], Training Loss: 0.9619, Validation Loss: 2.9913, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [825/1500], Training Loss: 1.0026, Validation Loss: 3.0413, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [826/1500], Training Loss: 1.0262, Validation Loss: 2.8120, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [827/1500], Training Loss: 0.8757, Validation Loss: 3.2131, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [828/1500], Training Loss: 1.0207, Validation Loss: 3.1282, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [829/1500], Training Loss: 1.0325, Validation Loss: 3.1583, Validation Accuracy: 0.3971, Percentage:39.7059%\n",
            "Epoch [830/1500], Training Loss: 1.0877, Validation Loss: 2.9922, Validation Accuracy: 0.4225, Percentage:42.2549%\n",
            "Epoch [831/1500], Training Loss: 1.0093, Validation Loss: 2.8644, Validation Accuracy: 0.3951, Percentage:39.5098%\n",
            "Epoch [832/1500], Training Loss: 0.9667, Validation Loss: 2.8822, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [833/1500], Training Loss: 0.9825, Validation Loss: 3.0332, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [834/1500], Training Loss: 0.9585, Validation Loss: 3.1081, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [835/1500], Training Loss: 1.0196, Validation Loss: 3.0065, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [836/1500], Training Loss: 1.0104, Validation Loss: 3.0881, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [837/1500], Training Loss: 0.9853, Validation Loss: 3.0857, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [838/1500], Training Loss: 0.9938, Validation Loss: 2.9606, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [839/1500], Training Loss: 1.1058, Validation Loss: 3.0192, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [840/1500], Training Loss: 1.0251, Validation Loss: 2.9418, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [841/1500], Training Loss: 0.9501, Validation Loss: 3.0960, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [842/1500], Training Loss: 0.9664, Validation Loss: 3.1301, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [843/1500], Training Loss: 0.9253, Validation Loss: 2.9400, Validation Accuracy: 0.4206, Percentage:42.0588%\n",
            "Epoch [844/1500], Training Loss: 1.0213, Validation Loss: 2.9868, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [845/1500], Training Loss: 0.9652, Validation Loss: 3.1669, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [846/1500], Training Loss: 0.9398, Validation Loss: 2.7670, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [847/1500], Training Loss: 0.9328, Validation Loss: 3.2565, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [848/1500], Training Loss: 1.0590, Validation Loss: 3.1825, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [849/1500], Training Loss: 0.9881, Validation Loss: 2.9399, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [850/1500], Training Loss: 0.9525, Validation Loss: 2.9751, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [851/1500], Training Loss: 0.9677, Validation Loss: 2.9466, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [852/1500], Training Loss: 0.8981, Validation Loss: 3.1139, Validation Accuracy: 0.4108, Percentage:41.0784%\n",
            "Epoch [853/1500], Training Loss: 1.0017, Validation Loss: 2.7764, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [854/1500], Training Loss: 0.9783, Validation Loss: 3.1856, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [855/1500], Training Loss: 0.9679, Validation Loss: 3.0716, Validation Accuracy: 0.4176, Percentage:41.7647%\n",
            "Epoch [856/1500], Training Loss: 1.0057, Validation Loss: 3.0125, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [857/1500], Training Loss: 0.9507, Validation Loss: 3.1664, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [858/1500], Training Loss: 0.8655, Validation Loss: 2.9549, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [859/1500], Training Loss: 0.9452, Validation Loss: 3.0792, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [860/1500], Training Loss: 0.9919, Validation Loss: 3.1495, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [861/1500], Training Loss: 0.9403, Validation Loss: 3.2817, Validation Accuracy: 0.4206, Percentage:42.0588%\n",
            "Epoch [862/1500], Training Loss: 0.9608, Validation Loss: 3.1503, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [863/1500], Training Loss: 0.9759, Validation Loss: 3.0183, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [864/1500], Training Loss: 0.9375, Validation Loss: 2.9066, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [865/1500], Training Loss: 0.9290, Validation Loss: 3.2395, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [866/1500], Training Loss: 0.9639, Validation Loss: 2.9556, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [867/1500], Training Loss: 0.9610, Validation Loss: 2.9788, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [868/1500], Training Loss: 0.9384, Validation Loss: 3.0447, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [869/1500], Training Loss: 0.9646, Validation Loss: 3.0730, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [870/1500], Training Loss: 0.9409, Validation Loss: 3.1011, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [871/1500], Training Loss: 0.9622, Validation Loss: 3.1014, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [872/1500], Training Loss: 0.9826, Validation Loss: 3.0300, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [873/1500], Training Loss: 1.0138, Validation Loss: 2.9957, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [874/1500], Training Loss: 1.0687, Validation Loss: 2.9047, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [875/1500], Training Loss: 0.8935, Validation Loss: 3.0240, Validation Accuracy: 0.4206, Percentage:42.0588%\n",
            "Epoch [876/1500], Training Loss: 1.0016, Validation Loss: 3.0423, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [877/1500], Training Loss: 0.9661, Validation Loss: 2.9537, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [878/1500], Training Loss: 1.0060, Validation Loss: 2.8931, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [879/1500], Training Loss: 0.8874, Validation Loss: 2.8091, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [880/1500], Training Loss: 0.9555, Validation Loss: 3.1018, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [881/1500], Training Loss: 0.9576, Validation Loss: 3.2240, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [882/1500], Training Loss: 1.0264, Validation Loss: 3.0917, Validation Accuracy: 0.4029, Percentage:40.2941%\n",
            "Epoch [883/1500], Training Loss: 0.9517, Validation Loss: 3.0722, Validation Accuracy: 0.4265, Percentage:42.6471%\n",
            "Epoch [884/1500], Training Loss: 0.9695, Validation Loss: 3.1794, Validation Accuracy: 0.4176, Percentage:41.7647%\n",
            "Epoch [885/1500], Training Loss: 0.9607, Validation Loss: 3.1272, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [886/1500], Training Loss: 0.9899, Validation Loss: 2.9771, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [887/1500], Training Loss: 0.8949, Validation Loss: 2.8706, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [888/1500], Training Loss: 1.0735, Validation Loss: 3.0761, Validation Accuracy: 0.4049, Percentage:40.4902%\n",
            "Epoch [889/1500], Training Loss: 0.9852, Validation Loss: 3.0672, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [890/1500], Training Loss: 0.7724, Validation Loss: 3.0201, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [891/1500], Training Loss: 0.8714, Validation Loss: 2.9397, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [892/1500], Training Loss: 0.8887, Validation Loss: 3.1105, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [893/1500], Training Loss: 0.9546, Validation Loss: 3.3323, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [894/1500], Training Loss: 0.9551, Validation Loss: 3.2200, Validation Accuracy: 0.4176, Percentage:41.7647%\n",
            "Epoch [895/1500], Training Loss: 0.9463, Validation Loss: 2.9948, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [896/1500], Training Loss: 0.8886, Validation Loss: 3.0215, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [897/1500], Training Loss: 0.9168, Validation Loss: 3.1948, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [898/1500], Training Loss: 0.9191, Validation Loss: 3.1473, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [899/1500], Training Loss: 0.9266, Validation Loss: 2.9162, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [900/1500], Training Loss: 0.9812, Validation Loss: 2.9797, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [901/1500], Training Loss: 0.9423, Validation Loss: 3.1616, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [902/1500], Training Loss: 1.0077, Validation Loss: 3.1546, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [903/1500], Training Loss: 0.9740, Validation Loss: 3.0190, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [904/1500], Training Loss: 0.9005, Validation Loss: 3.2253, Validation Accuracy: 0.4265, Percentage:42.6471%\n",
            "Epoch [905/1500], Training Loss: 0.9172, Validation Loss: 3.1165, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [906/1500], Training Loss: 0.9730, Validation Loss: 2.8811, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [907/1500], Training Loss: 0.9434, Validation Loss: 3.1061, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [908/1500], Training Loss: 0.9993, Validation Loss: 3.0044, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [909/1500], Training Loss: 1.1084, Validation Loss: 3.2553, Validation Accuracy: 0.4206, Percentage:42.0588%\n",
            "Epoch [910/1500], Training Loss: 0.9056, Validation Loss: 3.1917, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [911/1500], Training Loss: 0.9288, Validation Loss: 3.3316, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [912/1500], Training Loss: 0.8727, Validation Loss: 2.9961, Validation Accuracy: 0.4206, Percentage:42.0588%\n",
            "Epoch [913/1500], Training Loss: 0.8732, Validation Loss: 3.0437, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [914/1500], Training Loss: 0.8641, Validation Loss: 3.0849, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [915/1500], Training Loss: 0.9720, Validation Loss: 3.1725, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [916/1500], Training Loss: 0.9029, Validation Loss: 2.9412, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [917/1500], Training Loss: 0.9845, Validation Loss: 2.9550, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [918/1500], Training Loss: 1.0516, Validation Loss: 2.9616, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [919/1500], Training Loss: 0.9240, Validation Loss: 3.2807, Validation Accuracy: 0.4647, Percentage:46.4706%\n",
            "Epoch [920/1500], Training Loss: 0.9210, Validation Loss: 3.0312, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [921/1500], Training Loss: 0.9856, Validation Loss: 2.9615, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [922/1500], Training Loss: 0.8693, Validation Loss: 2.8992, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [923/1500], Training Loss: 0.8845, Validation Loss: 3.2010, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [924/1500], Training Loss: 1.5826, Validation Loss: 3.4056, Validation Accuracy: 0.3490, Percentage:34.9020%\n",
            "Epoch [925/1500], Training Loss: 1.2806, Validation Loss: 3.1000, Validation Accuracy: 0.4010, Percentage:40.0980%\n",
            "Epoch [926/1500], Training Loss: 1.0512, Validation Loss: 3.0183, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [927/1500], Training Loss: 1.0451, Validation Loss: 3.1619, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [928/1500], Training Loss: 0.9307, Validation Loss: 3.0691, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [929/1500], Training Loss: 1.1978, Validation Loss: 2.9821, Validation Accuracy: 0.3980, Percentage:39.8039%\n",
            "Epoch [930/1500], Training Loss: 0.9817, Validation Loss: 2.9273, Validation Accuracy: 0.4206, Percentage:42.0588%\n",
            "Epoch [931/1500], Training Loss: 0.9479, Validation Loss: 3.1676, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [932/1500], Training Loss: 0.9279, Validation Loss: 3.1570, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [933/1500], Training Loss: 0.9319, Validation Loss: 3.1183, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [934/1500], Training Loss: 0.9563, Validation Loss: 3.0719, Validation Accuracy: 0.4225, Percentage:42.2549%\n",
            "Epoch [935/1500], Training Loss: 1.0162, Validation Loss: 3.2935, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [936/1500], Training Loss: 0.8919, Validation Loss: 3.2248, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [937/1500], Training Loss: 0.9974, Validation Loss: 2.9695, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [938/1500], Training Loss: 1.0194, Validation Loss: 3.1102, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [939/1500], Training Loss: 0.9090, Validation Loss: 3.0606, Validation Accuracy: 0.4284, Percentage:42.8431%\n",
            "Epoch [940/1500], Training Loss: 1.0197, Validation Loss: 3.2065, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [941/1500], Training Loss: 1.0275, Validation Loss: 2.8455, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [942/1500], Training Loss: 0.9795, Validation Loss: 3.0850, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [943/1500], Training Loss: 0.9965, Validation Loss: 2.9825, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [944/1500], Training Loss: 0.9522, Validation Loss: 2.9826, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [945/1500], Training Loss: 0.9287, Validation Loss: 3.0305, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [946/1500], Training Loss: 0.9605, Validation Loss: 2.9578, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [947/1500], Training Loss: 0.9911, Validation Loss: 3.3229, Validation Accuracy: 0.4265, Percentage:42.6471%\n",
            "Epoch [948/1500], Training Loss: 1.0606, Validation Loss: 3.1282, Validation Accuracy: 0.4137, Percentage:41.3725%\n",
            "Epoch [949/1500], Training Loss: 1.0628, Validation Loss: 3.0107, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [950/1500], Training Loss: 0.8764, Validation Loss: 3.0904, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [951/1500], Training Loss: 0.8915, Validation Loss: 3.2566, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [952/1500], Training Loss: 1.0196, Validation Loss: 2.9165, Validation Accuracy: 0.4284, Percentage:42.8431%\n",
            "Epoch [953/1500], Training Loss: 0.8546, Validation Loss: 3.3783, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [954/1500], Training Loss: 1.0141, Validation Loss: 2.9698, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [955/1500], Training Loss: 0.9300, Validation Loss: 3.0096, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [956/1500], Training Loss: 0.9670, Validation Loss: 2.8356, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [957/1500], Training Loss: 0.9668, Validation Loss: 2.7953, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [958/1500], Training Loss: 0.9223, Validation Loss: 3.0805, Validation Accuracy: 0.4578, Percentage:45.7843%\n",
            "Epoch [959/1500], Training Loss: 0.9064, Validation Loss: 3.0681, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [960/1500], Training Loss: 0.9438, Validation Loss: 3.1268, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [961/1500], Training Loss: 0.8760, Validation Loss: 3.1478, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [962/1500], Training Loss: 0.9080, Validation Loss: 3.0008, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [963/1500], Training Loss: 1.0519, Validation Loss: 2.9835, Validation Accuracy: 0.4265, Percentage:42.6471%\n",
            "Epoch [964/1500], Training Loss: 0.9514, Validation Loss: 2.9351, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [965/1500], Training Loss: 0.9662, Validation Loss: 3.0483, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [966/1500], Training Loss: 0.9468, Validation Loss: 3.2676, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [967/1500], Training Loss: 0.9464, Validation Loss: 3.2604, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [968/1500], Training Loss: 0.9713, Validation Loss: 2.8303, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [969/1500], Training Loss: 1.0074, Validation Loss: 2.8690, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [970/1500], Training Loss: 0.9778, Validation Loss: 2.9991, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [971/1500], Training Loss: 0.9134, Validation Loss: 3.0809, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [972/1500], Training Loss: 0.8699, Validation Loss: 3.0837, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [973/1500], Training Loss: 1.0047, Validation Loss: 2.9121, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [974/1500], Training Loss: 0.9836, Validation Loss: 3.2439, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [975/1500], Training Loss: 0.9335, Validation Loss: 2.8298, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [976/1500], Training Loss: 0.9818, Validation Loss: 3.0311, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [977/1500], Training Loss: 0.8930, Validation Loss: 3.0305, Validation Accuracy: 0.4206, Percentage:42.0588%\n",
            "Epoch [978/1500], Training Loss: 0.9590, Validation Loss: 3.1690, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [979/1500], Training Loss: 0.9090, Validation Loss: 2.9402, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [980/1500], Training Loss: 1.0208, Validation Loss: 2.8062, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [981/1500], Training Loss: 0.9819, Validation Loss: 3.0963, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [982/1500], Training Loss: 0.9258, Validation Loss: 3.0499, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [983/1500], Training Loss: 0.9944, Validation Loss: 3.3117, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [984/1500], Training Loss: 0.9612, Validation Loss: 3.0151, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [985/1500], Training Loss: 1.0078, Validation Loss: 3.0677, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [986/1500], Training Loss: 0.8811, Validation Loss: 3.1085, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [987/1500], Training Loss: 1.0156, Validation Loss: 2.9155, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [988/1500], Training Loss: 0.9772, Validation Loss: 2.9808, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [989/1500], Training Loss: 0.9169, Validation Loss: 3.0612, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [990/1500], Training Loss: 0.9853, Validation Loss: 3.0610, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [991/1500], Training Loss: 1.0881, Validation Loss: 3.0242, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [992/1500], Training Loss: 0.8771, Validation Loss: 3.5720, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [993/1500], Training Loss: 0.9454, Validation Loss: 3.3326, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [994/1500], Training Loss: 0.8999, Validation Loss: 3.3435, Validation Accuracy: 0.4078, Percentage:40.7843%\n",
            "Epoch [995/1500], Training Loss: 0.9681, Validation Loss: 3.0929, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [996/1500], Training Loss: 0.9581, Validation Loss: 3.2426, Validation Accuracy: 0.4059, Percentage:40.5882%\n",
            "Epoch [997/1500], Training Loss: 0.9475, Validation Loss: 3.2973, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [998/1500], Training Loss: 0.9370, Validation Loss: 3.2473, Validation Accuracy: 0.4284, Percentage:42.8431%\n",
            "Epoch [999/1500], Training Loss: 1.0410, Validation Loss: 3.1170, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [1000/1500], Training Loss: 0.9129, Validation Loss: 3.3320, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [1001/1500], Training Loss: 0.9860, Validation Loss: 3.2042, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [1002/1500], Training Loss: 0.9236, Validation Loss: 3.0876, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [1003/1500], Training Loss: 1.0232, Validation Loss: 2.7873, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [1004/1500], Training Loss: 0.9886, Validation Loss: 2.9028, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [1005/1500], Training Loss: 0.9218, Validation Loss: 3.1359, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [1006/1500], Training Loss: 0.9490, Validation Loss: 2.9584, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [1007/1500], Training Loss: 0.9159, Validation Loss: 2.8858, Validation Accuracy: 0.4176, Percentage:41.7647%\n",
            "Epoch [1008/1500], Training Loss: 1.0106, Validation Loss: 3.1743, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [1009/1500], Training Loss: 0.9177, Validation Loss: 3.1655, Validation Accuracy: 0.4225, Percentage:42.2549%\n",
            "Epoch [1010/1500], Training Loss: 0.8782, Validation Loss: 3.2062, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [1011/1500], Training Loss: 0.9421, Validation Loss: 2.8489, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [1012/1500], Training Loss: 0.9283, Validation Loss: 3.3008, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [1013/1500], Training Loss: 0.9836, Validation Loss: 3.1068, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [1014/1500], Training Loss: 1.0010, Validation Loss: 3.2142, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [1015/1500], Training Loss: 0.9817, Validation Loss: 2.9298, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [1016/1500], Training Loss: 0.9307, Validation Loss: 3.0870, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [1017/1500], Training Loss: 0.9187, Validation Loss: 3.1167, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [1018/1500], Training Loss: 0.9392, Validation Loss: 2.9663, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [1019/1500], Training Loss: 0.8921, Validation Loss: 3.2208, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [1020/1500], Training Loss: 0.8714, Validation Loss: 3.0579, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [1021/1500], Training Loss: 0.9159, Validation Loss: 2.8985, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [1022/1500], Training Loss: 0.8574, Validation Loss: 2.9403, Validation Accuracy: 0.4284, Percentage:42.8431%\n",
            "Epoch [1023/1500], Training Loss: 0.9457, Validation Loss: 3.3388, Validation Accuracy: 0.4225, Percentage:42.2549%\n",
            "Epoch [1024/1500], Training Loss: 0.9740, Validation Loss: 3.2714, Validation Accuracy: 0.4206, Percentage:42.0588%\n",
            "Epoch [1025/1500], Training Loss: 0.9167, Validation Loss: 3.1605, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [1026/1500], Training Loss: 0.9034, Validation Loss: 3.3090, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [1027/1500], Training Loss: 0.9536, Validation Loss: 3.1877, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [1028/1500], Training Loss: 0.9077, Validation Loss: 3.1524, Validation Accuracy: 0.4176, Percentage:41.7647%\n",
            "Epoch [1029/1500], Training Loss: 0.8503, Validation Loss: 3.2304, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [1030/1500], Training Loss: 0.8731, Validation Loss: 3.2654, Validation Accuracy: 0.4000, Percentage:40.0000%\n",
            "Epoch [1031/1500], Training Loss: 0.9011, Validation Loss: 3.2437, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [1032/1500], Training Loss: 0.9481, Validation Loss: 3.5456, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [1033/1500], Training Loss: 0.8965, Validation Loss: 3.0885, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [1034/1500], Training Loss: 0.8575, Validation Loss: 3.2562, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [1035/1500], Training Loss: 0.8390, Validation Loss: 2.9981, Validation Accuracy: 0.4265, Percentage:42.6471%\n",
            "Epoch [1036/1500], Training Loss: 0.8959, Validation Loss: 3.2598, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [1037/1500], Training Loss: 0.9788, Validation Loss: 3.1624, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [1038/1500], Training Loss: 0.9576, Validation Loss: 3.2021, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [1039/1500], Training Loss: 0.9456, Validation Loss: 2.9228, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [1040/1500], Training Loss: 0.8516, Validation Loss: 2.9760, Validation Accuracy: 0.4284, Percentage:42.8431%\n",
            "Epoch [1041/1500], Training Loss: 0.8548, Validation Loss: 3.1936, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [1042/1500], Training Loss: 1.0370, Validation Loss: 2.8906, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [1043/1500], Training Loss: 0.9208, Validation Loss: 2.9808, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [1044/1500], Training Loss: 0.8722, Validation Loss: 3.1336, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [1045/1500], Training Loss: 0.8802, Validation Loss: 2.8500, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [1046/1500], Training Loss: 0.8381, Validation Loss: 3.1328, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [1047/1500], Training Loss: 0.9230, Validation Loss: 2.9704, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [1048/1500], Training Loss: 0.8293, Validation Loss: 2.8505, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [1049/1500], Training Loss: 0.9364, Validation Loss: 3.0236, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [1050/1500], Training Loss: 0.8864, Validation Loss: 3.1029, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [1051/1500], Training Loss: 0.8816, Validation Loss: 3.0641, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [1052/1500], Training Loss: 0.8941, Validation Loss: 3.2197, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [1053/1500], Training Loss: 1.1205, Validation Loss: 3.0475, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [1054/1500], Training Loss: 0.9446, Validation Loss: 3.3435, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [1055/1500], Training Loss: 0.9161, Validation Loss: 3.1602, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [1056/1500], Training Loss: 0.9364, Validation Loss: 3.0463, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [1057/1500], Training Loss: 0.9407, Validation Loss: 3.3460, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [1058/1500], Training Loss: 0.9717, Validation Loss: 3.1665, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [1059/1500], Training Loss: 1.0057, Validation Loss: 2.9487, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [1060/1500], Training Loss: 0.9295, Validation Loss: 2.9242, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [1061/1500], Training Loss: 0.8264, Validation Loss: 3.1048, Validation Accuracy: 0.4206, Percentage:42.0588%\n",
            "Epoch [1062/1500], Training Loss: 1.0716, Validation Loss: 3.0585, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [1063/1500], Training Loss: 0.8944, Validation Loss: 3.0737, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [1064/1500], Training Loss: 0.9467, Validation Loss: 3.0133, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [1065/1500], Training Loss: 0.9169, Validation Loss: 3.2658, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [1066/1500], Training Loss: 0.8812, Validation Loss: 3.1481, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [1067/1500], Training Loss: 0.8664, Validation Loss: 3.4931, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [1068/1500], Training Loss: 0.9083, Validation Loss: 3.4171, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [1069/1500], Training Loss: 0.9300, Validation Loss: 3.0200, Validation Accuracy: 0.4598, Percentage:45.9804%\n",
            "Epoch [1070/1500], Training Loss: 0.8276, Validation Loss: 3.1476, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [1071/1500], Training Loss: 0.9115, Validation Loss: 2.9890, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [1072/1500], Training Loss: 1.0260, Validation Loss: 2.9989, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [1073/1500], Training Loss: 0.9906, Validation Loss: 3.4297, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [1074/1500], Training Loss: 0.9072, Validation Loss: 3.2173, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [1075/1500], Training Loss: 0.9756, Validation Loss: 2.8532, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [1076/1500], Training Loss: 0.8454, Validation Loss: 2.9898, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [1077/1500], Training Loss: 0.9171, Validation Loss: 3.2413, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [1078/1500], Training Loss: 0.8550, Validation Loss: 3.0851, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [1079/1500], Training Loss: 0.9449, Validation Loss: 3.1810, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [1080/1500], Training Loss: 0.9725, Validation Loss: 2.8393, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [1081/1500], Training Loss: 0.9105, Validation Loss: 3.2603, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [1082/1500], Training Loss: 0.9560, Validation Loss: 3.0737, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [1083/1500], Training Loss: 0.9280, Validation Loss: 2.9499, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [1084/1500], Training Loss: 1.0037, Validation Loss: 2.8900, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [1085/1500], Training Loss: 0.8055, Validation Loss: 3.0136, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [1086/1500], Training Loss: 1.0168, Validation Loss: 3.1386, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [1087/1500], Training Loss: 0.9270, Validation Loss: 3.0012, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [1088/1500], Training Loss: 0.9432, Validation Loss: 2.9232, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [1089/1500], Training Loss: 0.9060, Validation Loss: 2.8167, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [1090/1500], Training Loss: 0.8791, Validation Loss: 3.2626, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [1091/1500], Training Loss: 0.9196, Validation Loss: 3.3750, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [1092/1500], Training Loss: 0.9743, Validation Loss: 3.0176, Validation Accuracy: 0.4176, Percentage:41.7647%\n",
            "Epoch [1093/1500], Training Loss: 0.9195, Validation Loss: 3.0066, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [1094/1500], Training Loss: 0.9480, Validation Loss: 2.9793, Validation Accuracy: 0.4265, Percentage:42.6471%\n",
            "Epoch [1095/1500], Training Loss: 0.8653, Validation Loss: 3.0320, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [1096/1500], Training Loss: 0.8605, Validation Loss: 3.0917, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [1097/1500], Training Loss: 0.8906, Validation Loss: 3.1453, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [1098/1500], Training Loss: 0.9807, Validation Loss: 3.0550, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [1099/1500], Training Loss: 0.8773, Validation Loss: 3.1490, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [1100/1500], Training Loss: 0.8583, Validation Loss: 3.2828, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [1101/1500], Training Loss: 0.9306, Validation Loss: 3.1107, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [1102/1500], Training Loss: 0.8740, Validation Loss: 3.3921, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [1103/1500], Training Loss: 0.8294, Validation Loss: 2.8314, Validation Accuracy: 0.4637, Percentage:46.3725%\n",
            "Epoch [1104/1500], Training Loss: 0.8419, Validation Loss: 3.3325, Validation Accuracy: 0.4284, Percentage:42.8431%\n",
            "Epoch [1105/1500], Training Loss: 0.9718, Validation Loss: 3.1464, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [1106/1500], Training Loss: 0.9478, Validation Loss: 2.9823, Validation Accuracy: 0.4020, Percentage:40.1961%\n",
            "Epoch [1107/1500], Training Loss: 0.8805, Validation Loss: 2.8170, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [1108/1500], Training Loss: 0.8672, Validation Loss: 3.0924, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [1109/1500], Training Loss: 0.8530, Validation Loss: 2.9080, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [1110/1500], Training Loss: 0.8846, Validation Loss: 2.9555, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [1111/1500], Training Loss: 0.9699, Validation Loss: 3.3277, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [1112/1500], Training Loss: 1.0447, Validation Loss: 3.3234, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [1113/1500], Training Loss: 1.0352, Validation Loss: 3.0920, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [1114/1500], Training Loss: 0.8946, Validation Loss: 2.8582, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [1115/1500], Training Loss: 0.9237, Validation Loss: 3.0572, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [1116/1500], Training Loss: 0.8814, Validation Loss: 2.7690, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [1117/1500], Training Loss: 0.8926, Validation Loss: 3.0741, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [1118/1500], Training Loss: 0.9370, Validation Loss: 2.9001, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [1119/1500], Training Loss: 0.7973, Validation Loss: 3.0916, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [1120/1500], Training Loss: 0.9747, Validation Loss: 3.1366, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [1121/1500], Training Loss: 0.7432, Validation Loss: 3.4390, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [1122/1500], Training Loss: 0.9752, Validation Loss: 3.1328, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [1123/1500], Training Loss: 0.8451, Validation Loss: 3.1016, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [1124/1500], Training Loss: 0.8684, Validation Loss: 3.0485, Validation Accuracy: 0.4608, Percentage:46.0784%\n",
            "Epoch [1125/1500], Training Loss: 0.9582, Validation Loss: 3.2468, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [1126/1500], Training Loss: 0.8484, Validation Loss: 3.2070, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [1127/1500], Training Loss: 0.9240, Validation Loss: 2.8232, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [1128/1500], Training Loss: 0.9121, Validation Loss: 3.1988, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [1129/1500], Training Loss: 0.9886, Validation Loss: 2.6643, Validation Accuracy: 0.4657, Percentage:46.5686%\n",
            "Epoch [1130/1500], Training Loss: 0.9378, Validation Loss: 3.0254, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [1131/1500], Training Loss: 0.8647, Validation Loss: 3.1111, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [1132/1500], Training Loss: 0.9149, Validation Loss: 2.9333, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [1133/1500], Training Loss: 0.8411, Validation Loss: 3.2510, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [1134/1500], Training Loss: 0.8638, Validation Loss: 2.9161, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [1135/1500], Training Loss: 0.8282, Validation Loss: 3.3088, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [1136/1500], Training Loss: 0.8533, Validation Loss: 2.9761, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [1137/1500], Training Loss: 0.9015, Validation Loss: 2.9971, Validation Accuracy: 0.4618, Percentage:46.1765%\n",
            "Epoch [1138/1500], Training Loss: 0.7817, Validation Loss: 3.3416, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [1139/1500], Training Loss: 0.9131, Validation Loss: 2.8682, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [1140/1500], Training Loss: 0.8426, Validation Loss: 2.9725, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [1141/1500], Training Loss: 0.9191, Validation Loss: 3.1344, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [1142/1500], Training Loss: 0.8738, Validation Loss: 3.1218, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [1143/1500], Training Loss: 0.9417, Validation Loss: 2.9723, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [1144/1500], Training Loss: 0.9448, Validation Loss: 3.0260, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [1145/1500], Training Loss: 0.8101, Validation Loss: 3.2034, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [1146/1500], Training Loss: 0.8751, Validation Loss: 3.3230, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [1147/1500], Training Loss: 0.8427, Validation Loss: 3.1828, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [1148/1500], Training Loss: 0.9503, Validation Loss: 3.1968, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [1149/1500], Training Loss: 0.9502, Validation Loss: 3.1320, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [1150/1500], Training Loss: 1.0300, Validation Loss: 3.1179, Validation Accuracy: 0.4176, Percentage:41.7647%\n",
            "Epoch [1151/1500], Training Loss: 0.8873, Validation Loss: 3.5183, Validation Accuracy: 0.4265, Percentage:42.6471%\n",
            "Epoch [1152/1500], Training Loss: 0.9539, Validation Loss: 3.1760, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [1153/1500], Training Loss: 1.0205, Validation Loss: 2.9737, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [1154/1500], Training Loss: 1.0649, Validation Loss: 3.0998, Validation Accuracy: 0.4647, Percentage:46.4706%\n",
            "Epoch [1155/1500], Training Loss: 0.7616, Validation Loss: 3.0621, Validation Accuracy: 0.4284, Percentage:42.8431%\n",
            "Epoch [1156/1500], Training Loss: 0.8275, Validation Loss: 3.1233, Validation Accuracy: 0.4657, Percentage:46.5686%\n",
            "Epoch [1157/1500], Training Loss: 0.7642, Validation Loss: 3.4832, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [1158/1500], Training Loss: 1.0027, Validation Loss: 3.1618, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [1159/1500], Training Loss: 0.9215, Validation Loss: 3.0369, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [1160/1500], Training Loss: 0.8366, Validation Loss: 2.9964, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [1161/1500], Training Loss: 0.7985, Validation Loss: 3.0646, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [1162/1500], Training Loss: 0.9250, Validation Loss: 3.0507, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [1163/1500], Training Loss: 0.7913, Validation Loss: 3.0122, Validation Accuracy: 0.4284, Percentage:42.8431%\n",
            "Epoch [1164/1500], Training Loss: 0.9389, Validation Loss: 3.3586, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [1165/1500], Training Loss: 0.8912, Validation Loss: 3.1797, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [1166/1500], Training Loss: 0.8482, Validation Loss: 2.8937, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [1167/1500], Training Loss: 0.8967, Validation Loss: 2.9547, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [1168/1500], Training Loss: 0.8651, Validation Loss: 3.1597, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [1169/1500], Training Loss: 0.9051, Validation Loss: 3.0341, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [1170/1500], Training Loss: 0.9959, Validation Loss: 2.9908, Validation Accuracy: 0.4598, Percentage:45.9804%\n",
            "Epoch [1171/1500], Training Loss: 0.8327, Validation Loss: 3.0394, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [1172/1500], Training Loss: 0.9178, Validation Loss: 3.0532, Validation Accuracy: 0.4225, Percentage:42.2549%\n",
            "Epoch [1173/1500], Training Loss: 0.9300, Validation Loss: 3.2417, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [1174/1500], Training Loss: 0.9325, Validation Loss: 3.0276, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [1175/1500], Training Loss: 0.9751, Validation Loss: 2.8590, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [1176/1500], Training Loss: 0.8999, Validation Loss: 2.9345, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [1177/1500], Training Loss: 0.8715, Validation Loss: 3.0710, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [1178/1500], Training Loss: 0.8648, Validation Loss: 2.9638, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [1179/1500], Training Loss: 0.9201, Validation Loss: 2.9186, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [1180/1500], Training Loss: 0.9507, Validation Loss: 2.9680, Validation Accuracy: 0.4265, Percentage:42.6471%\n",
            "Epoch [1181/1500], Training Loss: 0.8735, Validation Loss: 3.2125, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [1182/1500], Training Loss: 0.9187, Validation Loss: 3.1074, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [1183/1500], Training Loss: 0.7658, Validation Loss: 3.3527, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [1184/1500], Training Loss: 0.9120, Validation Loss: 3.0324, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [1185/1500], Training Loss: 1.0607, Validation Loss: 2.7909, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [1186/1500], Training Loss: 0.9296, Validation Loss: 2.8688, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [1187/1500], Training Loss: 0.9448, Validation Loss: 2.9788, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [1188/1500], Training Loss: 0.8972, Validation Loss: 3.1230, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [1189/1500], Training Loss: 1.0529, Validation Loss: 3.2872, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [1190/1500], Training Loss: 0.9407, Validation Loss: 3.1234, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [1191/1500], Training Loss: 0.9464, Validation Loss: 2.9793, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [1192/1500], Training Loss: 0.8434, Validation Loss: 3.0825, Validation Accuracy: 0.4667, Percentage:46.6667%\n",
            "Epoch [1193/1500], Training Loss: 0.9369, Validation Loss: 3.0977, Validation Accuracy: 0.4039, Percentage:40.3922%\n",
            "Epoch [1194/1500], Training Loss: 0.9370, Validation Loss: 2.8797, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [1195/1500], Training Loss: 0.8312, Validation Loss: 3.0132, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [1196/1500], Training Loss: 0.8354, Validation Loss: 2.7661, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [1197/1500], Training Loss: 0.8854, Validation Loss: 3.1188, Validation Accuracy: 0.4598, Percentage:45.9804%\n",
            "Epoch [1198/1500], Training Loss: 0.8995, Validation Loss: 3.3124, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [1199/1500], Training Loss: 0.9632, Validation Loss: 3.0901, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [1200/1500], Training Loss: 0.8579, Validation Loss: 3.3262, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [1201/1500], Training Loss: 0.8348, Validation Loss: 3.0483, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [1202/1500], Training Loss: 0.9153, Validation Loss: 2.9817, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [1203/1500], Training Loss: 0.9216, Validation Loss: 2.8680, Validation Accuracy: 0.4667, Percentage:46.6667%\n",
            "Epoch [1204/1500], Training Loss: 0.8249, Validation Loss: 3.2078, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [1205/1500], Training Loss: 0.8408, Validation Loss: 2.9886, Validation Accuracy: 0.4706, Percentage:47.0588%\n",
            "Epoch [1206/1500], Training Loss: 0.8794, Validation Loss: 2.9700, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [1207/1500], Training Loss: 0.9151, Validation Loss: 3.0740, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [1208/1500], Training Loss: 0.9223, Validation Loss: 3.3250, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [1209/1500], Training Loss: 1.0086, Validation Loss: 2.8859, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [1210/1500], Training Loss: 0.8575, Validation Loss: 3.0898, Validation Accuracy: 0.4667, Percentage:46.6667%\n",
            "Epoch [1211/1500], Training Loss: 0.9068, Validation Loss: 3.4305, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [1212/1500], Training Loss: 0.9018, Validation Loss: 2.9475, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [1213/1500], Training Loss: 0.8289, Validation Loss: 3.2364, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [1214/1500], Training Loss: 0.7774, Validation Loss: 3.4957, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [1215/1500], Training Loss: 0.9455, Validation Loss: 2.9235, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [1216/1500], Training Loss: 0.8374, Validation Loss: 3.2006, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [1217/1500], Training Loss: 0.8492, Validation Loss: 3.1408, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [1218/1500], Training Loss: 0.8630, Validation Loss: 3.1398, Validation Accuracy: 0.4627, Percentage:46.2745%\n",
            "Epoch [1219/1500], Training Loss: 0.9499, Validation Loss: 2.9887, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [1220/1500], Training Loss: 0.9694, Validation Loss: 3.0598, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [1221/1500], Training Loss: 0.8588, Validation Loss: 2.9934, Validation Accuracy: 0.4598, Percentage:45.9804%\n",
            "Epoch [1222/1500], Training Loss: 0.8944, Validation Loss: 3.3116, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [1223/1500], Training Loss: 0.9327, Validation Loss: 3.2328, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [1224/1500], Training Loss: 0.8749, Validation Loss: 3.0767, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [1225/1500], Training Loss: 0.8506, Validation Loss: 3.2016, Validation Accuracy: 0.4627, Percentage:46.2745%\n",
            "Epoch [1226/1500], Training Loss: 0.9619, Validation Loss: 3.0183, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [1227/1500], Training Loss: 0.8368, Validation Loss: 3.1295, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [1228/1500], Training Loss: 0.8159, Validation Loss: 3.1594, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [1229/1500], Training Loss: 0.8148, Validation Loss: 3.1352, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [1230/1500], Training Loss: 0.8047, Validation Loss: 3.3321, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [1231/1500], Training Loss: 0.9667, Validation Loss: 3.2464, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [1232/1500], Training Loss: 0.9555, Validation Loss: 3.1703, Validation Accuracy: 0.4265, Percentage:42.6471%\n",
            "Epoch [1233/1500], Training Loss: 0.8721, Validation Loss: 3.3230, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [1234/1500], Training Loss: 0.8504, Validation Loss: 2.9134, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [1235/1500], Training Loss: 0.8811, Validation Loss: 3.1691, Validation Accuracy: 0.4069, Percentage:40.6863%\n",
            "Epoch [1236/1500], Training Loss: 0.8714, Validation Loss: 3.1552, Validation Accuracy: 0.4578, Percentage:45.7843%\n",
            "Epoch [1237/1500], Training Loss: 0.9271, Validation Loss: 2.9559, Validation Accuracy: 0.4696, Percentage:46.9608%\n",
            "Epoch [1238/1500], Training Loss: 0.7690, Validation Loss: 3.3339, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [1239/1500], Training Loss: 0.8674, Validation Loss: 3.3410, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [1240/1500], Training Loss: 0.9196, Validation Loss: 3.0365, Validation Accuracy: 0.4578, Percentage:45.7843%\n",
            "Epoch [1241/1500], Training Loss: 0.8070, Validation Loss: 3.0838, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [1242/1500], Training Loss: 0.9245, Validation Loss: 2.9638, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [1243/1500], Training Loss: 0.7861, Validation Loss: 3.2080, Validation Accuracy: 0.4686, Percentage:46.8627%\n",
            "Epoch [1244/1500], Training Loss: 0.8678, Validation Loss: 3.1114, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [1245/1500], Training Loss: 0.8840, Validation Loss: 3.2385, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [1246/1500], Training Loss: 0.9150, Validation Loss: 2.9081, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [1247/1500], Training Loss: 0.9075, Validation Loss: 3.0333, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [1248/1500], Training Loss: 0.8130, Validation Loss: 3.2381, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [1249/1500], Training Loss: 0.8745, Validation Loss: 3.3900, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [1250/1500], Training Loss: 0.8242, Validation Loss: 3.2222, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [1251/1500], Training Loss: 0.8920, Validation Loss: 3.0925, Validation Accuracy: 0.4637, Percentage:46.3725%\n",
            "Epoch [1252/1500], Training Loss: 0.8589, Validation Loss: 3.5811, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [1253/1500], Training Loss: 0.7887, Validation Loss: 2.9476, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [1254/1500], Training Loss: 0.9547, Validation Loss: 2.9634, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [1255/1500], Training Loss: 0.9180, Validation Loss: 3.3068, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [1256/1500], Training Loss: 0.8937, Validation Loss: 3.2405, Validation Accuracy: 0.4686, Percentage:46.8627%\n",
            "Epoch [1257/1500], Training Loss: 0.8565, Validation Loss: 3.1777, Validation Accuracy: 0.4696, Percentage:46.9608%\n",
            "Epoch [1258/1500], Training Loss: 0.9191, Validation Loss: 2.9564, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [1259/1500], Training Loss: 0.7532, Validation Loss: 3.1251, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [1260/1500], Training Loss: 0.9379, Validation Loss: 3.0276, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [1261/1500], Training Loss: 0.9024, Validation Loss: 2.9539, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [1262/1500], Training Loss: 0.9690, Validation Loss: 2.9907, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [1263/1500], Training Loss: 1.0442, Validation Loss: 3.2287, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [1264/1500], Training Loss: 0.9632, Validation Loss: 2.9589, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [1265/1500], Training Loss: 0.8294, Validation Loss: 2.9223, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [1266/1500], Training Loss: 0.8581, Validation Loss: 3.1552, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [1267/1500], Training Loss: 0.8367, Validation Loss: 3.0474, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [1268/1500], Training Loss: 0.8568, Validation Loss: 3.0983, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [1269/1500], Training Loss: 1.0069, Validation Loss: 3.1953, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [1270/1500], Training Loss: 0.9454, Validation Loss: 3.0145, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [1271/1500], Training Loss: 0.8232, Validation Loss: 3.0250, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [1272/1500], Training Loss: 0.9416, Validation Loss: 2.6801, Validation Accuracy: 0.4627, Percentage:46.2745%\n",
            "Epoch [1273/1500], Training Loss: 0.9535, Validation Loss: 3.0398, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [1274/1500], Training Loss: 0.9063, Validation Loss: 3.0003, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [1275/1500], Training Loss: 0.9133, Validation Loss: 3.0336, Validation Accuracy: 0.4284, Percentage:42.8431%\n",
            "Epoch [1276/1500], Training Loss: 0.9973, Validation Loss: 3.3197, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [1277/1500], Training Loss: 0.9281, Validation Loss: 3.3226, Validation Accuracy: 0.4618, Percentage:46.1765%\n",
            "Epoch [1278/1500], Training Loss: 0.9108, Validation Loss: 2.9442, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [1279/1500], Training Loss: 0.8826, Validation Loss: 3.1915, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [1280/1500], Training Loss: 0.8692, Validation Loss: 3.1295, Validation Accuracy: 0.4637, Percentage:46.3725%\n",
            "Epoch [1281/1500], Training Loss: 0.9372, Validation Loss: 3.4065, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [1282/1500], Training Loss: 0.7974, Validation Loss: 3.1316, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [1283/1500], Training Loss: 0.7895, Validation Loss: 3.2875, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [1284/1500], Training Loss: 0.8750, Validation Loss: 3.0655, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [1285/1500], Training Loss: 0.9212, Validation Loss: 3.3513, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [1286/1500], Training Loss: 0.8736, Validation Loss: 3.6257, Validation Accuracy: 0.4186, Percentage:41.8627%\n",
            "Epoch [1287/1500], Training Loss: 1.0699, Validation Loss: 3.1732, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [1288/1500], Training Loss: 0.9390, Validation Loss: 3.0979, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [1289/1500], Training Loss: 0.9396, Validation Loss: 3.0946, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [1290/1500], Training Loss: 0.9170, Validation Loss: 3.0203, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [1291/1500], Training Loss: 0.8978, Validation Loss: 3.0073, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [1292/1500], Training Loss: 0.8386, Validation Loss: 3.1928, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [1293/1500], Training Loss: 0.8648, Validation Loss: 2.8329, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [1294/1500], Training Loss: 0.8842, Validation Loss: 3.0364, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [1295/1500], Training Loss: 0.7675, Validation Loss: 3.1587, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [1296/1500], Training Loss: 0.8845, Validation Loss: 3.2225, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [1297/1500], Training Loss: 0.8456, Validation Loss: 2.9463, Validation Accuracy: 0.4755, Percentage:47.5490%\n",
            "Epoch [1298/1500], Training Loss: 0.9145, Validation Loss: 3.0133, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [1299/1500], Training Loss: 0.8169, Validation Loss: 3.1819, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [1300/1500], Training Loss: 0.9356, Validation Loss: 3.3442, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [1301/1500], Training Loss: 0.9652, Validation Loss: 3.0769, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [1302/1500], Training Loss: 0.8841, Validation Loss: 2.8637, Validation Accuracy: 0.4608, Percentage:46.0784%\n",
            "Epoch [1303/1500], Training Loss: 0.8431, Validation Loss: 3.0452, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [1304/1500], Training Loss: 0.8552, Validation Loss: 3.3883, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [1305/1500], Training Loss: 0.9341, Validation Loss: 3.0220, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [1306/1500], Training Loss: 0.8342, Validation Loss: 3.0286, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [1307/1500], Training Loss: 0.8323, Validation Loss: 3.1892, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [1308/1500], Training Loss: 0.9342, Validation Loss: 3.0444, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [1309/1500], Training Loss: 0.9207, Validation Loss: 3.2644, Validation Accuracy: 0.4216, Percentage:42.1569%\n",
            "Epoch [1310/1500], Training Loss: 0.8139, Validation Loss: 3.4629, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [1311/1500], Training Loss: 0.8338, Validation Loss: 2.9072, Validation Accuracy: 0.4696, Percentage:46.9608%\n",
            "Epoch [1312/1500], Training Loss: 0.8742, Validation Loss: 3.1506, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [1313/1500], Training Loss: 0.9013, Validation Loss: 3.2014, Validation Accuracy: 0.4088, Percentage:40.8824%\n",
            "Epoch [1314/1500], Training Loss: 0.9479, Validation Loss: 3.1415, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [1315/1500], Training Loss: 0.8914, Validation Loss: 3.1881, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [1316/1500], Training Loss: 0.7919, Validation Loss: 3.3187, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [1317/1500], Training Loss: 0.8471, Validation Loss: 3.0977, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [1318/1500], Training Loss: 0.8681, Validation Loss: 3.1480, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [1319/1500], Training Loss: 0.9657, Validation Loss: 3.1590, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [1320/1500], Training Loss: 0.8653, Validation Loss: 3.4139, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [1321/1500], Training Loss: 0.8516, Validation Loss: 2.9267, Validation Accuracy: 0.4578, Percentage:45.7843%\n",
            "Epoch [1322/1500], Training Loss: 0.8318, Validation Loss: 3.0810, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [1323/1500], Training Loss: 0.8120, Validation Loss: 3.3127, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [1324/1500], Training Loss: 0.9089, Validation Loss: 2.9663, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [1325/1500], Training Loss: 0.8346, Validation Loss: 3.1358, Validation Accuracy: 0.4618, Percentage:46.1765%\n",
            "Epoch [1326/1500], Training Loss: 0.8048, Validation Loss: 3.2135, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [1327/1500], Training Loss: 0.8770, Validation Loss: 3.4166, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [1328/1500], Training Loss: 0.8446, Validation Loss: 3.3637, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [1329/1500], Training Loss: 0.9196, Validation Loss: 2.8297, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [1330/1500], Training Loss: 0.8608, Validation Loss: 3.2189, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [1331/1500], Training Loss: 0.9121, Validation Loss: 3.0311, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [1332/1500], Training Loss: 0.8036, Validation Loss: 3.2500, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [1333/1500], Training Loss: 0.8434, Validation Loss: 3.1269, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [1334/1500], Training Loss: 0.7474, Validation Loss: 3.2599, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [1335/1500], Training Loss: 0.8480, Validation Loss: 3.2730, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [1336/1500], Training Loss: 0.8749, Validation Loss: 3.0841, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [1337/1500], Training Loss: 0.8044, Validation Loss: 3.2442, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [1338/1500], Training Loss: 0.8273, Validation Loss: 3.6122, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [1339/1500], Training Loss: 0.9072, Validation Loss: 3.2927, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [1340/1500], Training Loss: 0.9005, Validation Loss: 3.2993, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [1341/1500], Training Loss: 0.7893, Validation Loss: 3.3949, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [1342/1500], Training Loss: 0.8581, Validation Loss: 3.1792, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [1343/1500], Training Loss: 0.8934, Validation Loss: 3.1779, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [1344/1500], Training Loss: 0.9103, Validation Loss: 3.0773, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [1345/1500], Training Loss: 0.7976, Validation Loss: 3.3579, Validation Accuracy: 0.4716, Percentage:47.1569%\n",
            "Epoch [1346/1500], Training Loss: 0.8652, Validation Loss: 3.2078, Validation Accuracy: 0.4157, Percentage:41.5686%\n",
            "Epoch [1347/1500], Training Loss: 0.8692, Validation Loss: 3.6393, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [1348/1500], Training Loss: 0.8468, Validation Loss: 3.1207, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [1349/1500], Training Loss: 0.8783, Validation Loss: 2.9339, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [1350/1500], Training Loss: 0.7905, Validation Loss: 3.1541, Validation Accuracy: 0.4667, Percentage:46.6667%\n",
            "Epoch [1351/1500], Training Loss: 0.9474, Validation Loss: 3.3889, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [1352/1500], Training Loss: 0.8651, Validation Loss: 3.2201, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [1353/1500], Training Loss: 0.9462, Validation Loss: 3.2452, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [1354/1500], Training Loss: 0.8082, Validation Loss: 3.3493, Validation Accuracy: 0.4275, Percentage:42.7451%\n",
            "Epoch [1355/1500], Training Loss: 0.8884, Validation Loss: 3.2088, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [1356/1500], Training Loss: 0.9421, Validation Loss: 3.0654, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [1357/1500], Training Loss: 0.8616, Validation Loss: 3.0349, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [1358/1500], Training Loss: 0.8222, Validation Loss: 3.1282, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [1359/1500], Training Loss: 0.8687, Validation Loss: 2.9886, Validation Accuracy: 0.4637, Percentage:46.3725%\n",
            "Epoch [1360/1500], Training Loss: 0.9454, Validation Loss: 3.3159, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [1361/1500], Training Loss: 0.9279, Validation Loss: 3.0970, Validation Accuracy: 0.4696, Percentage:46.9608%\n",
            "Epoch [1362/1500], Training Loss: 0.9108, Validation Loss: 3.1646, Validation Accuracy: 0.4284, Percentage:42.8431%\n",
            "Epoch [1363/1500], Training Loss: 0.8457, Validation Loss: 3.2099, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [1364/1500], Training Loss: 0.8382, Validation Loss: 2.9270, Validation Accuracy: 0.4657, Percentage:46.5686%\n",
            "Epoch [1365/1500], Training Loss: 0.8225, Validation Loss: 3.5043, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [1366/1500], Training Loss: 0.8423, Validation Loss: 3.2957, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [1367/1500], Training Loss: 0.8949, Validation Loss: 3.3217, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [1368/1500], Training Loss: 0.9008, Validation Loss: 3.1450, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [1369/1500], Training Loss: 0.9330, Validation Loss: 3.1412, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [1370/1500], Training Loss: 0.8310, Validation Loss: 3.2918, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [1371/1500], Training Loss: 0.8072, Validation Loss: 3.1303, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [1372/1500], Training Loss: 0.9187, Validation Loss: 2.9856, Validation Accuracy: 0.4304, Percentage:43.0392%\n",
            "Epoch [1373/1500], Training Loss: 0.8881, Validation Loss: 3.1879, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [1374/1500], Training Loss: 0.7677, Validation Loss: 3.1693, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [1375/1500], Training Loss: 0.9034, Validation Loss: 3.2424, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [1376/1500], Training Loss: 0.8733, Validation Loss: 3.0643, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [1377/1500], Training Loss: 0.8786, Validation Loss: 3.2470, Validation Accuracy: 0.4324, Percentage:43.2353%\n",
            "Epoch [1378/1500], Training Loss: 0.8318, Validation Loss: 3.1508, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [1379/1500], Training Loss: 0.9084, Validation Loss: 3.2367, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [1380/1500], Training Loss: 0.8753, Validation Loss: 3.1185, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [1381/1500], Training Loss: 0.8573, Validation Loss: 3.0400, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [1382/1500], Training Loss: 0.9651, Validation Loss: 2.8087, Validation Accuracy: 0.4667, Percentage:46.6667%\n",
            "Epoch [1383/1500], Training Loss: 0.8255, Validation Loss: 3.0758, Validation Accuracy: 0.4696, Percentage:46.9608%\n",
            "Epoch [1384/1500], Training Loss: 0.8671, Validation Loss: 3.1290, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [1385/1500], Training Loss: 0.8918, Validation Loss: 3.0005, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [1386/1500], Training Loss: 0.9746, Validation Loss: 3.0699, Validation Accuracy: 0.4608, Percentage:46.0784%\n",
            "Epoch [1387/1500], Training Loss: 0.8571, Validation Loss: 3.1085, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [1388/1500], Training Loss: 0.9167, Validation Loss: 3.1814, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [1389/1500], Training Loss: 0.8838, Validation Loss: 3.0308, Validation Accuracy: 0.4098, Percentage:40.9804%\n",
            "Epoch [1390/1500], Training Loss: 0.8985, Validation Loss: 3.3280, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [1391/1500], Training Loss: 0.8597, Validation Loss: 3.2543, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [1392/1500], Training Loss: 0.7821, Validation Loss: 2.8985, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [1393/1500], Training Loss: 0.8648, Validation Loss: 3.2127, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [1394/1500], Training Loss: 0.8651, Validation Loss: 3.1678, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [1395/1500], Training Loss: 0.8493, Validation Loss: 3.2392, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [1396/1500], Training Loss: 0.8285, Validation Loss: 3.0697, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [1397/1500], Training Loss: 0.8524, Validation Loss: 3.3222, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [1398/1500], Training Loss: 0.8266, Validation Loss: 3.4094, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [1399/1500], Training Loss: 0.8334, Validation Loss: 3.0658, Validation Accuracy: 0.4627, Percentage:46.2745%\n",
            "Epoch [1400/1500], Training Loss: 0.8338, Validation Loss: 3.2898, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [1401/1500], Training Loss: 0.8821, Validation Loss: 2.9052, Validation Accuracy: 0.4618, Percentage:46.1765%\n",
            "Epoch [1402/1500], Training Loss: 0.8672, Validation Loss: 2.8333, Validation Accuracy: 0.4618, Percentage:46.1765%\n",
            "Epoch [1403/1500], Training Loss: 0.7700, Validation Loss: 3.5088, Validation Accuracy: 0.4578, Percentage:45.7843%\n",
            "Epoch [1404/1500], Training Loss: 0.8195, Validation Loss: 3.3456, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [1405/1500], Training Loss: 0.7788, Validation Loss: 3.3088, Validation Accuracy: 0.4147, Percentage:41.4706%\n",
            "Epoch [1406/1500], Training Loss: 0.8636, Validation Loss: 2.9221, Validation Accuracy: 0.4627, Percentage:46.2745%\n",
            "Epoch [1407/1500], Training Loss: 0.8213, Validation Loss: 3.3236, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [1408/1500], Training Loss: 0.8638, Validation Loss: 2.9991, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [1409/1500], Training Loss: 0.9299, Validation Loss: 3.1603, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [1410/1500], Training Loss: 0.8393, Validation Loss: 3.0812, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [1411/1500], Training Loss: 0.7639, Validation Loss: 2.8219, Validation Accuracy: 0.4314, Percentage:43.1373%\n",
            "Epoch [1412/1500], Training Loss: 0.8670, Validation Loss: 3.1841, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [1413/1500], Training Loss: 0.8125, Validation Loss: 3.3917, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [1414/1500], Training Loss: 0.8196, Validation Loss: 3.2141, Validation Accuracy: 0.4755, Percentage:47.5490%\n",
            "Epoch [1415/1500], Training Loss: 0.7982, Validation Loss: 3.1566, Validation Accuracy: 0.4657, Percentage:46.5686%\n",
            "Epoch [1416/1500], Training Loss: 0.8404, Validation Loss: 3.0981, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [1417/1500], Training Loss: 0.8715, Validation Loss: 3.3921, Validation Accuracy: 0.4225, Percentage:42.2549%\n",
            "Epoch [1418/1500], Training Loss: 0.7587, Validation Loss: 2.9851, Validation Accuracy: 0.4529, Percentage:45.2941%\n",
            "Epoch [1419/1500], Training Loss: 0.9065, Validation Loss: 3.3132, Validation Accuracy: 0.4167, Percentage:41.6667%\n",
            "Epoch [1420/1500], Training Loss: 0.9368, Validation Loss: 2.8855, Validation Accuracy: 0.4539, Percentage:45.3922%\n",
            "Epoch [1421/1500], Training Loss: 0.8928, Validation Loss: 3.2516, Validation Accuracy: 0.4392, Percentage:43.9216%\n",
            "Epoch [1422/1500], Training Loss: 0.8639, Validation Loss: 3.4538, Validation Accuracy: 0.4461, Percentage:44.6078%\n",
            "Epoch [1423/1500], Training Loss: 0.8707, Validation Loss: 3.2022, Validation Accuracy: 0.4510, Percentage:45.0980%\n",
            "Epoch [1424/1500], Training Loss: 0.7425, Validation Loss: 3.3106, Validation Accuracy: 0.4431, Percentage:44.3137%\n",
            "Epoch [1425/1500], Training Loss: 0.9693, Validation Loss: 3.3177, Validation Accuracy: 0.4549, Percentage:45.4902%\n",
            "Epoch [1426/1500], Training Loss: 0.7635, Validation Loss: 3.3962, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [1427/1500], Training Loss: 0.8628, Validation Loss: 2.9588, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [1428/1500], Training Loss: 0.8504, Validation Loss: 2.8850, Validation Accuracy: 0.4608, Percentage:46.0784%\n",
            "Epoch [1429/1500], Training Loss: 0.8806, Validation Loss: 3.1054, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [1430/1500], Training Loss: 0.8681, Validation Loss: 3.0056, Validation Accuracy: 0.4245, Percentage:42.4510%\n",
            "Epoch [1431/1500], Training Loss: 0.8930, Validation Loss: 3.0866, Validation Accuracy: 0.4284, Percentage:42.8431%\n",
            "Epoch [1432/1500], Training Loss: 0.8014, Validation Loss: 3.5706, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [1433/1500], Training Loss: 1.0439, Validation Loss: 3.0999, Validation Accuracy: 0.4637, Percentage:46.3725%\n",
            "Epoch [1434/1500], Training Loss: 0.8392, Validation Loss: 3.0716, Validation Accuracy: 0.4118, Percentage:41.1765%\n",
            "Epoch [1435/1500], Training Loss: 0.8715, Validation Loss: 3.5047, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [1436/1500], Training Loss: 0.9644, Validation Loss: 3.1816, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [1437/1500], Training Loss: 0.8081, Validation Loss: 3.3219, Validation Accuracy: 0.4343, Percentage:43.4314%\n",
            "Epoch [1438/1500], Training Loss: 0.9102, Validation Loss: 2.9506, Validation Accuracy: 0.4353, Percentage:43.5294%\n",
            "Epoch [1439/1500], Training Loss: 0.8009, Validation Loss: 3.0011, Validation Accuracy: 0.4578, Percentage:45.7843%\n",
            "Epoch [1440/1500], Training Loss: 0.8679, Validation Loss: 2.9896, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [1441/1500], Training Loss: 0.8155, Validation Loss: 3.2624, Validation Accuracy: 0.4255, Percentage:42.5490%\n",
            "Epoch [1442/1500], Training Loss: 0.8617, Validation Loss: 2.8933, Validation Accuracy: 0.4598, Percentage:45.9804%\n",
            "Epoch [1443/1500], Training Loss: 0.8857, Validation Loss: 3.2904, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [1444/1500], Training Loss: 0.9655, Validation Loss: 3.0650, Validation Accuracy: 0.4402, Percentage:44.0196%\n",
            "Epoch [1445/1500], Training Loss: 0.9209, Validation Loss: 2.9674, Validation Accuracy: 0.4647, Percentage:46.4706%\n",
            "Epoch [1446/1500], Training Loss: 0.9121, Validation Loss: 2.9728, Validation Accuracy: 0.4735, Percentage:47.3529%\n",
            "Epoch [1447/1500], Training Loss: 0.8805, Validation Loss: 3.2257, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [1448/1500], Training Loss: 0.8816, Validation Loss: 3.0382, Validation Accuracy: 0.4235, Percentage:42.3529%\n",
            "Epoch [1449/1500], Training Loss: 0.9123, Validation Loss: 3.2318, Validation Accuracy: 0.4196, Percentage:41.9608%\n",
            "Epoch [1450/1500], Training Loss: 0.9267, Validation Loss: 3.4115, Validation Accuracy: 0.4206, Percentage:42.0588%\n",
            "Epoch [1451/1500], Training Loss: 0.8536, Validation Loss: 3.1825, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [1452/1500], Training Loss: 0.9083, Validation Loss: 3.1514, Validation Accuracy: 0.4225, Percentage:42.2549%\n",
            "Epoch [1453/1500], Training Loss: 0.9341, Validation Loss: 3.1663, Validation Accuracy: 0.4284, Percentage:42.8431%\n",
            "Epoch [1454/1500], Training Loss: 0.8187, Validation Loss: 3.3241, Validation Accuracy: 0.4618, Percentage:46.1765%\n",
            "Epoch [1455/1500], Training Loss: 0.8455, Validation Loss: 3.4707, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [1456/1500], Training Loss: 0.7628, Validation Loss: 3.4151, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [1457/1500], Training Loss: 0.8203, Validation Loss: 3.3970, Validation Accuracy: 0.4765, Percentage:47.6471%\n",
            "Epoch [1458/1500], Training Loss: 0.8702, Validation Loss: 3.0962, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [1459/1500], Training Loss: 0.8769, Validation Loss: 3.1653, Validation Accuracy: 0.4775, Percentage:47.7451%\n",
            "Epoch [1460/1500], Training Loss: 0.8199, Validation Loss: 3.5169, Validation Accuracy: 0.4127, Percentage:41.2745%\n",
            "Epoch [1461/1500], Training Loss: 0.9543, Validation Loss: 3.3949, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [1462/1500], Training Loss: 0.7971, Validation Loss: 3.0052, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [1463/1500], Training Loss: 0.8139, Validation Loss: 3.2400, Validation Accuracy: 0.4657, Percentage:46.5686%\n",
            "Epoch [1464/1500], Training Loss: 0.8875, Validation Loss: 3.1600, Validation Accuracy: 0.4578, Percentage:45.7843%\n",
            "Epoch [1465/1500], Training Loss: 0.8406, Validation Loss: 3.3211, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [1466/1500], Training Loss: 0.8311, Validation Loss: 3.1935, Validation Accuracy: 0.4225, Percentage:42.2549%\n",
            "Epoch [1467/1500], Training Loss: 0.8887, Validation Loss: 3.2555, Validation Accuracy: 0.4627, Percentage:46.2745%\n",
            "Epoch [1468/1500], Training Loss: 0.8631, Validation Loss: 3.3245, Validation Accuracy: 0.4412, Percentage:44.1176%\n",
            "Epoch [1469/1500], Training Loss: 0.9444, Validation Loss: 2.8510, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [1470/1500], Training Loss: 0.8980, Validation Loss: 3.1340, Validation Accuracy: 0.4382, Percentage:43.8235%\n",
            "Epoch [1471/1500], Training Loss: 0.7791, Validation Loss: 3.4002, Validation Accuracy: 0.4490, Percentage:44.9020%\n",
            "Epoch [1472/1500], Training Loss: 0.8381, Validation Loss: 3.0411, Validation Accuracy: 0.4451, Percentage:44.5098%\n",
            "Epoch [1473/1500], Training Loss: 0.8884, Validation Loss: 3.4161, Validation Accuracy: 0.4559, Percentage:45.5882%\n",
            "Epoch [1474/1500], Training Loss: 0.8675, Validation Loss: 3.0671, Validation Accuracy: 0.4765, Percentage:47.6471%\n",
            "Epoch [1475/1500], Training Loss: 0.7811, Validation Loss: 2.9615, Validation Accuracy: 0.4676, Percentage:46.7647%\n",
            "Epoch [1476/1500], Training Loss: 0.9263, Validation Loss: 2.6953, Validation Accuracy: 0.4569, Percentage:45.6863%\n",
            "Epoch [1477/1500], Training Loss: 0.7936, Validation Loss: 3.0784, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [1478/1500], Training Loss: 0.7987, Validation Loss: 3.0842, Validation Accuracy: 0.4618, Percentage:46.1765%\n",
            "Epoch [1479/1500], Training Loss: 0.8447, Validation Loss: 3.1766, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [1480/1500], Training Loss: 0.8123, Validation Loss: 3.2043, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [1481/1500], Training Loss: 0.9303, Validation Loss: 3.1690, Validation Accuracy: 0.4294, Percentage:42.9412%\n",
            "Epoch [1482/1500], Training Loss: 0.8283, Validation Loss: 3.2204, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [1483/1500], Training Loss: 0.8308, Validation Loss: 3.4497, Validation Accuracy: 0.4725, Percentage:47.2549%\n",
            "Epoch [1484/1500], Training Loss: 0.9399, Validation Loss: 3.6292, Validation Accuracy: 0.4480, Percentage:44.8039%\n",
            "Epoch [1485/1500], Training Loss: 0.9278, Validation Loss: 3.3032, Validation Accuracy: 0.4333, Percentage:43.3333%\n",
            "Epoch [1486/1500], Training Loss: 0.8882, Validation Loss: 3.2359, Validation Accuracy: 0.4471, Percentage:44.7059%\n",
            "Epoch [1487/1500], Training Loss: 0.8580, Validation Loss: 3.5376, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [1488/1500], Training Loss: 0.8826, Validation Loss: 2.9462, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [1489/1500], Training Loss: 0.9286, Validation Loss: 3.3157, Validation Accuracy: 0.4363, Percentage:43.6275%\n",
            "Epoch [1490/1500], Training Loss: 0.8525, Validation Loss: 3.1886, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Epoch [1491/1500], Training Loss: 0.8580, Validation Loss: 3.2645, Validation Accuracy: 0.4441, Percentage:44.4118%\n",
            "Epoch [1492/1500], Training Loss: 0.8365, Validation Loss: 3.0048, Validation Accuracy: 0.4176, Percentage:41.7647%\n",
            "Epoch [1493/1500], Training Loss: 0.9095, Validation Loss: 3.3491, Validation Accuracy: 0.4373, Percentage:43.7255%\n",
            "Epoch [1494/1500], Training Loss: 0.8507, Validation Loss: 3.0430, Validation Accuracy: 0.4598, Percentage:45.9804%\n",
            "Epoch [1495/1500], Training Loss: 0.8651, Validation Loss: 3.2602, Validation Accuracy: 0.4588, Percentage:45.8824%\n",
            "Epoch [1496/1500], Training Loss: 0.7931, Validation Loss: 3.3916, Validation Accuracy: 0.4520, Percentage:45.1961%\n",
            "Epoch [1497/1500], Training Loss: 0.8209, Validation Loss: 3.2851, Validation Accuracy: 0.4422, Percentage:44.2157%\n",
            "Epoch [1498/1500], Training Loss: 0.8796, Validation Loss: 3.1684, Validation Accuracy: 0.4873, Percentage:48.7255%\n",
            "Epoch [1499/1500], Training Loss: 0.7628, Validation Loss: 3.1124, Validation Accuracy: 0.4637, Percentage:46.3725%\n",
            "Epoch [1500/1500], Training Loss: 0.8165, Validation Loss: 3.2769, Validation Accuracy: 0.4500, Percentage:45.0000%\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import Flowers102\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define transforms for data augmentation and normalization\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the dataset with train/val/test splits\n",
        "train_dataset = Flowers102(root='./data', split='train', transform=train_transform, download=True)\n",
        "val_dataset = Flowers102(root='./data', split='val', transform=val_transform, download=True)\n",
        "test_dataset = Flowers102(root='./data', split='test', transform=val_transform, download=True)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Define data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "test_loader= DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "class CNN_NN(nn.Module):\n",
        "    def __init__(self, num_classes=102):\n",
        "        super(CNN_NN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv5= nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv6= nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation =1, ceil_mode=False)\n",
        "\n",
        "        # Initialize the size of the fully connected layer based on the sample input\n",
        "        self._to_linear = None\n",
        "        self.convs = nn.Sequential(\n",
        "            self.conv1,\n",
        "            nn.ReLU(inplace=True),\n",
        "            #self.pool,\n",
        "            self.conv2,\n",
        "            nn.ReLU(inplace=True),\n",
        "            self.pool,\n",
        "            self.conv3,\n",
        "            nn.ReLU(inplace=True),\n",
        "            #self.pool,\n",
        "            self.conv4,\n",
        "            nn.ReLU(inplace=True),\n",
        "            self.pool,\n",
        "            self.conv5,\n",
        "            nn.ReLU(inplace=True),\n",
        "            self.conv6,\n",
        "            nn.ReLU(inplace=True),\n",
        "            self.pool,\n",
        "        )\n",
        "        self._initialize_linear_layer()\n",
        "\n",
        "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def _initialize_linear_layer(self):\n",
        "        # Create a dummy input tensor to calculate the output size after conv layers\n",
        "        x = torch.randn(1, 3, 224, 224)\n",
        "        x = self.convs(x)\n",
        "        self._to_linear = x.view(1, -1).shape[1]\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor while preserving the batch size\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Define the device (GPU or CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyperparameters\n",
        "num_classes = 102  # Number of output classes\n",
        "learning_rate = 0.001\n",
        "num_epochs = 1500\n",
        "\n",
        "# Initialize the model\n",
        "model = CNN_NN(num_classes=num_classes).to(device)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    # Calculate average loss for the epoch\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item() * images.size(0)\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            testtotal += labels.size(0)\n",
        "            testcorrect += (predicted == labels).sum().item()\n",
        "\n",
        "    # Calculate average validation loss and accuracy\n",
        "    val_loss = val_loss / len(val_loader.dataset)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    test_loss = test_loss / len(test_loader.dataset)\n",
        "    testaccuracy = testcorrect / testtotal\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "          f'Training Loss: {epoch_loss:.4f}, '\n",
        "          f'Validation Loss: {val_loss:.4f}, '\n",
        "          f'Validation Accuracy: {accuracy:.4f}, '\n",
        "          f'Percentage:{accuracy*100:.4f}%'\n",
        "          f'Test Loss: {test_loss:.4f}, '\n",
        "          f'Test Accuracy: {testaccuracy:.4f}, '\n",
        "          f'Percentage:{testaccuracy*100:.4f}%'\n",
        "          )\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "rqUwnXfZ6YML",
        "outputId": "254a1617-894b-4e9f-d5a1-f32adca903c0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-d28051310ae4>\u001b[0m in \u001b[0;36m<cell line: 110>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Set the model to training mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/flowers102.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m   1278\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_saturation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaturation_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mfn_id\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhue_factor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1280\u001b[0;31m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_hue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36madjust_hue\u001b[0;34m(img, hue_factor)\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjust_hue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_hue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_hue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_pil.py\u001b[0m in \u001b[0;36madjust_hue\u001b[0;34m(img, hue_factor)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"L\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"HSV\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m   1079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdither\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}